{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d83b802-887f-4e95-8540-136c17a629df",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99cd3dce-5ab8-42dd-9509-caa6a16d8769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully configured pip to use AWS CodeArtifact repository https://amazon-149122183214.d.codeartifact.us-west-2.amazonaws.com/pypi/shared/ \n",
      "Login expires in 12 hours at 2025-04-25 00:48:49+00:00\n"
     ]
    }
   ],
   "source": [
    "!aws codeartifact login --tool pip --repository shared --domain amazon --domain-owner 149122183214 --region us-west-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f7260d-cfd1-45e5-aae5-57dd590be0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  -U -q transformers trl datasets bitsandbytes peft accelerate triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a005c53-c4f1-4ab2-9cf4-9107fe8d214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7633d9-3ddd-4471-81b7-68e89fb32f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorboard\n",
    "!pip install -q word2number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6bfa27-ac0b-41b6-9490-061483edf187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c265d3-aab1-4dea-8078-821edccddc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU allocated memory: 0.00 GB\n",
      "GPU reserved memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "\n",
    "def clear_memory():\n",
    "    # Delete variables if they exist in the current global scope\n",
    "    if \"inputs\" in globals():\n",
    "        del globals()[\"inputs\"]\n",
    "    if \"model\" in globals():\n",
    "        del globals()[\"model\"]\n",
    "    if \"processor\" in globals():\n",
    "        del globals()[\"processor\"]\n",
    "    if \"trainer\" in globals():\n",
    "        del globals()[\"trainer\"]\n",
    "    if \"peft_model\" in globals():\n",
    "        del globals()[\"peft_model\"]\n",
    "    if \"bnb_config\" in globals():\n",
    "        del globals()[\"bnb_config\"]\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Garbage collection and clearing CUDA memory\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    time.sleep(2)\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e67363-8216-4855-8755-fcaf089d165f",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d7d987-a855-4df8-8364-a143a1bf61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Resources & Precision ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16\n",
    "ATTN_IMPLEMENTATION = \"flash_attention_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38a358a-39e5-4e3a-83ae-7e3a4f56f2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 12:49:07.848482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-24 12:49:07.864255: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-24 12:49:07.869216: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-24 12:49:07.880668: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face transformers\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    Idefics3ForConditionalGeneration,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "\n",
    "MODEL_ID = \"HuggingFaceTB/SmolVLM-256M-Instruct\" # specify model to use here\n",
    "\n",
    "base_model_config = AutoConfig.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "base_model_config.use_cache = True\n",
    "\n",
    "if hasattr(base_model_config, \"attn_implementation\"):\n",
    "    base_model_config.attn_implementation = ATTN_IMPLEMENTATION\n",
    "\n",
    "base_load_kwargs = {\"device_map\": \"auto\", \"torch_dtype\": DTYPE}\n",
    "\n",
    "base_model_eval = Idefics3ForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    config=base_model_config,\n",
    "    trust_remote_code=True,\n",
    "    **base_load_kwargs\n",
    ")\n",
    "\n",
    "base_model_eval.eval()\n",
    "print(\"Base model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2883b2-4f66-42c5-948f-3701e089186b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9deac1ee-b18c-449d-b57c-5ca7a045b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "WORKING_DIR = \"./\"\n",
    "OUTPUT_DIR_BASE_NAME = \"base_evaluation\"\n",
    "\n",
    "OUTPUT_DIR = os.path.join(WORKING_DIR, OUTPUT_DIR_BASE_NAME) # full path on Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b487bcf-7f92-4813-a272-a5bf09d4ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation Config ---\n",
    "CHARTQA_DATASET_ID = \"HuggingFaceM4/ChartQA\"\n",
    "EVAL_SPLIT = \"test\"\n",
    "EVAL_LIMIT = None # number of chartqa samples to use when evaluating ChartQA\n",
    "MAX_NEW_TOKENS_EVAL = 32\n",
    "EVAL_OUTPUT_FILE = os.path.join(OUTPUT_DIR, MODEL_ID, \"chartqa_evaluation_results_comparison.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3081b667-5f31-4c4d-a514-0fc4e45c97df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2500 samples for evaluation (full test set).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "chartqa_test_iterable = load_dataset(CHARTQA_DATASET_ID, split=EVAL_SPLIT, streaming=False)\n",
    "chartqa_test_dataset = list(chartqa_test_iterable)\n",
    "print(f\"Loaded {len(chartqa_test_dataset)} samples for evaluation (full {EVAL_SPLIT} set).\")\n",
    "\n",
    "if chartqa_test_dataset:\n",
    "     if isinstance(chartqa_test_dataset[0], dict) and 'img_idx' not in chartqa_test_dataset[0]:\n",
    "          chartqa_test_dataset = [dict(sample, img_idx=i) for i, sample in enumerate(chartqa_test_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86f91aaf-3cdd-453b-9a69-fcce0536d1d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Evaluation Helper Functions ---\n",
      "Evaluation helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Define Evaluation helper functions\n",
    "print(\"\\n--- Defining Evaluation Helper Functions ---\")\n",
    "\n",
    "# System message for evaluation prompting (provided by SmolVLM)\n",
    "EVAL_SYSTEM_MESSAGE = \"\"\"You are a Vision Language Model specialized in interpreting visual data from chart images.\n",
    "Your task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase.\n",
    "The charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\n",
    "Focus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.\"\"\"\n",
    "\n",
    "def create_inference_chat_messages(sample):\n",
    "    \"\"\"Creates the chat message structure for inference using ChartQA's 'query' field.\"\"\"\n",
    "    question = sample.get(\"query\")\n",
    "    if not question:\n",
    "        return None\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": EVAL_SYSTEM_MESSAGE}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": question}]},\n",
    "    ]\n",
    "\n",
    "\n",
    "print(\"Evaluation helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005599c5-7ac7-47d1-83c8-26ce3fdfe7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Evaluation Generation & Saving ---\n"
     ]
    }
   ],
   "source": [
    "# --- Generate Predictions and Save Results ---\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "print(\"\\n--- Running Evaluation Generation & Saving ---\")\n",
    "\n",
    "# --- Define Concise Generation Function ---\n",
    "def generate_prediction_concise(model, processor, sample, max_tokens):\n",
    "    question, image = sample.get(\"query\"), sample.get(\"image\")\n",
    "    if not (question and isinstance(image, Image.Image)): return \"ERROR:Input\"\n",
    "    if image.mode != 'RGB':\n",
    "        try: image = image.convert('RGB')\n",
    "        except: return \"ERROR:Convert\"\n",
    "\n",
    "    messages = create_inference_chat_messages(sample)\n",
    "    if not messages: return \"ERROR:Messages\"\n",
    "\n",
    "    prediction = \"ERROR:Generate\"\n",
    "    inputs = None; generated_ids = None\n",
    "    try:\n",
    "        prompt = processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "        device = next(iter(model.parameters()), torch.tensor([])).device\n",
    "        if device is None: device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        inputs = processor(text=[prompt], images=[image], return_tensors=\"pt\", padding=True).to(device)\n",
    "        torch.cuda.empty_cache()\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=max_tokens, do_sample=False,\n",
    "                                       pad_token_id=processor.tokenizer.pad_token_id,\n",
    "                                       eos_token_id=processor.tokenizer.eos_token_id)\n",
    "        gen_tokens = generated_ids[0, inputs[\"input_ids\"].shape[1]:]\n",
    "        prediction = processor.decode(gen_tokens, skip_special_tokens=True).strip() if gen_tokens.numel() > 0 else \"[NO_TOKENS]\"\n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠️ Exception occurred during prediction:\\nType: {e.__class__.__name__}\\nMessage: {e}\")\n",
    "        prediction = f\"ERROR:{e.__class__.__name__}\"\n",
    "    finally:\n",
    "        del inputs, generated_ids\n",
    "    return prediction\n",
    "# --- End Generation Function ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea4cfaee-747a-4b64-9281-d5517eb579ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processor for model: HuggingFaceTB/SmolVLM-256M-Instruct\n",
      "Processor loaded.\n"
     ]
    }
   ],
   "source": [
    "# load Processor\n",
    "print(f\"Loading processor for model: {MODEL_ID}\")\n",
    "eval_processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "if eval_processor.tokenizer.pad_token_id is None:\n",
    "    eval_processor.tokenizer.pad_token = eval_processor.tokenizer.eos_token\n",
    "    if hasattr(eval_processor, 'pad_token') and eval_processor.pad_token is None:\n",
    "        eval_processor.pad_token = eval_processor.tokenizer.eos_token\n",
    "print(\"Processor loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74a1456-8ff7-45c0-b108-57695ce1c662",
   "metadata": {},
   "source": [
    "## Generate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c130793a-0562-4d87-9d81-ee00eb331e53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for 1 model(s) on 2500 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5f2cbceb2949d181c5f0bb50265584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 25.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 344.00 MiB memory in use. Of the allocated memory 92.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 25.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 344.00 MiB memory in use. Of the allocated memory 92.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 25.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 344.00 MiB memory in use. Of the allocated memory 92.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 25.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 344.00 MiB memory in use. Of the allocated memory 92.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 91.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: OutOfMemoryError\n",
      "Message: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 13.19 MiB is free. Process 64477 has 768.00 MiB memory in use. Process 65179 has 7.15 GiB memory in use. Process 13331 has 6.53 GiB memory in use. Process 16490 has 7.15 GiB memory in use. Process 37647 has 356.00 MiB memory in use. Of the allocated memory 104.20 MiB is allocated by PyTorch, and 3.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "⚠️ Exception occurred during prediction:\n",
      "Type: RuntimeError\n",
      "Message: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Generate for applicable models\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, model_obj \u001b[38;5;129;01min\u001b[39;00m models_to_eval\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 25\u001b[0m         entry[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_answer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_prediction_concise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_processor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_NEW_TOKENS_EVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     results_list\u001b[38;5;241m.\u001b[39mappend(entry)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# --- End Prediction Loop ---\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# --- Save results_df to JSON ---\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 37\u001b[0m, in \u001b[0;36mgenerate_prediction_concise\u001b[0;34m(model, processor, sample, max_tokens)\u001b[0m\n\u001b[1;32m     34\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(model\u001b[38;5;241m.\u001b[39mparameters()), torch\u001b[38;5;241m.\u001b[39mtensor([]))\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     38\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     39\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, max_new_tokens\u001b[38;5;241m=\u001b[39mmax_tokens, do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m                                pad_token_id\u001b[38;5;241m=\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[1;32m     41\u001b[0m                                eos_token_id\u001b[38;5;241m=\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/idefics3/processing_idefics3.py:286\u001b[0m, in \u001b[0;36mIdefics3Processor.__call__\u001b[0;34m(self, images, text, audio, videos, image_seq_len, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# Load images if they are URLs\u001b[39;00m\n\u001b[1;32m    284\u001b[0m images \u001b[38;5;241m=\u001b[39m [[load_image(im) \u001b[38;5;28;01mif\u001b[39;00m is_url(im) \u001b[38;5;28;01melse\u001b[39;00m im \u001b[38;5;28;01mfor\u001b[39;00m im \u001b[38;5;129;01min\u001b[39;00m sample] \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[0;32m--> 286\u001b[0m image_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moutput_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages_kwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m inputs\u001b[38;5;241m.\u001b[39mupdate(image_inputs)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/image_processing_utils.py:42\u001b[0m, in \u001b[0;36mBaseImageProcessor.__call__\u001b[0;34m(self, images, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchFeature:\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/idefics3/image_processing_idefics3.py:769\u001b[0m, in \u001b[0;36mIdefics3ImageProcessor.preprocess\u001b[0;34m(self, images, do_convert_rgb, do_resize, size, resample, do_image_splitting, do_rescale, max_image_size, rescale_factor, do_normalize, image_mean, image_std, do_pad, return_tensors, return_row_col_info, data_format, input_data_format)\u001b[0m\n\u001b[1;32m    767\u001b[0m image_cols \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, palette \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(images, palettes):\n\u001b[0;32m--> 769\u001b[0m     split_image_array, rows, cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_image_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_image_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    774\u001b[0m     split_image_arrays\u001b[38;5;241m.\u001b[39mextend(split_image_array)\n\u001b[1;32m    775\u001b[0m     split_palettes_arrays\u001b[38;5;241m.\u001b[39mextend([palette] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(split_image_array))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/idefics3/image_processing_idefics3.py:447\u001b[0m, in \u001b[0;36mIdefics3ImageProcessor.split_image\u001b[0;34m(self, image, max_image_size, resample, data_format, input_data_format)\u001b[0m\n\u001b[1;32m    445\u001b[0m     global_image_height, global_image_width \u001b[38;5;241m=\u001b[39m max_height, max_width\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m height \u001b[38;5;241m!=\u001b[39m global_image_height \u001b[38;5;129;01mor\u001b[39;00m width \u001b[38;5;241m!=\u001b[39m global_image_width:\n\u001b[0;32m--> 447\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_image_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwidth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_image_width\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     num_splits_h, num_splits_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/idefics3/image_processing_idefics3.py:369\u001b[0m, in \u001b[0;36mIdefics3ImageProcessor.resize\u001b[0;34m(self, image, size, resample, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m     image_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    367\u001b[0m image \u001b[38;5;241m=\u001b[39m to_pil_image(image, image_mode\u001b[38;5;241m=\u001b[39mimage_mode, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format)\n\u001b[0;32m--> 369\u001b[0m resized_image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m resized_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(resized_image)\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# If the input image channel dimension was of size 1, then it is dropped when converting to a PIL image\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# so we need to add it back if necessary.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/PIL/Image.py:2356\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2346\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2347\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2348\u001b[0m         )\n\u001b[1;32m   2349\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2350\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2351\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2352\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2353\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2354\u001b[0m         )\n\u001b[0;32m-> 2356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Determine models to evaluate\n",
    "models_to_eval = {}\n",
    "models_to_eval[\"base\"] = base_model_eval\n",
    "\n",
    "results_list = []\n",
    "# Check dataset and models before looping\n",
    "print(f\"Generating predictions for {len(models_to_eval)} model(s) on {len(chartqa_test_dataset)} samples...\")\n",
    "# --- Generate Predictions ---\n",
    "for sample in tqdm(chartqa_test_dataset, desc=\"Generating Predictions\"):\n",
    "    entry = {\"id\": sample.get(\"img_idx\", \"N/A\"),\n",
    "             \"question\": sample.get(\"query\"),\n",
    "             \"ground_truth\": str(sample.get(\"label\"))} # Convert GT to string here\n",
    "\n",
    "    # Basic validation of core sample data needed for processing\n",
    "    if not all([entry[\"id\"] != \"N/A\", entry[\"question\"], entry[\"ground_truth\"] is not None, isinstance(sample.get(\"image\"), Image.Image)]):\n",
    "        print(f\"Warning: Skipping sample {entry['id']} due to missing/invalid core data.\")\n",
    "        continue # Skip this sample\n",
    "\n",
    "    # Generate for applicable models\n",
    "    for name, model_obj in models_to_eval.items():\n",
    "        entry[f\"predicted_answer_{name}\"] = generate_prediction_concise(model_obj, eval_processor, sample, MAX_NEW_TOKENS_EVAL)\n",
    "    results_list.append(entry)\n",
    "# --- End Prediction Loop ---\n",
    "\n",
    "# --- Save results_df to JSON ---\n",
    "if results_list:\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    if 'EVAL_OUTPUT_FILE' in locals() and EVAL_OUTPUT_FILE:\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(EVAL_OUTPUT_FILE), exist_ok=True)\n",
    "            results_df.to_json(EVAL_OUTPUT_FILE, orient=\"records\", indent=2)\n",
    "            print(f\"\\nEvaluation results (raw predictions) saved to: {EVAL_OUTPUT_FILE}\")\n",
    "        except Exception as e_save:\n",
    "             print(f\"\\nERROR saving evaluation results to {EVAL_OUTPUT_FILE}: {e_save}\")\n",
    "    else:\n",
    "         print(\"\\nWarning: EVAL_OUTPUT_FILE not defined, results not saved.\")\n",
    "else:\n",
    "    print(\"No valid evaluation results were generated to save.\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n--- Evaluation Generation & Saving Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905910c9-cf29-4e9f-99b0-34b1416233dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "\n",
    "### Final results compilation\n",
    "print(\"--- Aggregating Evaluation Results ---\")\n",
    "\n",
    "BASE_OUTPUT_DIR = Path(WORKING_DIR)\n",
    "OUTPUT_FOLDER_PREFIX = OUTPUT_DIR_BASE_NAME\n",
    "EVAL_FILENAME = \"chartqa_evaluation_results_comparison.json\"\n",
    "\n",
    "search_pattern = f\"{OUTPUT_FOLDER_PREFIX}/{MODEL_ID}/{EVAL_FILENAME}\"\n",
    "result_files = list(BASE_OUTPUT_DIR.glob(search_pattern))\n",
    "\n",
    "# if not result_files:\n",
    "#     raise FileNotFoundError(\"No evaluation result files found.\")\n",
    "\n",
    "aggregated_dfs = []\n",
    "base_models_added = set()\n",
    "\n",
    "for file_path in result_files:\n",
    "    run_label = file_path.parent.name.replace(f\"{OUTPUT_FOLDER_PREFIX}-\", \"\")\n",
    "    parts = run_label.split('-')\n",
    "    base_model_name = '-'.join(parts[:-1]) if len(parts) >= 2 else \"UnknownBase\"\n",
    "    base_label = f\"{base_model_name}-Original\"\n",
    "\n",
    "    df = pd.read_json(file_path)\n",
    "\n",
    "    columns = ['id', 'question', 'ground_truth'] if not aggregated_dfs else ['id']\n",
    "    rename_dict = {}\n",
    "\n",
    "    if 'predicted_answer_finetuned' in df:\n",
    "        columns.append('predicted_answer_finetuned')\n",
    "        rename_dict['predicted_answer_finetuned'] = f\"Pred_{run_label}\"\n",
    "\n",
    "    if base_model_name not in base_models_added and 'predicted_answer_base' in df:\n",
    "        columns.append('predicted_answer_base')\n",
    "        rename_dict['predicted_answer_base'] = f\"Pred_{base_label}\"\n",
    "        base_models_added.add(base_model_name)\n",
    "\n",
    "    df_subset = df[columns].rename(columns=rename_dict)\n",
    "    aggregated_dfs.append(df_subset)\n",
    "\n",
    "if aggregated_dfs:\n",
    "    final_comparison_df = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), aggregated_dfs)\n",
    "    final_comparison_df.ffill(inplace=True)\n",
    "    final_comparison_df.bfill(inplace=True)\n",
    "else:\n",
    "    print(\"⚠️ No evaluation results found to aggregate.\")\n",
    "    final_comparison_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "print(\"Aggregated Results Preview:\")\n",
    "display(final_comparison_df.head())\n",
    "\n",
    "output_file = BASE_OUTPUT_DIR / OUTPUT_DIR_BASE_NAME / MODEL_ID /f\"{OUTPUT_FOLDER_PREFIX}-ALL_RUNS_COMPARISON_WITH_BASE.csv\"\n",
    "final_comparison_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Aggregated results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10316636-431a-44e3-a2c6-86aa954a1c1b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12659b6-d9d0-4621-b6af-b584cd60e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from word2number import w2n\n",
    "\n",
    "# --- Advanced accuracy metrics -------------------------------\n",
    "\n",
    "YES, NO      = {\"yes\",\"y\",\"true\",\"correct\"}, {\"no\",\"n\",\"false\",\"incorrect\"}\n",
    "TOL, EPS     = 0.05, 1e-9                  # ±5 %, tiny tolerance for 0\n",
    "PRED_PREFIX  = \"Pred_\"                     # rename if your columns differ\n",
    "\n",
    "# 2.  Helpers -------------------------------------------------------------------\n",
    "def to_scalar(v):\n",
    "    \"\"\"Clean & convert value → float | 'yes' | 'no' | None.\"\"\"\n",
    "    if pd.isna(v): return None\n",
    "    s = str(v).strip()\n",
    "    m = re.fullmatch(r\"\\[['\\\"]?(.*?)['\\\"]?\\]\", s)\n",
    "    if m: s = m.group(1)\n",
    "    s = s.lower().replace(\",\",\"\").replace(\"$\",\"\").replace(\"%\",\"\").strip()\n",
    "    if s in YES: return \"yes\"\n",
    "    if s in NO:  return \"no\"\n",
    "    for fn in (float, w2n.word_to_num):\n",
    "        try: return float(fn(s))\n",
    "        except Exception: pass\n",
    "    return None\n",
    "\n",
    "def relaxed(gt, pred):\n",
    "    return abs(gt - pred) <= (abs(gt) * TOL or EPS)\n",
    "\n",
    "# 3.  Basic checks --------------------------------------------------------------\n",
    "if not isinstance(globals().get(\"final_comparison_df\"), pd.DataFrame):\n",
    "    sys.exit(\"  `final_comparison_df` is missing.\")\n",
    "\n",
    "df = final_comparison_df.copy()\n",
    "df[\"GT_proc\"] = df[\"ground_truth\"].map(to_scalar)\n",
    "\n",
    "keep = df[\"GT_proc\"].isin([\"yes\",\"no\"]) | df[\"GT_proc\"].apply(lambda x: isinstance(x,(int,float)))\n",
    "df_filt = df[keep]\n",
    "if df_filt.empty:\n",
    "    sys.exit(\"  No yes/no/numeric ground‑truth rows after processing.\")\n",
    "\n",
    "# Metrics per run -----------------------------------------------------------\n",
    "results = {}\n",
    "for col in [c for c in df.columns if c.startswith(PRED_PREFIX)]:\n",
    "    proc = f\"{col}_proc\"\n",
    "    df[proc] = df[col].map(to_scalar)\n",
    "\n",
    "    valid   = df[[\"GT_proc\", proc]].dropna()\n",
    "    numeric = valid[valid[\"GT_proc\"].apply(lambda x:isinstance(x,(int,float))) &\n",
    "                    valid[proc].apply(lambda x:isinstance(x,(int,float)))]\n",
    "\n",
    "    em  = 100 * (valid[\"GT_proc\"] == valid[proc]).mean() if not valid.empty else 0\n",
    "    rel = 100 * numeric.apply(lambda r: relaxed(r[\"GT_proc\"], r[proc]), axis=1).mean() if not numeric.empty else 0\n",
    "\n",
    "    run = col.replace(PRED_PREFIX, \"\")\n",
    "    results[run] = {\"EM (%)\": round(em,2),\n",
    "                    \"Relaxed Num (%)\": round(rel,2),\n",
    "                    \"# Numeric\": len(numeric),\n",
    "                    \"# Valid\": len(valid)}\n",
    "\n",
    "    print(f\"{run:<15} EM={em:6.2f}%  Relaxed={rel:6.2f}%  ({len(numeric)} num / {len(valid)} valid)\")\n",
    "\n",
    "# Summary & preview ---------------------------------------------------------\n",
    "summary = pd.DataFrame(results).T.sort_values(\"EM (%)\", ascending=False)\n",
    "display(summary)\n",
    "display(df.head())\n",
    "\n",
    "# Save to CSV ---------------------------------------------------------------\n",
    "BASE_OUTPUT_DIR = Path(globals().get(\"BASE_OUTPUT_DIR\", \"./outputs\"))\n",
    "BASE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "prefix = globals().get(\"OUTPUT_FOLDER_PREFIX\", \"RUNS\")\n",
    "out_file = BASE_OUTPUT_DIR / OUTPUT_DIR_BASE_NAME / MODEL_ID / f\"{prefix}-ALL_RUNS_COMPARISON_WITH_PROCESSED.csv\"\n",
    "df.to_csv(out_file, index=False)\n",
    "print(\"💾  Saved:\", out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8c154-8219-4a70-b228-3510867b94e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
