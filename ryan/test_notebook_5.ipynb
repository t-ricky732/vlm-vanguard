{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVKZjV8QLkg-"
   },
   "source": [
    "# Fine-tuning SmolVLM on ChartLlama Dataset\n",
    "\n",
    "This notebook demonstrates how to fine-tune the SmolVLM model on the ChartLlama dataset using parameter-efficient fine-tuning (LoRA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2647,
     "status": "ok",
     "timestamp": 1745711394433,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "aYU5W95UL-6o",
    "outputId": "de2c0620-a0b3-4c97-b1e8-8d890980938f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745711394434,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "5_dD1fjUMVNd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14774,
     "status": "ok",
     "timestamp": 1745711409208,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "pcdMTIUFvfEK",
    "outputId": "69186c44-680e-4a4a-eeaa-99bc31983522"
   },
   "outputs": [],
   "source": [
    "# Core dependencies\n",
    "!pip install -U datasets\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -U transformers\n",
    "!pip install -U trl  # latest TRL library from HuggingFace\n",
    "!pip install -q flash-attn --no-build-isolation\n",
    "!pip install -q word2number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9732,
     "status": "ok",
     "timestamp": 1745711418940,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "BYxXUfaQc4Zi"
   },
   "outputs": [],
   "source": [
    "# --- Standard Libraries ---\n",
    "import os, sys, gc, time, json, re, math, string, traceback\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from itertools import islice\n",
    "\n",
    "# --- Data Science & Visualization ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from cycler import cycler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Image Processing ---\n",
    "from PIL import Image\n",
    "\n",
    "# --- Data Handling & Utils ---\n",
    "from datasets import Dataset, load_dataset\n",
    "from accelerate.utils import set_seed\n",
    "from word2number import w2n\n",
    "\n",
    "# --- Hugging Face Transformers ---\n",
    "from transformers import (\n",
    "    AutoProcessor, AutoConfig, Idefics3ForConditionalGeneration,\n",
    "    BitsAndBytesConfig, TrainingArguments\n",
    ")\n",
    "\n",
    "# --- PEFT (Parameter-Efficient Fine-Tuning) ---\n",
    "from peft import (\n",
    "    LoraConfig, get_peft_model,\n",
    "    prepare_model_for_kbit_training, PeftModel\n",
    ")\n",
    "\n",
    "# --- TRL (Supervised Fine-Tuning) ---\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# --- Experiment Tracking & Deep Learning ---\n",
    "import wandb\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1745711418947,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "RWp3MYBBc8iQ",
    "outputId": "5ea47cae-09d8-45d0-e252-bd6e90914abc"
   },
   "outputs": [],
   "source": [
    "print(\"--- Setting Configuration --- \")\n",
    "\n",
    "# --- Basic Setup ---\n",
    "WORKING_DIR = '/content/drive/MyDrive/code'\n",
    "DATA_DIR = Path(\"./chartllama_data\")\n",
    "OUTPUT_DIR_BASE_NAME = \"smolvlm-chartllama-sft-final\" # change to short prompt for short prompt\n",
    "# OUTPUT_DIR_BASE_NAME = \"smolvlm-chartllama-sft-refactored\"\n",
    "SEED = 42\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745711418951,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "1vjAnlL6dDJh",
    "outputId": "e6929ff2-e34f-4559-e5bc-af9ebbdd4fa6"
   },
   "outputs": [],
   "source": [
    "if os.getcwd() != WORKING_DIR:\n",
    "    print(f\"Changing working directory to: {WORKING_DIR}\")\n",
    "    os.makedirs(WORKING_DIR, exist_ok=True)\n",
    "    os.chdir(WORKING_DIR)\n",
    "else:\n",
    "    print(f\"Already in working directory: {WORKING_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745711418953,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "sIeivHQGdFgK"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"HuggingFaceTB/SmolVLM-256M-Instruct\" # specify model to use here\n",
    "\n",
    "USE_LORA = True\n",
    "USE_QLORA = True\n",
    "\n",
    "LORA_R = 8 # rank set to 8\n",
    "LORA_ALPHA = 16 # default of 8\n",
    "LORA_DROPOUT = 0.1\n",
    "LORA_TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",  # attention heads\n",
    "                       \"gate_proj\", \"up_proj\", \"down_proj\", \"lm_head\"\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745711418956,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "duu5OGm7dM6B"
   },
   "outputs": [],
   "source": [
    "if USE_QLORA and not USE_LORA:\n",
    "    print(\"Warning: USE_QLORA=True requires USE_LORA=True. Forcing USE_LORA=True.\")\n",
    "    USE_LORA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1745711418995,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "u-tvlcIQdOoV"
   },
   "outputs": [],
   "source": [
    "# --- Training Hyperparameters ---\n",
    "NUM_TRAIN_EPOCHS = 6 # keep to default of 3\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "LEARNING_RATE = 1e-3\n",
    "MAX_SEQ_LENGTH = 2048\n",
    "OPTIMIZER = \"adamw_torch_fused\"\n",
    "LR_SCHEDULER_TYPE = \"cosine\" # default to cosine\n",
    "LOGGING_STEPS = 25\n",
    "SAVE_STRATEGY = \"epoch\"\n",
    "EVAL_STRATEGY = \"epoch\"\n",
    "EVAL_STEPS = 50\n",
    "WARMUP_RATIO = 0.1\n",
    "WEIGHT_DECAY = 0.01 # default set to 0.01\n",
    "SAMPLE_LIMIT = None # training sample limit on Chartllama, None will use everything available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745711418997,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "mlBh3DVVdShz"
   },
   "outputs": [],
   "source": [
    "# --- Resources & Precision ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16\n",
    "ATTN_IMPLEMENTATION = \"flash_attention_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745711418999,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "OXBzYGOjdW7f"
   },
   "outputs": [],
   "source": [
    "# --- Output Directory (Directly on Drive) ---\n",
    "if not USE_LORA:\n",
    "    TRAINING_TYPE = \"full-tuned\"\n",
    "elif USE_QLORA:\n",
    "    TRAINING_TYPE = \"qlora-tuned\"\n",
    "else:\n",
    "    TRAINING_TYPE = \"lora-tuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745711419000,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "bUHrgvpCdZbl"
   },
   "outputs": [],
   "source": [
    "model_name_short = MODEL_ID.split('/')[-1]\n",
    "output_folder_name = f\"{OUTPUT_DIR_BASE_NAME}-{model_name_short}-{TRAINING_TYPE}-lalpha16-lr1e-3-6epochs\" # test for lora alpha 16\n",
    "OUTPUT_DIR = os.path.join(WORKING_DIR, output_folder_name) # full path on Drive\n",
    "FINAL_MODEL_DIR = os.path.join(OUTPUT_DIR, \"final_model\")\n",
    "FINAL_PROCESSOR_DIR = os.path.join(OUTPUT_DIR, \"final_processor\") # sub directory to save processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745711419002,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "kSAIVl-Fdbbn"
   },
   "outputs": [],
   "source": [
    "# --- Evaluation Config ---\n",
    "CHARTQA_DATASET_ID = \"HuggingFaceM4/ChartQA\"\n",
    "EVAL_SPLIT = \"test\"\n",
    "EVAL_LIMIT = None # number of chartqa samples to use when evaluating ChartQA\n",
    "MAX_NEW_TOKENS_EVAL = 32\n",
    "EVAL_OUTPUT_FILE = os.path.join(OUTPUT_DIR, \"chartqa_evaluation_results_comparison.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745711419003,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "ym39Yfg4deFo"
   },
   "outputs": [],
   "source": [
    "# --- W&B Logging ---\n",
    "WANDB_PROJECT = \"smolvlm-chartllama-sft-refactored\" # Set to None to disable\n",
    "WANDB_RUN_NAME = f\"{model_name_short}-{TRAINING_TYPE}-{int(time.time())}\" # Unique name for run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1745711419011,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "JFSY5rXtdg5b",
    "outputId": "a1629a13-928d-4d0a-aa6c-25aa67bebb02"
   },
   "outputs": [],
   "source": [
    "# Create output directory now (important for direct-to-drive)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Output directory ensured: '{OUTPUT_DIR}'\")\n",
    "\n",
    "# display summary of all relevant information based on above settings.\n",
    "# --- Print Summary ---\n",
    "print(f\"\\n--- Configuration Summary ---\")\n",
    "print(f\"Model ID: {MODEL_ID}\")\n",
    "print(f\"Training Type: {TRAINING_TYPE}\")\n",
    "print(f\"Use LoRA: {USE_LORA}, Use QLoRA: {USE_QLORA}\")\n",
    "print(f\"Device: {DEVICE}, Compute Dtype: {DTYPE}, Attention: {ATTN_IMPLEMENTATION}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}, Epochs: {NUM_TRAIN_EPOCHS}\")\n",
    "print(f\"Eval Strategy: {EVAL_STRATEGY}\")\n",
    "print(f\"Output Directory (on Drive): '{OUTPUT_DIR}'\")\n",
    "print(f\"Final Model Save Directory: '{FINAL_MODEL_DIR}'\")\n",
    "print(f\"Final Processor Save Directory: '{FINAL_PROCESSOR_DIR}'\")\n",
    "print(f\"Evaluation results file: {EVAL_OUTPUT_FILE}\")\n",
    "print(f\"WandB Project: {WANDB_PROJECT}, Run Name: {WANDB_RUN_NAME}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "print(\"\\n--- Full Configuration Complete --- \")\n",
    "\n",
    "print(\"\\n--- Configuration Complete --- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "executionInfo": {
     "elapsed": 2582,
     "status": "ok",
     "timestamp": 1745711421594,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "T3b3BNGjdjPZ",
    "outputId": "f502a84f-222f-4f00-ec59-854ef15f9281"
   },
   "outputs": [],
   "source": [
    "# api key: 0469802d14d997b8dad4d23a7ba212e0a8d8f197\n",
    "# --- Simplified WandB setup ---\n",
    "print(\"--- WandB Setup ---\")\n",
    "\n",
    "if WANDB_PROJECT:\n",
    "    try:\n",
    "        wandb.login(relogin=False)\n",
    "        wandb.init(\n",
    "            project=WANDB_PROJECT,\n",
    "            name=WANDB_RUN_NAME,\n",
    "            config={\n",
    "                \"model_id\": MODEL_ID,\n",
    "                \"training_type\": TRAINING_TYPE,\n",
    "                \"use_lora\": USE_LORA,\n",
    "                \"use_qlora\": USE_QLORA,\n",
    "                \"dtype\": str(DTYPE),\n",
    "                \"seed\": SEED,\n",
    "                \"lora_r\": LORA_R if USE_LORA else None,\n",
    "                \"lora_alpha\": LORA_ALPHA if USE_LORA else None,\n",
    "                \"num_epochs\": NUM_TRAIN_EPOCHS,\n",
    "                \"learning_rate\": LEARNING_RATE,\n",
    "                \"batch_size\": PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "                \"grad_accum\": GRADIENT_ACCUMULATION_STEPS,\n",
    "                \"max_seq_length\": MAX_SEQ_LENGTH,\n",
    "                \"output_dir\": OUTPUT_DIR,\n",
    "                \"optimizer\": OPTIMIZER,\n",
    "                \"lr_scheduler\": LR_SCHEDULER_TYPE,\n",
    "                \"warmup_ratio\": WARMUP_RATIO,\n",
    "                \"weight_decay\": WEIGHT_DECAY,\n",
    "            },\n",
    "            job_type=\"fine-tuning\"\n",
    "        )\n",
    "        print(\"WandB initialized.\")\n",
    "    except Exception as e:\n",
    "        print(f\"WandB initialization failed: {e}. Disabling WandB.\")\n",
    "        os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "else:\n",
    "    print(\"WandB disabled by configuration (WANDB_PROJECT=None).\")\n",
    "    os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"--- WandB Setup Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745711421601,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "odBskBDddpMe",
    "outputId": "2efbe7e1-4be1-487a-bcad-e52cabe05119"
   },
   "outputs": [],
   "source": [
    "# --- Define chartllama data loading function ---\n",
    "\n",
    "print(\"\\n--- Defining Data Loading Function ---\")\n",
    "\n",
    "def load_chartllama_data(data_root: Path, image_root: Path, limit: Optional[int] = None):\n",
    "    \"\"\"Loads ChartLlama QA pairs from JSON files.\"\"\"\n",
    "    if not data_root.is_dir():\n",
    "        raise FileNotFoundError(f\"Data root directory not found: {data_root.resolve()}\")\n",
    "\n",
    "    examples, skipped = [], 0\n",
    "    json_files = list(data_root.glob(\"*_simplified_qa.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        raise FileNotFoundError(f\"No '*_simplified_qa.json' files found in {data_root}\")\n",
    "\n",
    "    for json_file in tqdm(json_files, desc=\"Processing JSON files\"):\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            qa_list = json.load(f)\n",
    "\n",
    "        for idx, qa in enumerate(qa_list):\n",
    "            if limit and len(examples) >= limit:\n",
    "                break\n",
    "\n",
    "            question = qa.get(\"conversations\", [{}])[0].get(\"value\", \"\").replace(\"<image>\", \"\").strip()\n",
    "            answer = qa.get(\"conversations\", [{}, {}])[1].get(\"value\", \"\").strip()\n",
    "            image_path = (image_root / qa.get(\"image\", \"\")).resolve()\n",
    "\n",
    "            if question and answer and image_path.is_file():\n",
    "                examples.append({\n",
    "                    \"id\": qa.get(\"id\", f\"{json_file.stem}_{idx}\"),\n",
    "                    \"question\": question,\n",
    "                    \"answer\": answer,\n",
    "                    \"image_path\": str(image_path),\n",
    "                })\n",
    "            else:\n",
    "                skipped += 1\n",
    "\n",
    "    if not examples:\n",
    "        raise ValueError(f\"No valid examples loaded from {data_root}. Skipped {skipped} samples.\")\n",
    "\n",
    "    print(f\"\\nLoaded {len(examples)} examples. Skipped {skipped} invalid samples.\")\n",
    "    return Dataset.from_list(examples)\n",
    "\n",
    "print(\"Data loading function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257,
     "referenced_widgets": [
      "d4ede4870e1141c6bd20c881c7542561",
      "318fa65bb4b3451f848b9aabbc1c3dec",
      "95ee650e26524c2b95576af19956da20",
      "246b6fd44d954f2d957c03ef681be01f",
      "f70adc76a4ad409e9ac3eff3f36931d6",
      "d28f46fc556f4ad1be066066518db2d6",
      "1c6685c0922246f3a6a11c3bba62ea11",
      "e8859dca2116420b953ccc99bc2eca08",
      "79d2e1aaf7c6466db7fc1148ae0a2a20",
      "74b4488a1d5b4c7d8b93542de528ffd8",
      "06bd36c53ad14d7d891e84a4798b632a"
     ]
    },
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1745711422641,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "FU4jyOiEd2Rn",
    "outputId": "c56f60b3-738c-4ddf-dee5-1856b92b0ece"
   },
   "outputs": [],
   "source": [
    "# --- Load Chartllama data ---\n",
    "\n",
    "print(\"\\n--- Loading and Splitting Data ---\")\n",
    "train_dataset, eval_dataset, raw_dataset = None, None, None\n",
    "\n",
    "# ensure DATA_DIR is a valid Path object\n",
    "DATA_DIR = Path(DATA_DIR)\n",
    "if not DATA_DIR.is_absolute():\n",
    "    DATA_DIR = Path(WORKING_DIR) / DATA_DIR\n",
    "\n",
    "if not DATA_DIR.is_dir():\n",
    "    raise FileNotFoundError(f\"Input data directory not found: {DATA_DIR.resolve()}\")\n",
    "\n",
    "print(f\"Loading data from: {DATA_DIR.resolve()}\")\n",
    "raw_dataset = load_chartllama_data(DATA_DIR, DATA_DIR, limit=SAMPLE_LIMIT)\n",
    "\n",
    "if not raw_dataset:\n",
    "    raise RuntimeError(\"Data loading returned an empty dataset.\")\n",
    "\n",
    "# split dataset: 80% train, 20% validation\n",
    "dataset_split = raw_dataset.train_test_split(test_size=0.2, seed=SEED, shuffle=True)\n",
    "train_dataset, eval_dataset = dataset_split[\"train\"], dataset_split[\"test\"]\n",
    "\n",
    "print(f\"\\nRaw data loaded and split.\")\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Eval samples (Validation): {len(eval_dataset)}\")\n",
    "\n",
    "# display one sample from train dataset\n",
    "if train_dataset:\n",
    "    print(\"\\nSample train data point (raw):\")\n",
    "    print(train_dataset[0])\n",
    "else:\n",
    "    print(\"Train dataset is empty after split.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5631,
     "status": "ok",
     "timestamp": 1745711428279,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "xKDyoRSSd8V7",
    "outputId": "92d618ba-0500-458a-ac97-0784feec45ef"
   },
   "outputs": [],
   "source": [
    "# ### 3.1 Load Model and Processor\n",
    "\n",
    "print(\"\\n--- Loading Model and Processor for Training ---\")\n",
    "\n",
    "# load Processor\n",
    "print(f\"Loading processor for model: {MODEL_ID}\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "if processor.tokenizer.pad_token_id is None:\n",
    "    processor.tokenizer.pad_token = processor.tokenizer.eos_token\n",
    "    if hasattr(processor, 'pad_token') and processor.pad_token is None:\n",
    "        processor.pad_token = processor.tokenizer.eos_token\n",
    "print(\"Processor loaded.\")\n",
    "\n",
    "# configure Model Loading\n",
    "print(\"\\nConfiguring model loading...\")\n",
    "model_load_kwargs = {\"device_map\": \"auto\", \"torch_dtype\": DTYPE}\n",
    "\n",
    "if USE_LORA and USE_QLORA:\n",
    "    print(\"Configuring model for QLoRA (4-bit).\")\n",
    "    model_load_kwargs[\"quantization_config\"] = BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=DTYPE\n",
    "    )\n",
    "elif USE_LORA:\n",
    "    print(f\"Configuring model for LoRA (dtype: {DTYPE}).\")\n",
    "else:\n",
    "    print(f\"Configuring model for Full Fine-Tuning (dtype: {DTYPE}).\")\n",
    "\n",
    "# load Config\n",
    "config = AutoConfig.from_pretrained(MODEL_ID, trust_remote_code=True, use_cache=False)\n",
    "if hasattr(config, \"attn_implementation\"):\n",
    "    config.attn_implementation = ATTN_IMPLEMENTATION\n",
    "\n",
    "# load Model\n",
    "print(f\"Loading model '{MODEL_ID}'...\")\n",
    "model = Idefics3ForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID, config=config, trust_remote_code=True, **model_load_kwargs\n",
    ")\n",
    "\n",
    "print(\"Model loaded.\")\n",
    "print(f\"  - Device Map: {getattr(model, 'hf_device_map', model.device)}\")\n",
    "print(f\"  - Attention Implementation: {getattr(model.config, 'attn_implementation', 'N/A')}\")\n",
    "\n",
    "# PEFT Setup\n",
    "if USE_LORA:\n",
    "    print(\"\\nApplying PEFT/LoRA configuration...\")\n",
    "    if USE_QLORA:\n",
    "        model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True, gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "    elif hasattr(model, \"gradient_checkpointing_enable\"):\n",
    "        model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "        model.config.use_cache = False\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        r=LORA_R, lora_alpha=LORA_ALPHA, lora_dropout=LORA_DROPOUT,\n",
    "        target_modules=LORA_TARGET_MODULES, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "\n",
    "    if not isinstance(model, PeftModel):\n",
    "        model = get_peft_model(model, peft_config)\n",
    "        model.print_trainable_parameters()\n",
    "else:\n",
    "    if hasattr(model, \"gradient_checkpointing_enable\"):\n",
    "        model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "        model.config.use_cache = False\n",
    "\n",
    "print(\"\\n--- Model and Processor Setup Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1745711428292,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "odIqqWQXeT3r",
    "outputId": "937f937c-2c5c-4071-d63d-2db6cdafb727"
   },
   "outputs": [],
   "source": [
    "# ### 3.1 define smolvlm formatting functions and collate_fn\n",
    "\n",
    "print(\"\\n--- Defining Formatting Function & Data Collator ---\")\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"You are a Vision Language Model specialized in interpreting visual data from chart images.\n",
    "Your task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase.\n",
    "The charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\n",
    "Focus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.\"\"\"\n",
    "\n",
    "# SYSTEM_MESSAGE = \"\"\"You are a Vision-Language Model specialized in interpreting chart images. Please answer the question using only one word or a number based on the provided chart.\"\"\"\n",
    "\n",
    "def create_chat_messages(sample):\n",
    "    \"\"\"Creates the chat message structure for SFT training.\"\"\"\n",
    "    question = sample.get(\"question\")\n",
    "    answer = sample.get(\"answer\")\n",
    "    if question is None or answer is None:\n",
    "         return None\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": SYSTEM_MESSAGE}]},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": question}\n",
    "        ]},\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": answer}]},\n",
    "    ]\n",
    "\n",
    "\n",
    "@dataclass # ChartLlama collator class for collate function\n",
    "class ChartLlamaCollator:\n",
    "    processor: AutoProcessor\n",
    "    max_seq_length: int = MAX_SEQ_LENGTH\n",
    "\n",
    "    def __post_init__(self):\n",
    "        image_token_str = \"<image>\"\n",
    "        self.image_token_id = self.processor.tokenizer.convert_tokens_to_ids(image_token_str)\n",
    "        if self.image_token_id is None:\n",
    "            self.image_token_id = -100\n",
    "\n",
    "    def __call__(self, examples: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        pil_images, texts = [], []\n",
    "\n",
    "        for ex in examples:\n",
    "            img_path = ex.get('image_path')\n",
    "            if not img_path or not os.path.exists(img_path):\n",
    "                continue\n",
    "\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            messages = create_chat_messages(ex)\n",
    "            if messages is None:\n",
    "                continue\n",
    "\n",
    "            formatted_text = self.processor.apply_chat_template(\n",
    "                messages, add_generation_prompt=False, tokenize=False\n",
    "            )\n",
    "\n",
    "            pil_images.append(img)\n",
    "            texts.append(formatted_text)\n",
    "\n",
    "        if not texts or not pil_images:\n",
    "            return {\"input_ids\": torch.tensor([], dtype=torch.long)}\n",
    "\n",
    "        batch = self.processor(\n",
    "            text=texts,\n",
    "            images=pil_images,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            # truncation=True,\n",
    "            # max_length=self.max_seq_length,\n",
    "        )\n",
    "\n",
    "        labels = batch[\"input_ids\"].clone()\n",
    "        labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        if self.image_token_id != -100:\n",
    "            labels[labels == self.image_token_id] = -100\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "chart_collator = ChartLlamaCollator(processor=processor)\n",
    "print(\"\\nCustom Collator instantiated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1745711428319,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "vQ0-a3LaeZO9",
    "outputId": "267aae7c-da5e-48de-fe43-bc0466023569"
   },
   "outputs": [],
   "source": [
    "# configure training arguments\n",
    "print(\"\\n--- Configuring Training Arguments ---\")\n",
    "\n",
    "if 'OUTPUT_DIR' not in locals():\n",
    "    raise NameError(\"OUTPUT_DIR not defined. Rerun configuration cell.\")\n",
    "\n",
    "trainer_config = SFTConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    dataset_text_field=\"\",\n",
    "    packing=False,\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "\n",
    "    optim=OPTIMIZER,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
    "\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    save_strategy=SAVE_STRATEGY,\n",
    "    save_total_limit=2,\n",
    "    save_only_model=(\"peft_config\" in locals() and peft_config is not None),\n",
    "\n",
    "    bf16=(DTYPE == torch.bfloat16),\n",
    "    fp16=(DTYPE == torch.float16),\n",
    "\n",
    "    eval_strategy=EVAL_STRATEGY,\n",
    "    eval_steps=EVAL_STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "\n",
    "    seed=SEED,\n",
    "    report_to=\"wandb\" if WANDB_PROJECT and os.environ.get(\"WANDB_DISABLED\") != \"true\" else \"none\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "print(\"SFTConfig set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1745711428706,
     "user": {
      "displayName": "moto ginkoin",
      "userId": "12822709115880680776"
     },
     "user_tz": -540
    },
    "id": "7TzmIm_QcsfB",
    "outputId": "6c140006-9f9b-41ab-8f85-0a88f04c5f6e"
   },
   "outputs": [],
   "source": [
    "# initialize trainer\n",
    "\n",
    "print(\"\\n--- Initializing SFTTrainer ---\")\n",
    "\n",
    "required_components = [train_dataset, model, trainer_config, chart_collator, processor]\n",
    "\n",
    "if all(required_components):\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=trainer_config,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset if EVAL_STRATEGY != \"no\" else None,\n",
    "        data_collator=chart_collator,\n",
    "        peft_config=peft_config if USE_LORA else None,\n",
    "    )\n",
    "    print(\"SFTTrainer initialized successfully.\")\n",
    "else:\n",
    "    missing = [name for name, comp in zip(\n",
    "        ['train_dataset', 'model', 'trainer_config', 'chart_collator', 'processor'],\n",
    "        required_components) if comp is None]\n",
    "    raise RuntimeError(f\"Cannot initialize trainer. Missing components: {', '.join(missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "YExT-I4GevPn",
    "outputId": "f1071374-21f2-45ed-877a-4d2e7dcf713f"
   },
   "outputs": [],
   "source": [
    "# --- Run Training (with Loss curve Plotting Added & Enhanced Naming) ---\n",
    "\n",
    "print(\"\\n--- Checking if Training Should Be Skipped ---\")\n",
    "\n",
    "model_exists = os.path.isdir(FINAL_MODEL_DIR) and any(\n",
    "    f.endswith(('.bin', '.safetensors', 'adapter_config.json')) for f in os.listdir(FINAL_MODEL_DIR)\n",
    ")\n",
    "\n",
    "processor_exists = os.path.isfile(os.path.join(FINAL_PROCESSOR_DIR, \"preprocessor_config.json\"))\n",
    "\n",
    "if model_exists and processor_exists:\n",
    "    print(\"Model and processor already exist. Skipping training.\")\n",
    "else:\n",
    "    if trainer is None or processor is None:\n",
    "        raise RuntimeError(\"Trainer or processor not available. Cannot proceed with training.\")\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    os.makedirs(FINAL_MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(FINAL_PROCESSOR_DIR, exist_ok=True)\n",
    "\n",
    "    train_result = trainer.train()\n",
    "\n",
    "    print(f\"Training completed in {(time.time() - start_time)/60:.2f} minutes.\")\n",
    "\n",
    "    trainer.save_model(FINAL_MODEL_DIR)\n",
    "    processor.save_pretrained(FINAL_PROCESSOR_DIR)\n",
    "\n",
    "    trainer.log_metrics(\"train\", train_result.metrics)\n",
    "    trainer.save_metrics(\"train\", train_result.metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "    log_history = trainer.state.log_history\n",
    "    if log_history:\n",
    "        log_df = pd.DataFrame(log_history)\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "        if 'loss' in log_df:\n",
    "            ax.plot(log_df['step'], log_df['loss'], label='Training Loss', marker='o')\n",
    "        if 'eval_loss' in log_df:\n",
    "            ax.plot(log_df['step'], log_df['eval_loss'], label='Validation Loss', marker='s')\n",
    "\n",
    "        ax.set_title(f\"Training & Validation Loss ({model_name_short}, {TRAINING_TYPE})\")\n",
    "        ax.set_xlabel(\"Steps\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "        plot_path = os.path.join(OUTPUT_DIR, f\"loss_curves_{model_name_short}_{TRAINING_TYPE}.png\")\n",
    "        fig.savefig(plot_path, dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "# Cleanup\n",
    "del trainer\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n--- Training Step Execution Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLW_j24AfXO6"
   },
   "outputs": [],
   "source": [
    "# --- Load Fine-tuned Model ---\n",
    "print(\"\\n--- Setting up Evaluation Environment ---\")\n",
    "\n",
    "FT_MODEL_LOAD_PATH = FINAL_MODEL_DIR\n",
    "PROCESSOR_LOAD_PATH = FINAL_PROCESSOR_DIR\n",
    "\n",
    "print(f\"Loading processor from: {PROCESSOR_LOAD_PATH}\")\n",
    "\n",
    "if not os.path.isdir(PROCESSOR_LOAD_PATH):\n",
    "    raise FileNotFoundError(f\"Processor directory not found: {PROCESSOR_LOAD_PATH}\")\n",
    "\n",
    "eval_processor = AutoProcessor.from_pretrained(PROCESSOR_LOAD_PATH, trust_remote_code=True)\n",
    "\n",
    "if eval_processor.tokenizer.pad_token_id is None:\n",
    "    eval_processor.tokenizer.pad_token = eval_processor.tokenizer.eos_token\n",
    "    if hasattr(eval_processor, 'pad_token') and eval_processor.pad_token is None:\n",
    "        eval_processor.pad_token = eval_processor.tokenizer.eos_token\n",
    "\n",
    "print(\"Processor loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvrSHP3NbX3K"
   },
   "outputs": [],
   "source": [
    "# --- Load Fine-tuned Model ---\n",
    "\n",
    "eval_model = None\n",
    "if not eval_processor:\n",
    "    raise RuntimeError(\"Processor is not loaded. Cannot load model.\")\n",
    "\n",
    "if not os.path.isdir(FT_MODEL_LOAD_PATH):\n",
    "    raise FileNotFoundError(f\"Fine-tuned model directory not found: {FT_MODEL_LOAD_PATH}\")\n",
    "\n",
    "# Load evaluation configuration\n",
    "try:\n",
    "    eval_config = AutoConfig.from_pretrained(FT_MODEL_LOAD_PATH, trust_remote_code=True)\n",
    "except OSError:\n",
    "    eval_config = AutoConfig.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "eval_config.use_cache = True\n",
    "if hasattr(eval_config, \"attn_implementation\"):\n",
    "    eval_config.attn_implementation = ATTN_IMPLEMENTATION\n",
    "\n",
    "load_kwargs = {\"device_map\": \"auto\", \"torch_dtype\": DTYPE}\n",
    "\n",
    "if USE_LORA:\n",
    "    # Ensure pad_token consistency\n",
    "    pad_token_id = eval_processor.tokenizer.pad_token_id\n",
    "    base_config = AutoConfig.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "    config_to_modify = base_config.text_config if hasattr(base_config, 'text_config') else base_config\n",
    "    config_to_modify.pad_token_id = pad_token_id\n",
    "    config_to_modify.vocab_size = max(config_to_modify.vocab_size, pad_token_id + 1)\n",
    "\n",
    "    base_config.use_cache = True\n",
    "    if hasattr(base_config, \"attn_implementation\"):\n",
    "        base_config.attn_implementation = ATTN_IMPLEMENTATION\n",
    "\n",
    "    # if USE_QLORA: # do not use quantization\n",
    "    #     load_kwargs[\"quantization_config\"] = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=DTYPE)\n",
    "\n",
    "    base_model = Idefics3ForConditionalGeneration.from_pretrained(MODEL_ID, config=base_config, trust_remote_code=True, **load_kwargs)\n",
    "    eval_model = PeftModel.from_pretrained(base_model, FT_MODEL_LOAD_PATH)\n",
    "else:\n",
    "    eval_model = Idefics3ForConditionalGeneration.from_pretrained(FT_MODEL_LOAD_PATH, config=eval_config, trust_remote_code=True, **load_kwargs)\n",
    "\n",
    "# Prepare model for evaluation\n",
    "eval_model.eval()\n",
    "print(\"Fine-tuned model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7JCuLGbrGyJ"
   },
   "outputs": [],
   "source": [
    "# --- Load Base Model for Evaluation ---\n",
    "\n",
    "if eval_processor is None:\n",
    "    raise RuntimeError(\"Processor is not loaded; cannot load base model.\")\n",
    "\n",
    "base_model_config = AutoConfig.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "base_model_config.use_cache = True\n",
    "\n",
    "if hasattr(base_model_config, \"attn_implementation\"):\n",
    "    base_model_config.attn_implementation = ATTN_IMPLEMENTATION\n",
    "\n",
    "base_load_kwargs = {\"device_map\": \"auto\", \"torch_dtype\": DTYPE}\n",
    "\n",
    "base_model_eval = Idefics3ForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    config=base_model_config,\n",
    "    trust_remote_code=True,\n",
    "    **base_load_kwargs\n",
    ")\n",
    "\n",
    "base_model_eval.eval()\n",
    "print(\"Base model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stWYNZe_fyQD"
   },
   "outputs": [],
   "source": [
    "# --- Load Evaluation Dataset (ChartQA) ---\n",
    "chartqa_test_dataset = None\n",
    "if eval_processor:\n",
    "    try:\n",
    "        print(f\"\\nLoading evaluation dataset '{CHARTQA_DATASET_ID}' split '{EVAL_SPLIT}'...\")\n",
    "        chartqa_test_iterable = load_dataset(CHARTQA_DATASET_ID, split=EVAL_SPLIT, streaming=False)\n",
    "\n",
    "        if EVAL_LIMIT is not None and EVAL_LIMIT > 0:\n",
    "            chartqa_test_list = list(chartqa_test_iterable)\n",
    "            chartqa_test_dataset = chartqa_test_list[:EVAL_LIMIT]\n",
    "            print(f\"Loaded and limited to {len(chartqa_test_dataset)} samples for evaluation.\")\n",
    "        else:\n",
    "            chartqa_test_dataset = list(chartqa_test_iterable)\n",
    "            print(f\"Loaded {len(chartqa_test_dataset)} samples for evaluation (full {EVAL_SPLIT} set).\")\n",
    "\n",
    "        if chartqa_test_dataset:\n",
    "             if isinstance(chartqa_test_dataset[0], dict) and 'img_idx' not in chartqa_test_dataset[0]:\n",
    "                  chartqa_test_dataset = [dict(sample, img_idx=i) for i, sample in enumerate(chartqa_test_dataset)]\n",
    "        else:\n",
    "             print(\"Warning: ChartQA dataset is empty after loading/limiting.\")\n",
    "\n",
    "    except Exception as e_dataset:\n",
    "        print(f\"ERROR loading evaluation dataset: {e_dataset}\")\n",
    "        traceback.print_exc()\n",
    "        chartqa_test_dataset = None\n",
    "else:\n",
    "     print(\"Skipping dataset loading due to processor error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "za0dmEKnf0TZ"
   },
   "outputs": [],
   "source": [
    "# Check Evaluation Readiness\n",
    "components = {\n",
    "    \"Processor\": eval_processor,\n",
    "    \"Fine-tuned Model\": eval_model,\n",
    "    \"Base Model\": base_model_eval,\n",
    "    \"Dataset\": chartqa_test_dataset if chartqa_test_dataset else None,\n",
    "}\n",
    "\n",
    "readiness = {name: comp is not None for name, comp in components.items()}\n",
    "readiness[\"Dataset\"] = readiness[\"Dataset\"] and len(chartqa_test_dataset) > 0\n",
    "\n",
    "can_evaluate_finetuned = all([readiness[\"Processor\"], readiness[\"Fine-tuned Model\"], readiness[\"Dataset\"]])\n",
    "can_evaluate_base = all([readiness[\"Processor\"], readiness[\"Base Model\"], readiness[\"Dataset\"]])\n",
    "\n",
    "print(\"\\nEvaluation Readiness:\")\n",
    "for name, ready in readiness.items():\n",
    "    print(f\"  - {name} Ready: {ready}\")\n",
    "\n",
    "print(f\"  - Can Evaluate Fine-tuned: {can_evaluate_finetuned}\")\n",
    "print(f\"  - Can Evaluate Base: {can_evaluate_base}\")\n",
    "print(f\"Evaluation Device: {DEVICE}\")\n",
    "\n",
    "# cleanup\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n--- Evaluation Setup Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ursoAe7Yf314"
   },
   "outputs": [],
   "source": [
    "# Define Evaluation helper functions\n",
    "print(\"\\n--- Defining Evaluation Helper Functions ---\")\n",
    "\n",
    "# System message for evaluation prompting (provided by SmolVLM)\n",
    "EVAL_SYSTEM_MESSAGE = \"\"\"You are a Vision Language Model specialized in interpreting visual data from chart images.\n",
    "Your task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase.\n",
    "The charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\n",
    "Focus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.\"\"\"\n",
    "\n",
    "# EVAL_SYSTEM_MESSAGE = \"\"\"Have fun!\"\"\"\n",
    "\n",
    "def create_inference_chat_messages(sample):\n",
    "    \"\"\"Creates the chat message structure for inference using ChartQA's 'query' field.\"\"\"\n",
    "    question = sample.get(\"query\")\n",
    "    if not question:\n",
    "        return None\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": EVAL_SYSTEM_MESSAGE}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": question}]},\n",
    "    ]\n",
    "\n",
    "\n",
    "print(\"Evaluation helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhz0ZKGdf6hX"
   },
   "outputs": [],
   "source": [
    "# --- Generate Predictions and Save Results ---\n",
    "\n",
    "print(\"\\n--- Running Evaluation Generation & Saving ---\")\n",
    "\n",
    "# --- Define Concise Generation Function ---\n",
    "def generate_prediction_concise(model, processor, sample, max_tokens, max_len):\n",
    "    question, image = sample.get(\"query\"), sample.get(\"image\")\n",
    "    if not (question and isinstance(image, Image.Image)): return \"ERROR:Input\"\n",
    "    if image.mode != 'RGB':\n",
    "        try: image = image.convert('RGB')\n",
    "        except: return \"ERROR:Convert\"\n",
    "\n",
    "    messages = create_inference_chat_messages(sample)\n",
    "    if not messages: return \"ERROR:Messages\"\n",
    "\n",
    "    prediction = \"ERROR:Generate\"\n",
    "    inputs = None; generated_ids = None\n",
    "    try:\n",
    "        prompt = processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "        device = next(iter(model.parameters()), torch.tensor([])).device\n",
    "        if device is None: device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        inputs = processor(text=[prompt], images=[image], return_tensors=\"pt\", padding=False, truncation=True, max_length=max_len).to(device)\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=max_tokens, do_sample=False,\n",
    "                                       pad_token_id=processor.tokenizer.pad_token_id,\n",
    "                                       eos_token_id=processor.tokenizer.eos_token_id)\n",
    "        gen_tokens = generated_ids[0, inputs[\"input_ids\"].shape[1]:]\n",
    "        prediction = processor.decode(gen_tokens, skip_special_tokens=True).strip() if gen_tokens.numel() > 0 else \"[NO_TOKENS]\"\n",
    "    except Exception as e:\n",
    "        prediction = f\"ERROR:{e.__class__.__name__}\"\n",
    "    finally:\n",
    "        del inputs, generated_ids\n",
    "    return prediction\n",
    "# --- End Generation Function ---\n",
    "\n",
    "# Determine models to evaluate\n",
    "models_to_eval = {}\n",
    "if 'can_evaluate_finetuned' in locals() and can_evaluate_finetuned and 'eval_model' in locals():\n",
    "    models_to_eval[\"finetuned\"] = eval_model\n",
    "# if not needed comment out finetuning for base model\n",
    "# if 'can_evaluate_base' in locals() and can_evaluate_base and 'base_model_eval' in locals():\n",
    "#     models_to_eval[\"base\"] = base_model_eval\n",
    "\n",
    "results_list = []\n",
    "# Check dataset and models before looping\n",
    "if 'chartqa_test_dataset' in locals() and chartqa_test_dataset and models_to_eval:\n",
    "    print(f\"Generating predictions for {len(models_to_eval)} model(s) on {len(chartqa_test_dataset)} samples...\")\n",
    "    # --- Generate Predictions ---\n",
    "    for sample in tqdm(chartqa_test_dataset, desc=\"Generating Predictions\"):\n",
    "        entry = {\"id\": sample.get(\"img_idx\", \"N/A\"),\n",
    "                 \"question\": sample.get(\"query\"),\n",
    "                 \"ground_truth\": str(sample.get(\"label\"))} # Convert GT to string here\n",
    "\n",
    "        # Basic validation of core sample data needed for processing\n",
    "        if not all([entry[\"id\"] != \"N/A\", entry[\"question\"], entry[\"ground_truth\"] is not None, isinstance(sample.get(\"image\"), Image.Image)]):\n",
    "            print(f\"Warning: Skipping sample {entry['id']} due to missing/invalid core data.\")\n",
    "            continue # Skip this sample\n",
    "\n",
    "        # Generate for applicable models\n",
    "        for name, model_obj in models_to_eval.items():\n",
    "            entry[f\"predicted_answer_{name}\"] = generate_prediction_concise(model_obj, eval_processor, sample, MAX_NEW_TOKENS_EVAL, MAX_SEQ_LENGTH)\n",
    "        results_list.append(entry)\n",
    "    # --- End Prediction Loop ---\n",
    "\n",
    "    # --- Save results_df to JSON ---\n",
    "    if results_list:\n",
    "        results_df = pd.DataFrame(results_list)\n",
    "        if 'EVAL_OUTPUT_FILE' in locals() and EVAL_OUTPUT_FILE:\n",
    "            try:\n",
    "                os.makedirs(os.path.dirname(EVAL_OUTPUT_FILE), exist_ok=True)\n",
    "                results_df.to_json(EVAL_OUTPUT_FILE, orient=\"records\", indent=2)\n",
    "                print(f\"\\nEvaluation results (raw predictions) saved to: {EVAL_OUTPUT_FILE}\")\n",
    "            except Exception as e_save:\n",
    "                 print(f\"\\nERROR saving evaluation results to {EVAL_OUTPUT_FILE}: {e_save}\")\n",
    "        else:\n",
    "             print(\"\\nWarning: EVAL_OUTPUT_FILE not defined, results not saved.\")\n",
    "    else:\n",
    "        print(\"No valid evaluation results were generated to save.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping evaluation generation: Dataset or models not ready.\")\n",
    "\n",
    "print(f\"\\n--- Evaluation Generation & Saving Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46FDeddBnzI-"
   },
   "outputs": [],
   "source": [
    "### Final results compilation\n",
    "print(\"--- Aggregating Evaluation Results ---\")\n",
    "\n",
    "BASE_OUTPUT_DIR = Path(WORKING_DIR)\n",
    "OUTPUT_FOLDER_PREFIX = OUTPUT_DIR_BASE_NAME\n",
    "EVAL_FILENAME = \"chartqa_evaluation_results_comparison.json\"\n",
    "\n",
    "search_pattern = f\"{OUTPUT_FOLDER_PREFIX}*/{EVAL_FILENAME}\"\n",
    "result_files = list(BASE_OUTPUT_DIR.glob(search_pattern))\n",
    "\n",
    "# if not result_files:\n",
    "#     raise FileNotFoundError(\"No evaluation result files found.\")\n",
    "\n",
    "aggregated_dfs = []\n",
    "base_models_added = set()\n",
    "\n",
    "for file_path in result_files:\n",
    "    run_label = file_path.parent.name.replace(f\"{OUTPUT_FOLDER_PREFIX}-\", \"\")\n",
    "    parts = run_label.split('-')\n",
    "    base_model_name = '-'.join(parts[:-1]) if len(parts) >= 2 else \"UnknownBase\"\n",
    "    base_label = f\"{base_model_name}-Original\"\n",
    "\n",
    "    df = pd.read_json(file_path)\n",
    "\n",
    "    columns = ['id', 'question', 'ground_truth'] if not aggregated_dfs else ['id']\n",
    "    rename_dict = {}\n",
    "\n",
    "    if 'predicted_answer_finetuned' in df:\n",
    "        columns.append('predicted_answer_finetuned')\n",
    "        rename_dict['predicted_answer_finetuned'] = f\"Pred_{run_label}\"\n",
    "\n",
    "    if base_model_name not in base_models_added and 'predicted_answer_base' in df:\n",
    "        columns.append('predicted_answer_base')\n",
    "        rename_dict['predicted_answer_base'] = f\"Pred_{base_label}\"\n",
    "        base_models_added.add(base_model_name)\n",
    "\n",
    "    df_subset = df[columns].rename(columns=rename_dict)\n",
    "    aggregated_dfs.append(df_subset)\n",
    "\n",
    "if aggregated_dfs:\n",
    "    final_comparison_df = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), aggregated_dfs)\n",
    "    final_comparison_df.ffill(inplace=True)\n",
    "    final_comparison_df.bfill(inplace=True)\n",
    "else:\n",
    "    print(\" No evaluation results found to aggregate.\")\n",
    "    final_comparison_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "print(\"Aggregated Results Preview:\")\n",
    "display(final_comparison_df.head())\n",
    "\n",
    "output_file = BASE_OUTPUT_DIR / f\"{OUTPUT_FOLDER_PREFIX}-ALL_RUNS_COMPARISON_WITH_BASE.csv\"\n",
    "final_comparison_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Aggregated results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OolIvYVfkEY"
   },
   "outputs": [],
   "source": [
    "# --- Advanced accuracy metrics -------------------------------\n",
    "\n",
    "YES, NO      = {\"yes\",\"y\",\"true\",\"correct\"}, {\"no\",\"n\",\"false\",\"incorrect\"}\n",
    "TOL, EPS     = 0.05, 1e-9                  # 5 %, tiny tolerance for 0\n",
    "PRED_PREFIX  = \"Pred_\"                     # rename if your columns differ\n",
    "\n",
    "# 2.  Helpers -------------------------------------------------------------------\n",
    "def to_scalar(v):\n",
    "    \"\"\"Clean & convert value  float | 'yes' | 'no' | None.\"\"\"\n",
    "    if pd.isna(v): return None\n",
    "    s = str(v).strip()\n",
    "    m = re.fullmatch(r\"\\[['\\\"]?(.*?)['\\\"]?\\]\", s)\n",
    "    if m: s = m.group(1)\n",
    "    s = s.lower().replace(\",\",\"\").replace(\"$\",\"\").replace(\"%\",\"\").strip()\n",
    "    if s in YES: return \"yes\"\n",
    "    if s in NO:  return \"no\"\n",
    "    for fn in (float, w2n.word_to_num):\n",
    "        try: return float(fn(s))\n",
    "        except Exception: pass\n",
    "    return None\n",
    "\n",
    "def relaxed(gt, pred):\n",
    "    return abs(gt - pred) <= (abs(gt) * TOL or EPS)\n",
    "\n",
    "# 3.  Basic checks --------------------------------------------------------------\n",
    "if not isinstance(globals().get(\"final_comparison_df\"), pd.DataFrame):\n",
    "    sys.exit(\"  `final_comparison_df` is missing.\")\n",
    "\n",
    "df = final_comparison_df.copy()\n",
    "df[\"GT_proc\"] = df[\"ground_truth\"].map(to_scalar)\n",
    "\n",
    "keep = df[\"GT_proc\"].isin([\"yes\",\"no\"]) | df[\"GT_proc\"].apply(lambda x: isinstance(x,(int,float)))\n",
    "df_filt = df[keep]\n",
    "if df_filt.empty:\n",
    "    sys.exit(\"  No yes/no/numeric groundtruth rows after processing.\")\n",
    "\n",
    "# Metrics per run -----------------------------------------------------------\n",
    "results = {}\n",
    "for col in [c for c in df.columns if c.startswith(PRED_PREFIX)]:\n",
    "    proc = f\"{col}_proc\"\n",
    "    df[proc] = df[col].map(to_scalar)\n",
    "\n",
    "    valid   = df[[\"GT_proc\", proc]].dropna()\n",
    "    numeric = valid[valid[\"GT_proc\"].apply(lambda x:isinstance(x,(int,float))) &\n",
    "                    valid[proc].apply(lambda x:isinstance(x,(int,float)))]\n",
    "\n",
    "    em  = 100 * (valid[\"GT_proc\"] == valid[proc]).mean() if not valid.empty else 0\n",
    "    rel = 100 * numeric.apply(lambda r: relaxed(r[\"GT_proc\"], r[proc]), axis=1).mean() if not numeric.empty else 0\n",
    "\n",
    "    run = col.replace(PRED_PREFIX, \"\")\n",
    "    results[run] = {\"EM (%)\": round(em,2),\n",
    "                    \"Relaxed Num (%)\": round(rel,2),\n",
    "                    \"# Numeric\": len(numeric),\n",
    "                    \"# Valid\": len(valid)}\n",
    "\n",
    "    print(f\"{run:<15} EM={em:6.2f}%  Relaxed={rel:6.2f}%  ({len(numeric)} num / {len(valid)} valid)\")\n",
    "\n",
    "# Summary & preview ---------------------------------------------------------\n",
    "summary = pd.DataFrame(results).T.sort_values(\"EM (%)\", ascending=False)\n",
    "display(summary)\n",
    "display(df.head())\n",
    "\n",
    "# Save to CSV ---------------------------------------------------------------\n",
    "BASE_OUTPUT_DIR = Path(globals().get(\"BASE_OUTPUT_DIR\", \"./outputs\"))\n",
    "BASE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "prefix = globals().get(\"OUTPUT_FOLDER_PREFIX\", \"RUNS\")\n",
    "\n",
    "# Save the full dataframe\n",
    "out_file = BASE_OUTPUT_DIR / f\"{prefix}-ALL_RUNS_COMPARISON_WITH_PROCESSED.csv\"\n",
    "df.to_csv(out_file, index=False)\n",
    "print(\"  Saved full DataFrame:\", out_file)\n",
    "\n",
    "# Save the summary metrics dataframe\n",
    "summary_file = BASE_OUTPUT_DIR / f\"{prefix}-METRICS_SUMMARY.csv\"\n",
    "summary.to_csv(summary_file, index=True)\n",
    "print(\"  Saved metrics summary:\", summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUXl8q28jK48"
   },
   "outputs": [],
   "source": [
    "# Prepare and clean the summary DataFrame\n",
    "def clean_summary(summary):\n",
    "    df = summary.copy()\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"Model\"}, inplace=True)\n",
    "\n",
    "    df[\"is_original\"] = df[\"Model\"].str.contains(\"-Original\")\n",
    "    df[\"base_model\"] = df[\"Model\"].apply(lambda x: re.sub(r\"-(qlora|lora|full)(-alpha-\\d+)?-Original$\", \"-Original\", x))\n",
    "\n",
    "    df_filtered = df[~df[\"is_original\"] | ~df.duplicated(\"base_model\")].copy()\n",
    "    df_filtered.loc[df_filtered[\"is_original\"], \"Model\"] = df_filtered.loc[df_filtered[\"is_original\"], \"base_model\"]\n",
    "\n",
    "    df_filtered.drop_duplicates(subset=[\"Model\"], inplace=True)\n",
    "\n",
    "    df_filtered.drop(columns=[\"is_original\", \"base_model\"], inplace=True)\n",
    "\n",
    "    df_filtered.sort_values(by=\"Model\", inplace=True)\n",
    "    df_filtered.reset_index(drop=True, inplace=True)\n",
    "    df_filtered[\"Average Accuracy (%)\"] = (df_filtered[\"EM (%)\"] + df_filtered[\"Relaxed Num (%)\"]) / 2\n",
    "    return df_filtered\n",
    "\n",
    "# Compare tuned models to originals and include originals in output\n",
    "def compute_improvements(df_filtered):\n",
    "    true_originals = df_filtered[\n",
    "        df_filtered[\"Model\"].str.endswith(\"-Original\") &\n",
    "        ~df_filtered[\"Model\"].str.contains(\"-(lora|qlora|full)\", regex=True)\n",
    "    ].copy()\n",
    "\n",
    "    tuneds = df_filtered[~df_filtered[\"Model\"].str.endswith(\"-Original\")].copy()\n",
    "\n",
    "    def normalize_model_name(name):\n",
    "        name = re.sub(r\"-(qlora|lora|full)(-alpha(-\\d+)?)*-tuned.*\", \"\", name)\n",
    "        name = re.sub(r\"-Original$\", \"\", name)\n",
    "        return name\n",
    "\n",
    "    tuneds[\"base_model\"] = tuneds[\"Model\"].apply(normalize_model_name)\n",
    "    true_originals[\"base_model\"] = true_originals[\"Model\"].apply(normalize_model_name)\n",
    "\n",
    "    originals_deduped = true_originals.drop_duplicates(subset=\"base_model\", keep=\"first\")\n",
    "\n",
    "    comparison = pd.merge(\n",
    "        tuneds,\n",
    "        originals_deduped[[\"base_model\", \"Average Accuracy (%)\"]],\n",
    "        on=\"base_model\",\n",
    "        suffixes=(\"\", \"_Original\"),\n",
    "        how=\"left\"\n",
    "    )\n",
    "    # compute Improvement score\n",
    "    comparison[\"Improvement (%)\"] = np.where(\n",
    "        comparison[\"Average Accuracy (%)_Original\"] == 0,\n",
    "        comparison[\"Average Accuracy (%)\"] - comparison[\"Average Accuracy (%)_Original\"],\n",
    "        ((comparison[\"Average Accuracy (%)\"] / comparison[\"Average Accuracy (%)_Original\"]) - 1) * 100\n",
    "    )\n",
    "    comparison = comparison.drop_duplicates(subset=[\"Model\"])\n",
    "\n",
    "    originals_to_append = originals_deduped.copy()\n",
    "    originals_to_append[\"Improvement (%)\"] = 0.0\n",
    "    originals_to_append.rename(columns={\"Average Accuracy (%)\": \"Average Accuracy (%)_Original\"}, inplace=True)\n",
    "    originals_to_append[\"Average Accuracy (%)\"] = originals_to_append[\"Average Accuracy (%)_Original\"]\n",
    "\n",
    "    columns = list(comparison.columns)\n",
    "    originals_to_append = originals_to_append[columns]\n",
    "\n",
    "    final_df = pd.concat([comparison, originals_to_append], ignore_index=True)\n",
    "    final_df.sort_values(by=\"Improvement (%)\", ascending=False, inplace=True)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "df_filtered = clean_summary(summary)\n",
    "comparison_sorted = compute_improvements(df_filtered)\n",
    "out_file = BASE_OUTPUT_DIR / f\"{prefix}-final-ranking.csv\"\n",
    "comparison_sorted.to_csv(out_file, index=False)\n",
    "display(comparison_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xh3ES_Khp-UA"
   },
   "outputs": [],
   "source": [
    "def load_runs(base_dir, prefix, filter_mode=\"base\"):\n",
    "    search_pattern = f\"{prefix}*/trainer_state.json\"\n",
    "    state_files = list(base_dir.glob(search_pattern))\n",
    "\n",
    "    if not state_files:\n",
    "        raise FileNotFoundError(\"No trainer state files found.\")\n",
    "\n",
    "    run_data = []\n",
    "    max_loss = 0\n",
    "\n",
    "    for file_path in state_files:\n",
    "        folder_name = file_path.parent.name\n",
    "        run_label = folder_name.replace(f\"{prefix}-\", \"\")\n",
    "\n",
    "        if filter_mode == \"base\":\n",
    "            # Only folders like \"SmolVLM-256M-Instruct-lora-tuned\" (not extra-tuned)\n",
    "            if not re.fullmatch(r\".*-tuned\", run_label):\n",
    "                continue\n",
    "        elif filter_mode == \"finetuned\":\n",
    "            # Match folders with -tuned-xxx or _tuned_yyy or anything more than \"-tuned\"\n",
    "            if re.fullmatch(r\".*-tuned\", run_label):\n",
    "                continue\n",
    "        else:\n",
    "            raise ValueError(\"filter_mode must be 'base' or 'finetuned'\")\n",
    "\n",
    "        # Determine method\n",
    "        if \"-full-\" in folder_name:\n",
    "            method = \"Full\"\n",
    "        elif \"-qlora-\" in folder_name:\n",
    "            method = \"QLoRA\"\n",
    "        elif \"-lora-\" in folder_name:\n",
    "            method = \"LoRA\"\n",
    "        else:\n",
    "            method = \"LoRA\"\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            log_history = json.load(f).get(\"log_history\", [])\n",
    "\n",
    "        df = pd.DataFrame(log_history)\n",
    "        train_df = df[df[\"loss\"].notna() & df[\"step\"].notna()]\n",
    "        val_df = df[df[\"eval_loss\"].notna() & df[\"step\"].notna()]\n",
    "\n",
    "        if not train_df.empty:\n",
    "            max_loss = max(max_loss, train_df[\"loss\"].max())\n",
    "        if not val_df.empty:\n",
    "            max_loss = max(max_loss, val_df[\"eval_loss\"].max())\n",
    "\n",
    "        # Strip suffix for cleaner display\n",
    "        clean_label = re.sub(r\"-tuned$\", \"\", run_label)\n",
    "        run_data.append((clean_label, train_df, val_df, method))\n",
    "\n",
    "    run_data.sort(key=lambda x: x[0])\n",
    "    return run_data, max_loss\n",
    "\n",
    "\n",
    "def set_scientific_plot_style():\n",
    "    \"\"\"Set publication-quality plot style with advanced settings\"\"\"\n",
    "    # Use academic-focused style\n",
    "    plt.style.use('seaborn-v0_8-paper')\n",
    "\n",
    "    # Set color palette - scientific publication friendly\n",
    "    colors = sns.color_palette(\"viridis\", 8)\n",
    "\n",
    "    # Configure matplotlib with better defaults for scientific plots\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'serif',\n",
    "        # Use default serif fonts available on most systems\n",
    "        'font.serif': ['DejaVu Serif', 'Bitstream Vera Serif', 'serif'],\n",
    "        'font.size': 10,\n",
    "        'axes.labelsize': 11,\n",
    "        'axes.titlesize': 12,\n",
    "        'xtick.labelsize': 9,\n",
    "        'ytick.labelsize': 9,\n",
    "        'legend.fontsize': 9,\n",
    "        'axes.linewidth': 0.8,\n",
    "        'grid.linewidth': 0.6,\n",
    "        'lines.linewidth': 1.5,\n",
    "        'lines.markersize': 5,\n",
    "        'axes.prop_cycle': cycler('color', colors),\n",
    "        'axes.spines.top': False,\n",
    "        'axes.spines.right': False,\n",
    "        'axes.grid': True,\n",
    "        'grid.alpha': 0.3,\n",
    "        'figure.figsize': (8, 6),\n",
    "        'figure.dpi': 300,\n",
    "        'savefig.dpi': 300,\n",
    "        'savefig.bbox': 'tight',\n",
    "        'savefig.pad_inches': 0.05,\n",
    "    })\n",
    "\n",
    "\n",
    "def get_method_colors():\n",
    "    \"\"\"Return consistent colors by method type\"\"\"\n",
    "    return {\n",
    "        \"Full\": \"#1f77b4\",  # blue\n",
    "        \"LoRA\": \"#2ca02c\",  # green\n",
    "        \"QLoRA\": \"#d62728\"  # red\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_runs(run_data, output_path, title=\"Loss Curves\", figsize=None):\n",
    "    if not run_data:\n",
    "        print(\"No runs to plot.\")\n",
    "        return\n",
    "\n",
    "    # Set scientific plot style\n",
    "    set_scientific_plot_style()\n",
    "\n",
    "    # Get method-specific colors\n",
    "    method_colors = get_method_colors()\n",
    "\n",
    "    # Calculate grid layout based on number of runs\n",
    "    ncols = min(6, len(run_data))\n",
    "    nrows = math.ceil(len(run_data) / ncols)\n",
    "\n",
    "    # Use figsize if provided, otherwise calculate based on grid\n",
    "    if figsize is None:\n",
    "        figsize = (ncols * 3.2, nrows * 2.5)\n",
    "\n",
    "    # Create figure with more sophisticated layout using GridSpec\n",
    "    fig = plt.figure(figsize=figsize, constrained_layout=True)\n",
    "    gs = GridSpec(nrows, ncols, figure=fig)\n",
    "\n",
    "    # Track y-limits to standardize across subplots\n",
    "    y_min, y_max = float('inf'), float('-inf')\n",
    "\n",
    "    # Create subplots and plot data\n",
    "    axes = []\n",
    "    for i, (label, train_df, val_df, method) in enumerate(run_data):\n",
    "        row, col = i // ncols, i % ncols\n",
    "        ax = fig.add_subplot(gs[row, col])\n",
    "        axes.append(ax)\n",
    "\n",
    "        # Color based on method\n",
    "        method_color = method_colors.get(method, \"#ff7f0e\")  # orange as default\n",
    "\n",
    "        # Plot with enhanced styling\n",
    "        if not train_df.empty:\n",
    "            ax.plot(\n",
    "                train_df[\"step\"], train_df[\"loss\"],\n",
    "                label=\"Train\",\n",
    "                color=method_color,\n",
    "                linestyle=\"-\",\n",
    "                marker=\"o\",\n",
    "                markersize=3,\n",
    "                markevery=max(1, len(train_df)//8),\n",
    "                alpha=0.95\n",
    "            )\n",
    "\n",
    "            # Update y limits\n",
    "            y_min = min(y_min, train_df[\"loss\"].min() * 0.95)\n",
    "            y_max = max(y_max, train_df[\"loss\"].max() * 1.05)\n",
    "\n",
    "        if not val_df.empty:\n",
    "            ax.plot(\n",
    "                val_df[\"step\"], val_df[\"eval_loss\"],\n",
    "                label=\"Val\",\n",
    "                color=method_color,\n",
    "                linestyle=\"--\",\n",
    "                marker=\"s\",\n",
    "                markersize=3,\n",
    "                markevery=max(1, len(val_df)//8),\n",
    "                alpha=0.85\n",
    "            )\n",
    "\n",
    "            # Update y limits\n",
    "            y_min = min(y_min, val_df[\"eval_loss\"].min() * 0.95)\n",
    "            y_max = max(y_max, val_df[\"eval_loss\"].max() * 1.05)\n",
    "\n",
    "        # Format tick labels\n",
    "        ax.ticklabel_format(axis='y', style='sci', scilimits=(-2, 2))\n",
    "\n",
    "        # Add method indicators with colored backgrounds\n",
    "        ax.set_title(f\"{label}\", fontsize=10, pad=6)\n",
    "\n",
    "        # Add method indicator as a colored text label in top-right\n",
    "        ax.text(\n",
    "            0.97, 0.07, method,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=8,\n",
    "            ha='right',\n",
    "            va='center',\n",
    "            bbox=dict(\n",
    "                boxstyle='round,pad=0.3',\n",
    "                facecolor=method_color,\n",
    "                alpha=0.2,\n",
    "                edgecolor=method_color,\n",
    "                linewidth=0.5\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Add small legend in each subplot for train/val distinction\n",
    "        ax.legend(\n",
    "            ['Train', 'Val'],\n",
    "            loc='upper right',\n",
    "            fontsize=7,\n",
    "            framealpha=0.5,\n",
    "            handlelength=1.0,\n",
    "            borderpad=0.2\n",
    "        )\n",
    "\n",
    "        # Style the grid\n",
    "        ax.grid(True, linestyle=':', alpha=0.3, color='gray')\n",
    "\n",
    "    # Standardize y-limits across all plots if we have data\n",
    "    if y_min != float('inf') and y_max != float('-inf'):\n",
    "        for ax in axes:\n",
    "            ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    # Hide unused axes\n",
    "    for ax in axes[len(run_data):]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Add suptitle with enhanced styling\n",
    "    fig.suptitle(\n",
    "        title,\n",
    "        fontsize=14,\n",
    "        y=0.98,\n",
    "        fontweight='bold',\n",
    "        bbox=dict(\n",
    "            facecolor='white',\n",
    "            alpha=0.8,\n",
    "            edgecolor='lightgray',\n",
    "            boxstyle='round,pad=0.5'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add common axis labels\n",
    "    fig.supxlabel(\"Training Steps\", fontsize=11, y=0.02)\n",
    "    fig.supylabel(\"Loss\", fontsize=11, x=0.02)\n",
    "\n",
    "    # Tight layout\n",
    "    plt.tight_layout(rect=[0.02, 0.05, 0.98, 0.95])\n",
    "\n",
    "    # Add watermark with timestamp/version info\n",
    "    fig.text(\n",
    "        0.98, 0.01, f\"Generated: {pd.Timestamp.now().strftime('%Y-%m-%d')}\",\n",
    "        ha='right', va='bottom', fontsize=6, color='gray', alpha=0.7\n",
    "    )\n",
    "\n",
    "    # Save with high resolution\n",
    "    fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    print(f\"Enhanced plot saved to {output_path}\")\n",
    "\n",
    "    # Display in Jupyter if running in a notebook environment\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if get_ipython() is not None:\n",
    "            plt.show()\n",
    "    except (ImportError, NameError):\n",
    "        pass\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def aggregate_and_plot_loss_curves():\n",
    "    print(\"--- Plotting Base Runs ---\")\n",
    "    run_data, _ = load_runs(BASE_OUTPUT_DIR, OUTPUT_FOLDER_PREFIX, filter_mode=\"base\")\n",
    "    output_path = BASE_OUTPUT_DIR / f\"{OUTPUT_FOLDER_PREFIX}_base_loss_curves.pdf\"\n",
    "\n",
    "    # Use PDF for publication quality\n",
    "    fig = plot_runs(\n",
    "        run_data,\n",
    "        output_path,\n",
    "        title=\"Training & Validation Losses During Fine-Tuning\"\n",
    "    )\n",
    "\n",
    "    # Save additional PNG for quick viewing\n",
    "    png_path = output_path.with_suffix('.png')\n",
    "    fig.savefig(png_path, dpi=300)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def aggregate_and_plot_finetuned_loss_curves():\n",
    "    print(\"--- Plotting Fine-tuned Runs ---\")\n",
    "    run_data, _ = load_runs(BASE_OUTPUT_DIR, OUTPUT_FOLDER_PREFIX, filter_mode=\"finetuned\")\n",
    "    output_path = BASE_OUTPUT_DIR / f\"{OUTPUT_FOLDER_PREFIX}_finetuned_loss_curves.pdf\"\n",
    "\n",
    "    fig = plot_runs(\n",
    "        run_data,\n",
    "        output_path,\n",
    "        title=\"Hyperparameter Tuning: Training & Validation Losses\"\n",
    "    )\n",
    "\n",
    "    # Save additional PNG for quick viewing\n",
    "    png_path = output_path.with_suffix('.png')\n",
    "    fig.savefig(png_path, dpi=300)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# Run both\n",
    "aggregate_and_plot_loss_curves()\n",
    "aggregate_and_plot_finetuned_loss_curves()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06bd36c53ad14d7d891e84a4798b632a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c6685c0922246f3a6a11c3bba62ea11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "246b6fd44d954f2d957c03ef681be01f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74b4488a1d5b4c7d8b93542de528ffd8",
      "placeholder": "",
      "style": "IPY_MODEL_06bd36c53ad14d7d891e84a4798b632a",
      "value": "7/7[00:01&lt;00:00,7.09it/s]"
     }
    },
    "318fa65bb4b3451f848b9aabbc1c3dec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d28f46fc556f4ad1be066066518db2d6",
      "placeholder": "",
      "style": "IPY_MODEL_1c6685c0922246f3a6a11c3bba62ea11",
      "value": "ProcessingJSONfiles:100%"
     }
    },
    "74b4488a1d5b4c7d8b93542de528ffd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79d2e1aaf7c6466db7fc1148ae0a2a20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "95ee650e26524c2b95576af19956da20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8859dca2116420b953ccc99bc2eca08",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79d2e1aaf7c6466db7fc1148ae0a2a20",
      "value": 7
     }
    },
    "d28f46fc556f4ad1be066066518db2d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4ede4870e1141c6bd20c881c7542561": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_318fa65bb4b3451f848b9aabbc1c3dec",
       "IPY_MODEL_95ee650e26524c2b95576af19956da20",
       "IPY_MODEL_246b6fd44d954f2d957c03ef681be01f"
      ],
      "layout": "IPY_MODEL_f70adc76a4ad409e9ac3eff3f36931d6"
     }
    },
    "e8859dca2116420b953ccc99bc2eca08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f70adc76a4ad409e9ac3eff3f36931d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
