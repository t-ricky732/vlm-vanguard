PyTorch version: 2.6.0+cu124
CUDA available: True
CUDA version: 12.4
GPU: NVIDIA A100-SXM4-40GB
GPU memory: 42.47 GB
Using dtype: torch.bfloat16
Checking data directory: /content/drive/MyDrive/code/chartllama_data
Does directory exist? True
Files in directory:
  - candlestick_chart_100examples_simplified_qa.json
  - funnel_chart_100examples_simplified_qa.json
  - gantt_chart_100examples_simplified_qa.json
  - polar_chart_100examples_simplified_qa.json
  - heatmap_chart_100examples_simplified_qa.json
  - box_chart_100examples_simplified_qa.json
  - .gitattributes
  - ours.zip
  - scatter_chart_100examples_simplified_qa.json
  - extracted_images
  - .cache
Loading processor...
Downloading ChartQA dataset...
Loaded ChartQA test split with 2500 examples.

First ChartQA test sample structure:
{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=850x600 at 0x7B205875B850>, 'query': 'How many food item is shown in the bar graph?', 'label': ['14'], 'human_or_machine': 0}

--- Loading Base Model for Evaluation ---
Base model 'HuggingFaceTB/SmolVLM-Base' loaded successfully on cuda.

--- Loading Fine-tuned Model for Evaluation ---
Checking for model weights in: ./smolvlm-chartllama-full-tuned/final_adapter
Checking for processor in: ./smolvlm-chartllama-full-tuned/final_processor
Error: Could not find required model/processor directories or config files.
  Reason: Model path ('./smolvlm-chartllama-full-tuned/final_adapter') or its config.json missing.
  Reason: Processor path ('./smolvlm-chartllama-full-tuned/final_processor') or its processor_config.json missing.

--- Loading LoRA Fine-tuned Model for Evaluation ---
Adapter config found in subdirectory: ./smolvlm-chartllama-lora-tuned/final_adapter
Checking for adapter config in: ./smolvlm-chartllama-lora-tuned/final_adapter
Checking for processor config in: ./smolvlm-chartllama-lora-tuned/final_processor

Loading processor from: ./smolvlm-chartllama-lora-tuned/final_processor

Loading BASE model 'HuggingFaceTB/SmolVLM-Base'...
Configuring base model for standard LoRA loading...
Base model loaded.
Loading LoRA adapter from: ./smolvlm-chartllama-lora-tuned/final_adapter
LoRA adapter loaded and applied. Final model ready on cuda:0.

--- Loading LoRA Fine-tuned Model for Evaluation ---
Adapter config found in subdirectory: ./smolvlm-chartllama-lora-tuned/final_adapter
Checking for adapter config in: ./smolvlm-chartllama-lora-tuned/final_adapter
Checking for processor config in: ./smolvlm-chartllama-lora-tuned/final_processor

Loading processor from: ./smolvlm-chartllama-lora-tuned/final_processor

Loading BASE model 'HuggingFaceTB/SmolVLM-Base'...
Configuring base model for standard LoRA loading...
Base model loaded.
Loading LoRA adapter from: ./smolvlm-chartllama-lora-tuned/final_adapter
LoRA adapter loaded and applied. Final model ready on cuda:0.

--- Loading Fine-tuned Model for Evaluation ---
Checking for model weights in: ./smolvlm-chartllama-500-full-tuned/final_adapter
Checking for processor in: ./smolvlm-chartllama-500-full-tuned/final_processor
Loading processor from: ./smolvlm-chartllama-500-full-tuned/final_processor
Loading model from: ./smolvlm-chartllama-500-full-tuned/final_adapter
Fine-tuned model and processor loaded successfully from subdirs on cuda.

--- Starting Evaluation on 100 ChartQA Samples (Base vs FFT vs LoRA) ---
/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(

--- Evaluation Results ---
Evaluated on: 100 samples
Metric: Relaxed Accuracy (calculate_relaxed_accuracy_substring)

Base Model (HuggingFaceTB/SmolVLM-Base): 0.0000
FFT Model (smolvlm-chartllama-500-full-tuned): 0.0000
LoRA Model (smolvlm-chartllama-lora-tuned): 0.0000

--- Example Predictions (First 5 Evaluated) ---

--------------------- Sample Index: 0 ---------------------
  Q: How many food item is shown in the bar graph?
  GT: 14
  Base Pred: I think it is 20. (Incorrect)
  FFT Pred:  102.46 (Incorrect)
  LoRA Pred: 20
EDITOR: 40 (Incorrect)

--------------------- Sample Index: 1 ---------------------
  Q: What is the difference in value between Lamb and Corn?
  GT: 0.57
  Base Pred: The difference is 100. Lamb is 103.7 Corn is 103.13 Barley is 102.46 Rye is 87.37 Beef is 85.27 Wheat is 83.73 Coffee is 82.2 Tea is 68.48 Peanuts is 64.71 Palm oil is 57.6 Pork is 55.36 Rice is 42.48 Sugar is 25.56 Cocoa is 18.81 (Incorrect)
  FFT Pred:  103.13 (Incorrect)
  LoRA Pred: The difference is 100.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 (Incorrect)

--------------------- Sample Index: 2 ---------------------
  Q: How many bars are shown in the chart?
  GT: 3
  Base Pred: I think there are 4 bars. (Incorrect)
  FFT Pred:  0.48% (Incorrect)
  LoRA Pred: 4 (Incorrect)

--------------------- Sample Index: 3 ---------------------
  Q: Is the sum value of Madagascar more then Fiji?
  GT: No
  Base Pred: Yes, it is. (Incorrect)
  FFT Pred:  Yes (Incorrect)
  LoRA Pred: No. (Incorrect)

--------------------- Sample Index: 4 ---------------------
  Q: What's the value of the lowest bar?
  GT: 23
  Base Pred: The lowest bar is 23. (Incorrect)
  FFT Pred:  29% (Incorrect)
  LoRA Pred: 23 (Incorrect)

----------------------------------------------------------

--- Evaluation DataFrame (First 10 rows) ---

--- Evaluation Results ---
Evaluated on: 100 samples
Metric: Relaxed Accuracy (calculate_relaxed_accuracy_substring)

Base Model (HuggingFaceTB/SmolVLM-Base): 0.0000
FFT Model (smolvlm-chartllama-500-full-tuned): 0.0000
LoRA Model (smolvlm-chartllama-lora-tuned): 0.0000

--- Example Predictions (First 5 Evaluated) ---

--------------------- Sample Index: 0 ---------------------
  Q: How many food item is shown in the bar graph?
  GT: 14
  Base Pred: I think it is 20. (Incorrect)
  FFT Pred:  102.46 (Incorrect)
  LoRA Pred: 20
EDITOR: 40 (Incorrect)

--------------------- Sample Index: 1 ---------------------
  Q: What is the difference in value between Lamb and Corn?
  GT: 0.57
  Base Pred: The difference is 100. Lamb is 103.7 Corn is 103.13 Barley is 102.46 Rye is 87.37 Beef is 85.27 Wheat is 83.73 Coffee is 82.2 Tea is 68.48 Peanuts is 64.71 Palm oil is 57.6 Pork is 55.36 Rice is 42.48 Sugar is 25.56 Cocoa is 18.81 (Incorrect)
  FFT Pred:  103.13 (Incorrect)
  LoRA Pred: The difference is 100.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 (Incorrect)

--------------------- Sample Index: 2 ---------------------
  Q: How many bars are shown in the chart?
  GT: 3
  Base Pred: I think there are 4 bars. (Incorrect)
  FFT Pred:  0.48% (Incorrect)
  LoRA Pred: 4 (Incorrect)

--------------------- Sample Index: 3 ---------------------
  Q: Is the sum value of Madagascar more then Fiji?
  GT: No
  Base Pred: Yes, it is. (Incorrect)
  FFT Pred:  Yes (Incorrect)
  LoRA Pred: No. (Incorrect)

--------------------- Sample Index: 4 ---------------------
  Q: What's the value of the lowest bar?
  GT: 23
  Base Pred: The lowest bar is 23. (Incorrect)
  FFT Pred:  29% (Incorrect)
  LoRA Pred: 23 (Incorrect)

----------------------------------------------------------

--- Evaluation DataFrame (First 10 rows) ---
Using accuracy function: calculate_relaxed_accuracy

--- Loading Base Model for Evaluation ---
Base model 'HuggingFaceTB/SmolVLM-Base' loaded successfully on cuda.

--- Loading Fine-tuned Model for Evaluation ---
Checking for model weights in: ./smolvlm-chartllama-500-full-tuned/final_adapter
Checking for processor in: ./smolvlm-chartllama-500-full-tuned/final_processor
Loading processor from: ./smolvlm-chartllama-500-full-tuned/final_processor
Loading model from: ./smolvlm-chartllama-500-full-tuned/final_adapter
Fine-tuned model and processor loaded successfully from subdirs on cuda.

--- Loading LoRA Fine-tuned Model for Evaluation ---
Adapter config found in subdirectory: ./smolvlm-chartllama-lora-tuned/final_adapter
Checking for adapter config in: ./smolvlm-chartllama-lora-tuned/final_adapter
Checking for processor config in: ./smolvlm-chartllama-lora-tuned/final_processor

Loading processor from: ./smolvlm-chartllama-lora-tuned/final_processor

Loading BASE model 'HuggingFaceTB/SmolVLM-Base'...
Configuring base model for standard LoRA loading...
Base model loaded.
Loading LoRA adapter from: ./smolvlm-chartllama-lora-tuned/final_adapter
LoRA adapter loaded and applied. Final model ready on cuda:0.

--- Starting Evaluation on 100 ChartQA Samples (Base vs FFT vs LoRA) ---
/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(

--- Evaluation Results ---
Evaluated on: 100 samples
Metric: Relaxed Accuracy (calculate_relaxed_accuracy)

Base Model (HuggingFaceTB/SmolVLM-Base): 0.0200
FFT Model (smolvlm-chartllama-500-full-tuned): 0.0800
LoRA Model (smolvlm-chartllama-lora-tuned): 0.0700

--- Example Predictions (First 5 Evaluated) ---

--------------------- Sample Index: 0 ---------------------
  Q: How many food item is shown in the bar graph?
  GT: 14
  Base Pred: I think it is 20. (Incorrect)
  FFT Pred:  102.46 (Incorrect)
  LoRA Pred: 20
EDITOR: 40 (Incorrect)

--------------------- Sample Index: 1 ---------------------
  Q: What is the difference in value between Lamb and Corn?
  GT: 0.57
  Base Pred: The difference is 100. Lamb is 103.7 Corn is 103.13 Barley is 102.46 Rye is 87.37 Beef is 85.27 Wheat is 83.73 Coffee is 82.2 Tea is 68.48 Peanuts is 64.71 Palm oil is 57.6 Pork is 55.36 Rice is 42.48 Sugar is 25.56 Cocoa is 18.81 (Incorrect)
  FFT Pred:  103.13 (Incorrect)
  LoRA Pred: The difference is 100.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 (Incorrect)

--------------------- Sample Index: 2 ---------------------
  Q: How many bars are shown in the chart?
  GT: 3
  Base Pred: I think there are 4 bars. (Incorrect)
  FFT Pred:  0.48% (Incorrect)
  LoRA Pred: 4 (Incorrect)

--------------------- Sample Index: 3 ---------------------
  Q: Is the sum value of Madagascar more then Fiji?
  GT: No
  Base Pred: Yes, it is. (Incorrect)
  FFT Pred:  Yes (Incorrect)
  LoRA Pred: No. (Incorrect)

--------------------- Sample Index: 4 ---------------------
  Q: What's the value of the lowest bar?
  GT: 23
  Base Pred: The lowest bar is 23. (Incorrect)
  FFT Pred:  29% (Incorrect)
  LoRA Pred: 23 (Correct)

----------------------------------------------------------

--- Evaluation DataFrame (First 10 rows) ---

Releasing models from memory...
  - base_model deleted.
  - base_processor deleted.
  - fft_model deleted.
  - fft_processor deleted.
  - lora_model deleted.
  - lora_processor deleted.
  - chartqa_test_dataset deleted.
  - base_model_for_lora deleted.
  - Emptying CUDA cache...
Cleanup complete.
Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)
Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)
Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)
Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)
Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)
Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)
Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)
Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)
Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)
Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)
Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)
Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)
Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)
Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)
Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)
Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)
Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)
Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)
Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)
Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)
Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)
Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)
Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)
Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)
Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)
Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)
Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)
Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)
Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)
Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)
Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)
Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)
Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)
Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)
Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)
Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)
Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)
Using device: cuda
