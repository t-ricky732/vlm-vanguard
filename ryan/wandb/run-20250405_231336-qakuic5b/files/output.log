PyTorch version: 2.6.0+cu124
CUDA available: True
CUDA version: 12.4
GPU: NVIDIA A100-SXM4-40GB
GPU memory: 42.47 GB
Using dtype: torch.bfloat16
Loading processor...
/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning:
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
Configuring model for QLoRA (8-bit quantization)...
Loading model 'HuggingFaceTB/SmolVLM-Base'...
`low_cpu_mem_usage` was None, now default to True since model is quantized.
Model loaded in 5.08 seconds
Preparing model for LoRA training...
Applying prepare_model_for_kbit_training for QLoRA...
trainable params: 21,073,920 || all params: 2,267,346,800 || trainable%: 0.9295
Checking data directory: /content/drive/MyDrive/code/chartllama_data
Does directory exist? True
Files in directory:
  - funnel_chart_100examples_simplified_qa.json
  - ours.zip
  - heatmap_chart_100examples_simplified_qa.json
  - gantt_chart_100examples_simplified_qa.json
  - scatter_chart_100examples_simplified_qa.json
  - polar_chart_100examples_simplified_qa.json
  - box_chart_100examples_simplified_qa.json
  - .gitattributes
  - candlestick_chart_100examples_simplified_qa.json
  - extracted_images
  - .cache
Loading dataset using custom ChartDataset...
Loading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:15<00:00,  2.23s/it]
Total samples: 980
Training samples: 784
Validation samples: 98
Test samples: 98
--- Displaying Item Index: 654 ---
Original ID: ours_simplified_qa_9_6
Chart Type: polar
Question: What type of chart is used to represent the data?
<image>...
Answer: Polar bar chart
Image Path (from JSON): ours/polar_chart/png/polar_chart_100examples_9.png
--------------------------------------
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
Initializing Trainer...
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Starting training...
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
Initializing Trainer...
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Starting training...

--- Collator: Shapes received from __getitem__ ---
  Item 0: input_ids=torch.Size([1570]), labels=torch.Size([1])
  >>> WARNING: Item 0 has mismatched/invalid length BEFORE padding!
  Item 1: input_ids=torch.Size([1574]), labels=torch.Size([10])
  >>> WARNING: Item 1 has mismatched/invalid length BEFORE padding!
  >>> Problem identified: __getitem__ is returning items with mismatched input/label lengths.
--- Collator: Calculated max_length = 1574 ---
--- Collator: Shapes before torch.stack ---
  labels_padded shapes: [torch.Size([5]), torch.Size([10])]
  >>> ERROR DETECTED: Not all labels have the same length AFTER padding logic!

!!! Runtime Error during torch.stack !!!
Error message: stack expects each tensor to be equal size, but got [5] at entry 0 and [10] at entry 1
Shapes that caused the error:
  labels_padded shapes: [torch.Size([5]), torch.Size([10])]
  input_ids_padded shapes: [torch.Size([1574]), torch.Size([1574])]
