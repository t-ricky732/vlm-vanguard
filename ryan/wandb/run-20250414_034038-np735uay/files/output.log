WandB initialized.
--- WandB Setup Complete ---

--- Defining Data Loading Function ---
Data loading function defined.

--- Loading and Splitting Data ---
Loading data from: /content/drive/MyDrive/code/chartllama_data
Found 7 JSON files in /content/drive/MyDrive/code/chartllama_data

Loaded 980 raw examples. Skipped 0 invalid/missing samples.

Raw data loaded and split.
Train samples: 882
Eval samples (Validation): 98

Sample train data point (raw):
{'id': 'ours_simplified_qa_59_0', 'question': 'What is the theme of the chart?', 'answer': 'Variation in the Consumer Price Index (CPI)', 'image_path': '/content/drive/MyDrive/code/chartllama_data/ours/candlestick_chart/png/candlestick_chart_100examples_59.png'}

--- Loading Model and Processor for Training ---
Loading processor for model: HuggingFaceTB/SmolVLM-Instruct
/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning:
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
Processor loaded.

Configuring model loading...
Configuring model for LoRA (dtype: torch.bfloat16).
Loading config for HuggingFaceTB/SmolVLM-Instruct...
Config does not have 'attn_implementation' attribute.
Loading model 'HuggingFaceTB/SmolVLM-Instruct' with configuration...

Model loaded.
  - Device Map: {'': 0}
  - Attention Implementation: N/A
  - Use Cache: False

Applying PEFT/LoRA configuration...
Enabling gradient checkpointing for LoRA.
Wrapping model with get_peft_model...
trainable params: 10,946,584 || all params: 2,257,219,464 || trainable%: 0.4850

--- Model and Processor Setup Complete ---

--- Defining Formatting Function & Data Collator ---
Collator Initialized: Found image token ID: 49153

Custom Collator instantiated.

--- Configuring Training Arguments ---
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
SFTConfig set.

--- Initializing SFTTrainer ---
All components ready, initializing trainer...
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
SFTTrainer initialized successfully.

--- Checking if Training Should Be Skipped ---

Final output files not found or incomplete on Drive.
  - Model Check: False (Checked dir: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/final_model)
  - Processor Check: False (Checked dir: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/final_processor)
--- Proceeding with Training ---
Starting training run...
Ensuring output directory exists: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned
Ensuring final model directory exists: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/final_model
Ensuring final processor directory exists: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/final_processor
Pausing briefly for Drive sync...
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
Training finished in 47.20 minutes.

Saving final model/adapter to: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/final_model
Saving processor to: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/final_processor
Processor saving initiated.
Verifying processor save...
Processor config file verified.

Logging metrics and saving state...
***** train metrics *****
  total_flos               = 43927482GF
  train_loss               =     0.9094
  train_runtime            = 0:47:06.15
  train_samples_per_second =      0.936
  train_steps_per_second   =      0.058
Metrics and state saved successfully.

Generating and saving loss curves...
Loss curve plot saved to: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/loss_curves_SmolVLM-Instruct_lora-tuned_1744604891.png

Cleaning up trainer object...

--- Training Step Execution Finished ---

--- Setting up Evaluation Environment ---
Fine-tuned model will be loaded from: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/final_model
Processor will be loaded from: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/final_processor
Base model will be loaded from Hub ID: HuggingFaceTB/SmolVLM-Instruct
Results will be saved to: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/chartqa_evaluation_results_comparison.json

Loading processor from /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/final_processor...
Processor loaded from Drive.

Loading fine-tuned model/adapter from /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/final_model...
Loaded config from fine-tuned model directory: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/final_model
Pad token ID from loaded processor: 2
Modifying text_config within base config.
Base model config pad_token_id already matches loaded processor (2).
Loading base model 'HuggingFaceTB/SmolVLM-Instruct' for LoRA adapter merging (using potentially modified config)...
Loading LoRA adapter from /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/final_model...
LoRA/QLoRA model loaded.
Fine-tuned model ready. Device map: {'': 0}

Loading original base model 'HuggingFaceTB/SmolVLM-Instruct' from Hub for comparison...
Loading base model config for HuggingFaceTB/SmolVLM-Instruct...
Base model config has no attn_implementation attr, adding to kwargs: 'flash_attention_2'
Loading base model 'HuggingFaceTB/SmolVLM-Instruct' with config and kwargs...
Base model loaded. Device map: {'': 0}
Base model attention implementation: N/A
Base model use_cache: True

Loading evaluation dataset 'HuggingFaceM4/ChartQA' split 'test'...
Loaded and limited to 100 samples for evaluation.

Evaluation Readiness:
  - Processor Ready: True
  - Fine-tuned Model Ready: True
  - Base Model Ready: True
  - Dataset Ready: True
  - Can Evaluate Fine-tuned: True
  - Can Evaluate Base: True
Evaluation will run on device inferred from models (likely: cuda)

--- Evaluation Setup Complete ---

--- Defining Evaluation Helper Functions ---
Evaluation helper functions defined.

--- Starting Comparative Evaluation Generation ---
Evaluating models: ['Finetuned', 'Base'] on 100 samples.

--- Sample 0 Prompt String ---
'<|im_start|>System: You are a Vision Language Model specialized in interpreting visual data from chart images.\nYour task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase.\nThe charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\nFocus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.<end_of_utterance>\nUser:<image>How many food item is shown in the bar graph?<end_of_utterance>\nAssistant:'
------------------------------


--- Sample 0 Prompt String ---
'<|im_start|>System: You are a Vision Language Model specialized in interpreting visual data from chart images.\nYour task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase.\nThe charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\nFocus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.<end_of_utterance>\nUser:<image>How many food item is shown in the bar graph?<end_of_utterance>\nAssistant:'
------------------------------


--- Sample 1 Prompt String ---
'<|im_start|>System: You are a Vision Language Model specialized in interpreting visual data from chart images.\nYour task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase.\nThe charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\nFocus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.<end_of_utterance>\nUser:<image>What is the difference in value between Lamb and Corn?<end_of_utterance>\nAssistant:'
------------------------------


Finished comparative generation. Processed 100 samples.

--- Calculating and Displaying Comparative Evaluation Metrics ---

Total samples in results: 100

Calculating Exact Match (EM) scores...
<ipython-input-31-336f2db4f048>:44: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  results_df[match_col] = results_df[match_col].fillna(False).astype(bool) #

Finetuned Model:
  - Valid Samples (non-error): 100
  - Correct Matches (EM): 44
  - EM Score: 44.00%
  - Error Samples (Generation): 0
<ipython-input-31-336f2db4f048>:44: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  results_df[match_col] = results_df[match_col].fillna(False).astype(bool) #

Base Model:
  - Valid Samples (non-error): 100
  - Correct Matches (EM): 38
  - EM Score: 38.00%
  - Error Samples (Generation): 0

--- Sample Evaluation Results (DataFrame) ---

Saving combined evaluation results to: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/chartqa_evaluation_results_comparison.json
Combined results saved successfully to: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/chartqa_evaluation_results_comparison.json

--- Final Evaluation Metrics Summary ---
{
  "finetuned_error_samples": 0,
  "finetuned_valid_samples": 100,
  "finetuned_exact_match_normalized": 44.0,
  "base_error_samples": 0,
  "base_valid_samples": 100,
  "base_exact_match_normalized": 38.0
}

--- Evaluation Script Finished ---
Checking for file: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/loss_curves_SmolVLM-Instruct_lora-tuned_1744604891.png

âœ… SUCCESS: The file exists at the specified path.

--- File Check Complete ---
--- Aggregating Results from Multiple Runs ---
Searching for result files in '/content/drive/MyDrive/code' using pattern: 'smolvlm-chartllama-sft-refactored*/chartqa_evaluation_results_comparison.json'
Found 13 potential result file(s):
  - smolvlm-chartllama-sft-refactored-SmolVLM-Base-full-tuned/chartqa_evaluation_results_comparison.json
  - smolvlm-chartllama-sft-refactored-SmolVLM-Base-lora-tuned/chartqa_evaluation_results_comparison.json
  - smolvlm-chartllama-sft-refactored-SmolVLM-Base-qlora-tuned/chartqa_evaluation_results_comparison.json
  - smolvlm-chartllama-sft-refactored-SmolVLM-256M-Base-full-tuned/chartqa_evaluation_results_comparison.json
  - smolvlm-chartllama-sft-refactored-SmolVLM-256M-Instruct-full-tuned/chartqa_evaluation_results_comparison.json
  - smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-full-tuned/chartqa_evaluation_results_comparison.json
  - smolvlm-chartllama-sft-refactored-SmolVLM-500M-Base-full-tuned/chartqa_evaluation_results_comparison.json
  - smolvlm-chartllama-sft-refactored-SmolVLM-500M-Base-qlora-tuned/chartqa_evaluation_results_comparison.json
  - smolvlm-chartllama-sft-refactored-SmolVLM-500M-Base-lora-tuned/chartqa_evaluation_results_comparison.json
  - smolvlm-chartllama-sft-refactored-SmolVLM-256M-Base-lora-tuned/chartqa_evaluation_results_comparison.json
  - smolvlm-chartllama-sft-refactored-SmolVLM-256M-Base-qlora-tuned/chartqa_evaluation_results_comparison.json
  - smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-qlora-tuned/chartqa_evaluation_results_comparison.json
  - smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/chartqa_evaluation_results_comparison.json

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-Base-full-tuned)
  Loaded 100 records.
  (First file, selecting core columns)
  Prepared subset with columns: ['id', 'question', 'ground_truth', 'Normalized_GT', 'Pred_SmolVLM-Base-full-tuned', 'NormPred_SmolVLM-Base-full-tuned', 'Match_SmolVLM-Base-full-tuned']

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-Base-lora-tuned)
  Loaded 100 records.
  Prepared subset with columns: ['id', 'Pred_SmolVLM-Base-lora-tuned', 'NormPred_SmolVLM-Base-lora-tuned', 'Match_SmolVLM-Base-lora-tuned']

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-Base-qlora-tuned)
  Loaded 100 records.
  Prepared subset with columns: ['id', 'Pred_SmolVLM-Base-qlora-tuned', 'NormPred_SmolVLM-Base-qlora-tuned', 'Match_SmolVLM-Base-qlora-tuned']

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-256M-Base-full-tuned)
  Loaded 100 records.
  Prepared subset with columns: ['id', 'Pred_SmolVLM-256M-Base-full-tuned', 'NormPred_SmolVLM-256M-Base-full-tuned', 'Match_SmolVLM-256M-Base-full-tuned']

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-256M-Instruct-full-tuned)
  Loaded 100 records.
  Prepared subset with columns: ['id', 'Pred_SmolVLM-256M-Instruct-full-tuned', 'NormPred_SmolVLM-256M-Instruct-full-tuned', 'Match_SmolVLM-256M-Instruct-full-tuned']

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-full-tuned)
  Loaded 100 records.
  Prepared subset with columns: ['id', 'Pred_SmolVLM-Instruct-full-tuned', 'NormPred_SmolVLM-Instruct-full-tuned', 'Match_SmolVLM-Instruct-full-tuned']

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-500M-Base-full-tuned)
  Loaded 100 records.
  Prepared subset with columns: ['id', 'Pred_SmolVLM-500M-Base-full-tuned', 'NormPred_SmolVLM-500M-Base-full-tuned', 'Match_SmolVLM-500M-Base-full-tuned']

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-500M-Base-qlora-tuned)
  Loaded 100 records.
  Prepared subset with columns: ['id', 'Pred_SmolVLM-500M-Base-qlora-tuned', 'NormPred_SmolVLM-500M-Base-qlora-tuned', 'Match_SmolVLM-500M-Base-qlora-tuned']

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-500M-Base-lora-tuned)
  Loaded 100 records.
  Prepared subset with columns: ['id', 'Pred_SmolVLM-500M-Base-lora-tuned', 'NormPred_SmolVLM-500M-Base-lora-tuned', 'Match_SmolVLM-500M-Base-lora-tuned']

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-256M-Base-lora-tuned)
  Loaded 100 records.
  Prepared subset with columns: ['id', 'Pred_SmolVLM-256M-Base-lora-tuned', 'NormPred_SmolVLM-256M-Base-lora-tuned', 'Match_SmolVLM-256M-Base-lora-tuned']

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-256M-Base-qlora-tuned)
  Loaded 100 records.
  Prepared subset with columns: ['id', 'Pred_SmolVLM-256M-Base-qlora-tuned', 'NormPred_SmolVLM-256M-Base-qlora-tuned', 'Match_SmolVLM-256M-Base-qlora-tuned']

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-qlora-tuned)
  Loaded 100 records.
  Prepared subset with columns: ['id', 'Pred_SmolVLM-Instruct-qlora-tuned', 'NormPred_SmolVLM-Instruct-qlora-tuned', 'Match_SmolVLM-Instruct-qlora-tuned']

Processing file: chartqa_evaluation_results_comparison.json (from run: smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned)
  Loaded 100 records.
  Prepared subset with columns: ['id', 'Pred_SmolVLM-Instruct-lora-tuned', 'NormPred_SmolVLM-Instruct-lora-tuned', 'Match_SmolVLM-Instruct-lora-tuned']

Merging data from 13 runs...
Merging complete.

--- Final Aggregated Results (100 samples) ---

Saving aggregated results to CSV: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-ALL_RUNS_COMPARISON.csv
Aggregated CSV saved successfully.

--- Aggregation Script Finished ---
Listing contents of: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-Instruct-lora-tuned/

Contents:
  - final_model
  - final_processor
  - checkpoint-112
  - checkpoint-165
  - train_results.json
  - all_results.json
  - trainer_state.json
  - loss_curves_SmolVLM-Instruct_lora-tuned_1744604891.png
  - chartqa_evaluation_results_comparison.json
