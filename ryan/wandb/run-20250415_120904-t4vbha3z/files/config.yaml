_wandb:
    value:
        cli_version: 0.19.9
        m: []
        python_version: 3.11.12
        t:
            "1":
                - 1
                - 2
                - 3
                - 5
                - 11
                - 12
                - 41
                - 49
                - 51
                - 53
                - 55
                - 71
                - 84
                - 98
                - 105
            "2":
                - 1
                - 2
                - 3
                - 5
                - 11
                - 12
                - 41
                - 49
                - 51
                - 53
                - 55
                - 63
                - 71
                - 84
                - 98
                - 105
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.11.12
            "5": 0.19.9
            "6": 4.51.1
            "8":
                - 1
                - 5
                - 12
            "12": 0.19.9
            "13": linux-x86_64
batch_size:
    value: 4
dtype:
    value: torch.bfloat16
grad_accum:
    value: 4
learning_rate:
    value: 5e-05
lora_alpha:
    value: 8
lora_r:
    value: 8
lr_scheduler:
    value: cosine
max_seq_length:
    value: 2048
model_id:
    value: HuggingFaceTB/SmolVLM-500M-Instruct
num_epochs:
    value: 3
optimizer:
    value: adamw_torch_fused
output_dir:
    value: /content/drive/MyDrive/code/smolvlm-chartllama-sft-refactored-SmolVLM-500M-Instruct-lora-tuned
seed:
    value: 42
training_type:
    value: lora-tuned
use_lora:
    value: true
use_qlora:
    value: false
warmup_ratio:
    value: 0.1
weight_decay:
    value: 0.01
