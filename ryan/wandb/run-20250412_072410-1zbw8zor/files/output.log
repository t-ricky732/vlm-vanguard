
--- Configuration Summary ---
Model ID: HuggingFaceTB/SmolVLM-Base
Training Type: full-tuned
Using LoRA: False
Using QLoRA: False
Output Directory: ./smolvlm-chartllama-full-tuned
Device: cuda
Dtype: torch.bfloat16
Seed: 42
---------------------------

PyTorch version: 2.6.0+cu124
CUDA available: True
CUDA version: 12.4
GPU: NVIDIA A100-SXM4-40GB
GPU memory: 42.47 GB
Using compute dtype: torch.bfloat16
Loading processor...
/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning:
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
Processor loaded.

Starting raw data loading and preprocessing...
Loading raw ChartLlama data...
Found 7 JSON files in chartllama_data.
Reading JSONs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.71it/s]

Initial processing complete.
Loaded 980 valid samples.
Skipped 0 samples due to missing data or images.
Encountered 0 errors during file processing.

Created final dataset with 980 samples.
Dataset features: {'id': Value(dtype='string', id=None), 'image': Image(mode=None, decode=True, id=None), 'question': Value(dtype='string', id=None), 'answer': Value(dtype='string', id=None)}
Raw data loaded: 980 samples.
Raw dataset columns: ['id', 'image', 'question', 'answer']
Defining output structure and columns to remove...
Defined output features for map: {'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'pixel_values': Value(dtype='binary', id=None)}
Columns to remove after mapping: ['image', 'question', 'answer', 'id']
Preprocessing raw data (map with batch_size=1 and serialization)...

ERROR: An error occurred during data loading/processing: Provided `function` which is applied to all elements of table returns a `dict` of types [<class 'list'>, <class 'list'>, <class 'bytes'>, <class 'list'>]. When using `batched=True`, make sure provided `function` returns a `dict` of types like `(<class 'list'>, <class 'numpy.ndarray'>, <class 'pandas.core.series.Series'>, <class 'tensorflow.python.framework.tensor.Tensor'>, <class 'torch.Tensor'>, <class 'jax.Array'>)`.
Traceback (most recent call last):
  File "<ipython-input-19-987cfd485e8a>", line 37, in <cell line: 0>
    processed_dataset = raw_dataset.map(
                        ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py", line 557, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py", line 3074, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py", line 3516, in _map_single
    for i, batch in iter_outputs(shard_iterable):
  File "/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py", line 3466, in iter_outputs
    yield i, apply_function(example, i, offset=offset)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py", line 3390, in apply_function
    return prepare_outputs(pa_inputs, inputs, processed_inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py", line 3354, in prepare_outputs
    validate_function_output(processed_inputs)
  File "/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py", line 3319, in validate_function_output
    raise TypeError(
TypeError: Provided `function` which is applied to all elements of table returns a `dict` of types [<class 'list'>, <class 'list'>, <class 'bytes'>, <class 'list'>]. When using `batched=True`, make sure provided `function` returns a `dict` of types like `(<class 'list'>, <class 'numpy.ndarray'>, <class 'pandas.core.series.Series'>, <class 'tensorflow.python.framework.tensor.Tensor'>, <class 'torch.Tensor'>, <class 'jax.Array'>)`.

CRITICAL ERROR: Dataset preparation failed. Cannot proceed to training.
Configuring model for Full Fine-Tuning (dtype: torch.bfloat16)...

Loading model 'HuggingFaceTB/SmolVLM-Base' with config: {'torch_dtype': torch.bfloat16}
Moving model to device: cuda
Model loaded in 2.96 seconds
Model device: cuda:0

Model configured for Full Fine-tuning.
Enabling gradient checkpointing for Full Fine-Tuning.

Setting Training Arguments for full-tuned...
Batch Size (Train): 2, Grad Accum: 8
Effective Batch Size: 16
Learning Rate: 2e-05
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(

Skipping Trainer initialization due to dataset loading/processing errors.

Training skipped due to errors in data loading, preprocessing, or trainer initialization.

--- Preparing for Evaluation ---

Downloading ChartQA dataset...
Limiting evaluation to 100 samples.
Loaded ChartQA test split with 100 examples.

First ChartQA test sample structure:
{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=850x600 at 0x7DB20051DBD0>, 'query': 'How many food item is shown in the bar graph?', 'label': ['14'], 'human_or_machine': 0}

Using accuracy function: calculate_relaxed_accuracy

Evaluation setup complete.

Evaluation setup complete.
