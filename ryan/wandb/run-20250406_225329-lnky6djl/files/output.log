PyTorch version: 2.6.0+cu124
CUDA available: True
CUDA version: 12.4
GPU: NVIDIA A100-SXM4-40GB
GPU memory: 42.47 GB
Using dtype: torch.bfloat16
Loading processor...
/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning:
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
Configuring model for standard LoRA (dtype: torch.bfloat16)...
Loading model 'HuggingFaceTB/SmolVLM-256M-Base'...
Model loaded in 24.97 seconds
Configured for Full Fine-tuning.
Checking data directory: /content/drive/MyDrive/code/chartllama_data
Does directory exist? True
Files in directory:
  - candlestick_chart_100examples_simplified_qa.json
  - funnel_chart_100examples_simplified_qa.json
  - gantt_chart_100examples_simplified_qa.json
  - polar_chart_100examples_simplified_qa.json
  - heatmap_chart_100examples_simplified_qa.json
  - box_chart_100examples_simplified_qa.json
  - .gitattributes
  - ours.zip
  - scatter_chart_100examples_simplified_qa.json
  - extracted_images
  - .cache
Loading dataset using custom ChartDataset...
Loading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [05:17<00:00, 45.33s/it]
Total samples: 980
Training samples: 784
Validation samples: 98
Test samples: 98
--- Displaying Item Index: 281 ---
Original ID: ours_simplified_qa_61_3
Chart Type: funnel
Question: What stage corresponds to the value of 30.2?
<image>...
Answer: Car Owners
Image Path (from JSON): ours/funnel_chart/png/funnel_chart_100examples_61.png
--------------------------------------
--- Displaying Item Index: 250 ---
Original ID: ours_simplified_qa_96_7
Chart Type: funnel
Question: Does the chart show that more people consume Processed Food than those who follow Vegetarianism?
<image>...
Answer: Yes
Image Path (from JSON): ours/funnel_chart/png/funnel_chart_100examples_96.png
--------------------------------------
--- Displaying Item Index: 228 ---
Original ID: ours_simplified_qa_0_7
Chart Type: funnel
Question: <image>
Is there a stage with exactly 50 advancements?...
Answer: No
Image Path (from JSON): ours/funnel_chart/png/funnel_chart_100examples_0.png
--------------------------------------
--- Displaying Item Index: 142 ---
Original ID: ours_simplified_qa_34_3
Chart Type: candlestick
Question: What is the general trend of the stock price from 2020-07-01 to 2020-07-06?
<image>...
Answer: Decreasing
Image Path (from JSON): ours/candlestick_chart/png/candlestick_chart_100examples_34.png
--------------------------------------
--- Displaying Item Index: 754 ---
Original ID: ours_simplified_qa_76_4
Chart Type: heatmap
Question: <image>
Did Twitter see a decrease in users in 2021 compared to 2020?...
Answer: Yes
Image Path (from JSON): ours/heatmap_chart/png/heatmap_chart_100examples_76.png
--------------------------------------
--- Displaying Item Index: 104 ---
Original ID: ours_simplified_qa_4_6
Chart Type: candlestick
Question: <image>
What is the difference between the highest and lowest prices on January 3, 2021?...
Answer: $20.00
Image Path (from JSON): ours/candlestick_chart/png/candlestick_chart_100examples_4.png
--------------------------------------
--- Displaying Item Index: 692 ---
Original ID: ours_simplified_qa_25_6
Chart Type: heatmap
Question: <image>
Is the maximum value of AR Devices higher than 200?...
Answer: No
Image Path (from JSON): ours/heatmap_chart/png/heatmap_chart_100examples_25.png
--------------------------------------
--- Displaying Item Index: 758 ---
Original ID: ours_simplified_qa_71_2
Chart Type: heatmap
Question: What is the impact on deer population due to urbanization in 2020?
<image>...
Answer: 55
Image Path (from JSON): ours/heatmap_chart/png/heatmap_chart_100examples_71.png
--------------------------------------
--- Displaying Item Index: 913 ---
Original ID: ours_simplified_qa_19_3
Chart Type: scatter
Question: <image>
How many books were borrowed in 2017?...
Answer: 6500
Image Path (from JSON): ours/scatter_chart/png/scatter_chart_100examples_19.png
--------------------------------------
--- Displaying Item Index: 558 ---
Original ID: ours_simplified_qa_39_0
Chart Type: polar
Question: What is the title of the chart?
<image>...
Answer: Increase in the Prevalence of Home Cooking
Image Path (from JSON): ours/polar_chart/png/polar_chart_100examples_39.png
--------------------------------------
--- Displaying Item Index: 89 ---
Original ID: ours_simplified_qa_9_6
Chart Type: candlestick
Question: <image>
Is the highest price on 2021-01-03 greater than 520,000?...
Answer: No
Image Path (from JSON): ours/candlestick_chart/png/candlestick_chart_100examples_9.png
--------------------------------------
--- Displaying Item Index: 604 ---
Original ID: ours_simplified_qa_59_0
Chart Type: polar
Question: <image>
What is the theme of the chart?...
Answer: The shifts in the popularity of various sports
Image Path (from JSON): ours/polar_chart/png/polar_chart_100examples_59.png
--------------------------------------
--- Displaying Item Index: 432 ---
Original ID: ours_simplified_qa_49_9
Chart Type: gantt
Question: Is the Testing task the longest in duration?
<image>...
Answer: No
Image Path (from JSON): ours/gantt_chart/png/gantt_chart_100examples_49.png
--------------------------------------
--- Displaying Item Index: 32 ---
Original ID: ours_simplified_qa_66_7
Chart Type: candlestick
Question: <image>
Is the overall trend of the chart Monotonic?...
Answer: No
Image Path (from JSON): ours/candlestick_chart/png/candlestick_chart_100examples_66.png
--------------------------------------
--- Displaying Item Index: 30 ---
Original ID: ours_simplified_qa_62_5
Chart Type: candlestick
Question: <image>
Were there any days when the closing value was higher than the opening value?...
Answer: Yes
Image Path (from JSON): ours/candlestick_chart/png/candlestick_chart_100examples_62.png
--------------------------------------
--- Displaying Item Index: 95 ---
Original ID: ours_simplified_qa_21_8
Chart Type: candlestick
Question: Did the opening price exceed 400000 on any day?
<image>...
Answer: Yes
Image Path (from JSON): ours/candlestick_chart/png/candlestick_chart_100examples_21.png
--------------------------------------
--- Displaying Item Index: 223 ---
Original ID: ours_simplified_qa_92_4
Chart Type: funnel
Question: Which meat has the lowest consumption?
<image>...
Answer: Lamb
Image Path (from JSON): ours/funnel_chart/png/funnel_chart_100examples_92.png
--------------------------------------
--- Displaying Item Index: 238 ---
Original ID: ours_simplified_qa_31_7
Chart Type: funnel
Question: Are there any significant outliers in the chart?
<image>...
Answer: No
Image Path (from JSON): ours/funnel_chart/png/funnel_chart_100examples_31.png
--------------------------------------
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
Initializing Trainer...
Starting training...
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
Initializing Trainer...
Starting training...
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
Initializing Trainer...
Starting training...
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
Initializing Trainer...
Starting training...
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
Initializing Trainer...
Starting training...
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
Initializing Trainer...
Starting training...
Training completed in 37.12 minutes
Saving training results and final model/adapter...
***** train metrics *****
  epoch                    =        3.0
  total_flos               =  3449970GF
  train_loss               =     2.6639
  train_runtime            = 0:37:06.95
  train_samples_per_second =      1.056
  train_steps_per_second   =      0.066
Model adapter and processor saved to ./smolvlm-chartllama-256-full-tuned
Failed to load fine-tuned model. Error: ./smolvlm-chartllama-256-full-tuned does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/./smolvlm-chartllama-256-full-tuned/tree/main' for available files.
Collecting datasets
  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)
Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)
Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)
Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)
Collecting dill<0.3.9,>=0.3.0 (from datasets)
  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)
Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)
Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)
Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)
Collecting xxhash (from datasets)
  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)
Collecting multiprocess<0.70.17 (from datasets)
  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)
Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)
  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)
Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)
Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)
Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)
Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)
Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)
Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)
Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)
Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.1)
Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)
Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)
Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)
Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)
Downloading datasets-3.5.0-py3-none-any.whl (491 kB)
[2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m491.2/491.2 kB[0m [31m33.9 MB/s[0m eta [36m0:00:00[0m
[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)
[2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m116.3/116.3 kB[0m [31m12.3 MB/s[0m eta [36m0:00:00[0m
[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)
[2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m183.9/183.9 kB[0m [31m20.2 MB/s[0m eta [36m0:00:00[0m
[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)
[2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m143.5/143.5 kB[0m [31m14.7 MB/s[0m eta [36m0:00:00[0m
[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)
[2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m194.8/194.8 kB[0m [31m20.7 MB/s[0m eta [36m0:00:00[0m
[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets
  Attempting uninstall: fsspec
    Found existing installation: fsspec 2025.3.2
    Uninstalling fsspec-2025.3.2:
      Successfully uninstalled fsspec-2025.3.2
[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == "Linux" and platform_machine == "x86_64", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.
torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == "Linux" and platform_machine == "x86_64", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.
torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == "Linux" and platform_machine == "x86_64", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.
torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == "Linux" and platform_machine == "x86_64", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.
torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == "Linux" and platform_machine == "x86_64", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.
torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == "Linux" and platform_machine == "x86_64", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.
torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == "Linux" and platform_machine == "x86_64", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.
torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == "Linux" and platform_machine == "x86_64", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.
torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == "Linux" and platform_machine == "x86_64", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.
torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == "Linux" and platform_machine == "x86_64", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.
gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.[0m[31m
[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0
Downloading ChartQA dataset...
Error downloading ChartQA dataset: Dataset 'HuggingFaceH4/ChartQA' doesn't exist on the Hub or cannot be accessed.
Using device: cuda
Using device: cuda
Downloading ChartQA dataset...
Error downloading/loading ChartQA dataset: Dataset 'google/chartqa' doesn't exist on the Hub or cannot be accessed.
Downloading ChartQA dataset...
Loaded ChartQA test split with 2500 examples.

First ChartQA test sample structure:
{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=850x600 at 0x7C3F01AE76D0>, 'query': 'How many food item is shown in the bar graph?', 'label': ['14'], 'human_or_machine': 0}
Using accuracy function: calculate_relaxed_accuracy

--- Loading Base Model for Evaluation ---
Base model 'HuggingFaceTB/SmolVLM-256M-Base' loaded successfully on cuda.

--- Loading Fine-tuned Model for Evaluation ---
Error: Could not find required processor config (processor_config.json) in ./smolvlm-chartllama-256-full-tuned or ./smolvlm-chartllama-256-full-tuned/final_processor
total 24
-rw------- 1 root root  203 Apr  7 00:05 all_results.json
drwx------ 2 root root 4096 Apr  7 00:04 checkpoint-147
drwx------ 2 root root 4096 Apr  6 23:52 checkpoint-98
drwx------ 2 root root 4096 Apr  7 00:05 final_adapter
drwx------ 2 root root 4096 Apr  7 00:05 final_processor
drwx------ 7 root root 4096 Apr  6 23:27 runs
-rw------- 1 root root 2459 Apr  7 00:05 trainer_state.json
-rw------- 1 root root  203 Apr  7 00:05 train_results.json

--- Loading Fine-tuned Model for Evaluation ---
Checking for model weights in: ./smolvlm-chartllama-256-full-tuned/final_adapter
Checking for processor in: ./smolvlm-chartllama-256-full-tuned/final_processor
Loading processor from: ./smolvlm-chartllama-256-full-tuned/final_processor
Loading model from: ./smolvlm-chartllama-256-full-tuned/final_adapter
Fine-tuned model and processor loaded successfully from subdirs on cuda.

--- Starting Evaluation on 100 ChartQA Samples ---
Warning: Skipping sample 0 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 1 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 2 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 3 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 4 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 5 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 6 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 7 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 8 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 9 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 10 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 11 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 12 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 13 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 14 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 15 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 16 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 17 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 18 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 19 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 20 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 21 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 22 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 23 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 24 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 25 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 26 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 27 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 28 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 29 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 30 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 31 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 32 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 33 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 34 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 35 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 36 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 37 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 38 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 39 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 40 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 41 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 42 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 43 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 44 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 45 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 46 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 47 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 48 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 49 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 50 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 51 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 52 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 53 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 54 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 55 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 56 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 57 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 58 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 59 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 60 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 61 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 62 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 63 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 64 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 65 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 66 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 67 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 68 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 69 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 70 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 71 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 72 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 73 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 74 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 75 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 76 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 77 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 78 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 79 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 80 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 81 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 82 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 83 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 84 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 85 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 86 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 87 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 88 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 89 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 90 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 91 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 92 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 93 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 94 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 95 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 96 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 97 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 98 due to missing data (img: True, query: False, or label: False).
Warning: Skipping sample 99 due to missing data (img: True, query: False, or label: False).

--- Evaluation Results ---
Evaluated on: 100 samples
Metric: Relaxed Accuracy (calculate_relaxed_accuracy)

Base Model (HuggingFaceTB/SmolVLM-256M-Base): 0.0000
Fine-tuned Model (smolvlm-chartllama-256-full-tuned): 0.0000

--- Example Predictions (First 5 Evaluated) ---

Sample Index: 0
  Error: Missing data field(s)
  Q (if available): N/A
  GT (if available): N/A

Sample Index: 1
  Error: Missing data field(s)
  Q (if available): N/A
  GT (if available): N/A

Sample Index: 2
  Error: Missing data field(s)
  Q (if available): N/A
  GT (if available): N/A

Sample Index: 3
  Error: Missing data field(s)
  Q (if available): N/A
  GT (if available): N/A

Sample Index: 4
  Error: Missing data field(s)
  Q (if available): N/A
  GT (if available): N/A
{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=850x600 at 0x7C3EF4579E10>, 'query': 'How many food item is shown in the bar graph?', 'label': ['14'], 'human_or_machine': 0}

--- Starting Evaluation on 100 ChartQA Samples ---
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.
Error during model inference: The total number of <image> tokens in the prompts should be the same as the number of images passed. Found 0 <image> tokens and 1 images.

--- Loading Base Model for Evaluation ---
Base model 'HuggingFaceTB/SmolVLM-256M-Base' loaded successfully on cuda.

--- Loading Fine-tuned Model for Evaluation ---
Checking for model weights in: ./smolvlm-chartllama-256-full-tuned/final_adapter
Checking for processor in: ./smolvlm-chartllama-256-full-tuned/final_processor
Loading processor from: ./smolvlm-chartllama-256-full-tuned/final_processor
Loading model from: ./smolvlm-chartllama-256-full-tuned/final_adapter
Fine-tuned model and processor loaded successfully from subdirs on cuda.

--- Starting Evaluation on 100 ChartQA Samples ---
/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(

--- Evaluation Results ---
Evaluated on: 100 samples
Metric: Relaxed Accuracy (calculate_relaxed_accuracy)

Base Model (HuggingFaceTB/SmolVLM-256M-Base): 0.0300
Fine-tuned Model (smolvlm-chartllama-256-full-tuned): 0.0400

--- Example Predictions (First 5 Evaluated) ---

Sample Index: 0
  Q: How many food item is shown in the bar graph?
  GT: 14
  Base Pred: 1000 (Incorrect)
  FFT Pred:  1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 (Incorrect)

Sample Index: 1
  Q: What is the difference in value between Lamb and Corn?
  GT: 0.57
  Base Pred: 1000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.00 (Incorrect)
  FFT Pred:  103.13 103.13 103.13 103.13 103.13 103.13 103.13 103.13 103.13 103.13 103.13 103.13 103.13 103.13 103.13 103.13 103.13 103.13 1 (Incorrect)

Sample Index: 2
  Q: How many bars are shown in the chart?
  GT: 3
  Base Pred: 0.1% 0.2% 0.3% 0.4% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0. (Incorrect)
  FFT Pred:  0.21% (Incorrect)

Sample Index: 3
  Q: Is the sum value of Madagascar more then Fiji?
  GT: No
  Base Pred: 0.1% 0.2% 0.3% 0.4% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0.3% 0. (Incorrect)
  FFT Pred:  0.4% (Incorrect)

Sample Index: 4
  Q: What's the value of the lowest bar?
  GT: 23
  Base Pred: 0.000000 (Incorrect)
  FFT Pred:  10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 (Incorrect)

Releasing models from memory...
Cleanup complete.
Evaluation Results DataFrame (first 10 rows):
Evaluation Results DataFrame (first 10 rows):
