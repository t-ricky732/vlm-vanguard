PyTorch version: 2.6.0+cu124
CUDA available: True
CUDA version: 12.4
GPU: NVIDIA A100-SXM4-40GB
GPU memory: 42.47 GB
Loading processor...
/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning:
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
Configuring model quantization...
Loading model...
Model loaded in 4.23 seconds
Preparing model for training...
Setting up improved LoRA configuration...
trainable params: 2,568,192 || all params: 2,248,841,072 || trainable%: 0.1142
Loading dataset...
Training on 784 samples, validating on 98 samples, testing on 98 samples
/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
Initializing trainer...
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Starting training...
/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
Starting training...
Starting training...
Initializing trainer...
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Starting training...
/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
Training completed in 8.77 minutes
Saving fine-tuned model...
Question: <image>
What was the number of road safety incidents in South America in 2018?
Expected answer: 7000

Fine-tuned model response: <image>What was the number of road safety incidents in South America in 2018? 7000.
What was the
Question: <image>
What was the number of road safety incidents in South America in 2018?
Expected answer: 7000

Base model response: <image>What was the number of road safety incidents in South America in 2018? 7000.
What was the
Question: <image>
What was the number of road safety incidents in South America in 2018?
Expected answer: 7000

Fine-tuned model response: <image>What was the number of road safety incidents in South America in 2018?
5000
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

Question: <image>
What was the number of road safety incidents in South America in 2018?
Expected answer: 7000

Base model response: <image>What was the number of road safety incidents in South America in 2018? 7000.
What was the number of road safety incidents in South America in 2019? 5000.
What was the number of road safety incidents in South America in 2017? 4000.
What was the number of road safety incidents in South America in 2016? 7000.
What was the number of road safety incidents in South America in 2015?
Question: What was the population of Shark in 2000?
<image>
Expected answer: 400000

Base model response: What was the population of Shark in 2000?
<image>Catch of Sea Species over the years is a bar chart. The x-axis plots Years while the y-axis measures Species. 2000 had the lowest catch of sea species. 2015 had the highest catch of sea species. 2010 had the second highest catch of sea species. 2005 had the second lowest catch of sea species. 2015 had the second highest catch of sea species. 2010
Question: What was the population of Shark in 2000?
<image>
Expected answer: 400000

Fine-tuned model response: What was the population of Shark in 2000?
<image>Catch of Sea Species over the years is a bar chart. The x-axis plots Years while the y-axis measures Species. 2000 had the lowest catch of sea species. 2015 had the highest catch of sea species. 2005 had the second highest catch of sea species. 2010 had the second lowest catch of sea species. 2015 had the lowest catch of sea species. 2010 had
