{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVKZjV8QLkg-"
   },
   "source": [
    "# Fine-tuning SmolVLM on ChartLlama Dataset\n",
    "\n",
    "This notebook demonstrates how to fine-tune the SmolVLM model on the ChartLlama dataset using parameter-efficient fine-tuning (LoRA)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYU5W95UL-6o",
    "outputId": "c64b1312-776f-4097-81ad-3f58e83f8880"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5_dD1fjUMVNd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('/content/drive/MyDrive/code')\n",
    "os.chdir('/home/ricky732/CS7643_final_project/working_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pcdMTIUFvfEK",
    "outputId": "86ee6a8e-4230-456b-e88e-9ab85dc56d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (0.30.1)\n",
      "Requirement already satisfied: packaging in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (0.45.5)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from bitsandbytes) (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (4.11.0)\n",
      "Requirement already satisfied: networkx in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: transformers in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: trl in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (0.16.1)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from trl) (1.6.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from trl) (3.5.0)\n",
      "Requirement already satisfied: rich in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from trl) (13.9.4)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from trl) (4.51.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (24.1)\n",
      "Requirement already satisfied: psutil in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (0.30.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
      "Requirement already satisfied: filelock in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (3.11.16)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from transformers>=4.46.0->trl) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from rich->trl) (2.15.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from rich->trl) (4.11.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.19.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2024.8.30)\n",
      "Requirement already satisfied: networkx in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# Core dependencies\n",
    "!pip install -U datasets\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -U transformers\n",
    "!pip install -U trl  # latest TRL library from HuggingFace\n",
    "!pip install -q flash-attn --no-build-isolation\n",
    "!pip install -q word2number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BYxXUfaQc4Zi"
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import gc\n",
    "import time\n",
    "import traceback\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from itertools import islice\n",
    "\n",
    "# Data science & visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "\n",
    "# Data handling\n",
    "from datasets import Dataset, load_dataset\n",
    "from accelerate.utils import set_seed\n",
    "from word2number import w2n\n",
    "\n",
    "# Hugging Face transformers\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    Idefics3ForConditionalGeneration,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "# PEFT (Parameter-Efficient Fine-Tuning)\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    "    PeftModel\n",
    ")\n",
    "\n",
    "# TRL (Training utilities)\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# Experiment tracking\n",
    "import wandb\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWp3MYBBc8iQ",
    "outputId": "8ffec345-a9fc-4ae7-99c3-85a11dddc2d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting Configuration --- \n"
     ]
    }
   ],
   "source": [
    "print(\"--- Setting Configuration --- \")\n",
    "\n",
    "# --- Basic Setup ---\n",
    "#WORKING_DIR = '/content/drive/MyDrive/code'\n",
    "WORKING_DIR = '/home/ricky732/CS7643_final_project/working_dir'\n",
    "DATA_DIR = Path(\"./chartllama_data\")\n",
    "OUTPUT_DIR_BASE_NAME = \"smolvlm-500M-chartllama-sft-long-prompt\" # change to short prompt for short prompt\n",
    "# OUTPUT_DIR_BASE_NAME = \"smolvlm-chartllama-sft-refactored\"\n",
    "SEED = 42\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vjAnlL6dDJh",
    "outputId": "032e15e9-5b14-45b3-b38b-e9b3586ca505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already in working directory: /home/ricky732/CS7643_final_project/working_dir\n"
     ]
    }
   ],
   "source": [
    "if os.getcwd() != WORKING_DIR:\n",
    "    print(f\"Changing working directory to: {WORKING_DIR}\")\n",
    "    os.makedirs(WORKING_DIR, exist_ok=True)\n",
    "    os.chdir(WORKING_DIR)\n",
    "else:\n",
    "    print(f\"Already in working directory: {WORKING_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sIeivHQGdFgK"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"HuggingFaceTB/SmolVLM-500M-Instruct\" # specify model to use here\n",
    "\n",
    "USE_LORA = True\n",
    "USE_QLORA = True\n",
    "\n",
    "LORA_R = 8 # rank set to 8\n",
    "LORA_ALPHA = 8\n",
    "LORA_DROPOUT = 0.1\n",
    "LORA_TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", # attention heads\n",
    "                       \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\", \"lm_head\"\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "duu5OGm7dM6B"
   },
   "outputs": [],
   "source": [
    "if USE_QLORA and not USE_LORA:\n",
    "    print(\"Warning: USE_QLORA=True requires USE_LORA=True. Forcing USE_LORA=True.\")\n",
    "    USE_LORA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "u-tvlcIQdOoV"
   },
   "outputs": [],
   "source": [
    "# --- Training Hyperparameters ---\n",
    "NUM_TRAIN_EPOCHS = 3 # keep to default\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "LEARNING_RATE = 1e-4\n",
    "MAX_SEQ_LENGTH = 2048\n",
    "OPTIMIZER = \"adamw_torch_fused\"\n",
    "LR_SCHEDULER_TYPE = \"cosine\"\n",
    "LOGGING_STEPS = 25\n",
    "SAVE_STRATEGY = \"epoch\"\n",
    "EVAL_STRATEGY = \"epoch\"\n",
    "EVAL_STEPS = 50\n",
    "WARMUP_RATIO = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAMPLE_LIMIT = None # training sample limit on Chartllama, None will use everything available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mlBh3DVVdShz"
   },
   "outputs": [],
   "source": [
    "# --- Resources & Precision ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16\n",
    "ATTN_IMPLEMENTATION = \"flash_attention_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OXBzYGOjdW7f"
   },
   "outputs": [],
   "source": [
    "# --- Output Directory (Directly on Drive) ---\n",
    "if not USE_LORA:\n",
    "    TRAINING_TYPE = \"full-tuned\"\n",
    "elif USE_QLORA:\n",
    "    TRAINING_TYPE = \"qlora-tuned\"\n",
    "else:\n",
    "    TRAINING_TYPE = \"lora-tuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bUHrgvpCdZbl"
   },
   "outputs": [],
   "source": [
    "model_name_short = MODEL_ID.split('/')[-1]\n",
    "output_folder_name = f\"{OUTPUT_DIR_BASE_NAME}-{model_name_short}-{TRAINING_TYPE}-paddingTrue\" # test for lora alpha 16\n",
    "OUTPUT_DIR = os.path.join(WORKING_DIR, output_folder_name) # full path on Drive\n",
    "FINAL_MODEL_DIR = os.path.join(OUTPUT_DIR, \"final_model\")\n",
    "FINAL_PROCESSOR_DIR = os.path.join(OUTPUT_DIR, \"final_processor\") # sub directory to save processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kSAIVl-Fdbbn"
   },
   "outputs": [],
   "source": [
    "# --- Evaluation Config ---\n",
    "CHARTQA_DATASET_ID = \"HuggingFaceM4/ChartQA\"\n",
    "EVAL_SPLIT = \"test\"\n",
    "EVAL_LIMIT = None # number of chartqa samples to use when evaluating ChartQA\n",
    "MAX_NEW_TOKENS_EVAL = 32\n",
    "EVAL_OUTPUT_FILE = os.path.join(OUTPUT_DIR, \"chartqa_evaluation_results_comparison.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ym39Yfg4deFo"
   },
   "outputs": [],
   "source": [
    "# --- W&B Logging ---\n",
    "#WANDB_PROJECT = \"smolvlm-chartllama-sft-refactored\" # Set to None to disable\n",
    "WANDB_PROJECT = None\n",
    "WANDB_RUN_NAME = f\"{model_name_short}-{TRAINING_TYPE}-{int(time.time())}\" # Unique name for run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFSY5rXtdg5b",
    "outputId": "b5120ab0-ab11-42db-8fee-3e39a742d70d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory ensured: '/home/ricky732/CS7643_final_project/working_dir/smolvlm-500M-chartllama-sft-long-prompt-SmolVLM-500M-Instruct-qlora-tuned-paddingTrue'\n",
      "\n",
      "--- Configuration Summary ---\n",
      "Model ID: HuggingFaceTB/SmolVLM-500M-Instruct\n",
      "Training Type: qlora-tuned\n",
      "Use LoRA: True, Use QLoRA: True\n",
      "Device: cuda, Compute Dtype: torch.bfloat16, Attention: flash_attention_2\n",
      "Learning Rate: 0.0001, Epochs: 3\n",
      "Eval Strategy: epoch\n",
      "Output Directory (on Drive): '/home/ricky732/CS7643_final_project/working_dir/smolvlm-500M-chartllama-sft-long-prompt-SmolVLM-500M-Instruct-qlora-tuned-paddingTrue'\n",
      "Final Model Save Directory: '/home/ricky732/CS7643_final_project/working_dir/smolvlm-500M-chartllama-sft-long-prompt-SmolVLM-500M-Instruct-qlora-tuned-paddingTrue/final_model'\n",
      "Final Processor Save Directory: '/home/ricky732/CS7643_final_project/working_dir/smolvlm-500M-chartllama-sft-long-prompt-SmolVLM-500M-Instruct-qlora-tuned-paddingTrue/final_processor'\n",
      "Evaluation results file: /home/ricky732/CS7643_final_project/working_dir/smolvlm-500M-chartllama-sft-long-prompt-SmolVLM-500M-Instruct-qlora-tuned-paddingTrue/chartqa_evaluation_results_comparison.json\n",
      "WandB Project: None, Run Name: SmolVLM-500M-Instruct-qlora-tuned-1745322909\n",
      "-----------------------------\n",
      "\n",
      "--- Full Configuration Complete --- \n",
      "\n",
      "--- Configuration Complete --- \n"
     ]
    }
   ],
   "source": [
    "# Create output directory now (important for direct-to-drive)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Output directory ensured: '{OUTPUT_DIR}'\")\n",
    "\n",
    "# display summary of all relevant information based on above settings.\n",
    "# --- Print Summary ---\n",
    "print(f\"\\n--- Configuration Summary ---\")\n",
    "print(f\"Model ID: {MODEL_ID}\")\n",
    "print(f\"Training Type: {TRAINING_TYPE}\")\n",
    "print(f\"Use LoRA: {USE_LORA}, Use QLoRA: {USE_QLORA}\")\n",
    "print(f\"Device: {DEVICE}, Compute Dtype: {DTYPE}, Attention: {ATTN_IMPLEMENTATION}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}, Epochs: {NUM_TRAIN_EPOCHS}\")\n",
    "print(f\"Eval Strategy: {EVAL_STRATEGY}\")\n",
    "print(f\"Output Directory (on Drive): '{OUTPUT_DIR}'\")\n",
    "print(f\"Final Model Save Directory: '{FINAL_MODEL_DIR}'\")\n",
    "print(f\"Final Processor Save Directory: '{FINAL_PROCESSOR_DIR}'\")\n",
    "print(f\"Evaluation results file: {EVAL_OUTPUT_FILE}\")\n",
    "print(f\"WandB Project: {WANDB_PROJECT}, Run Name: {WANDB_RUN_NAME}\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "print(\"\\n--- Full Configuration Complete --- \")\n",
    "\n",
    "print(\"\\n--- Configuration Complete --- \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "T3b3BNGjdjPZ",
    "outputId": "58d6c885-b715-4b27-e23c-83124d6abea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- WandB Setup ---\n",
      "WandB disabled by configuration (WANDB_PROJECT=None).\n",
      "--- WandB Setup Complete ---\n"
     ]
    }
   ],
   "source": [
    "# api key: 0469802d14d997b8dad4d23a7ba212e0a8d8f197\n",
    "# --- Simplified WandB setup ---\n",
    "print(\"--- WandB Setup ---\")\n",
    "\n",
    "if WANDB_PROJECT:\n",
    "    try:\n",
    "        wandb.login(relogin=False)\n",
    "        wandb.init(\n",
    "            project=WANDB_PROJECT,\n",
    "            name=WANDB_RUN_NAME,\n",
    "            config={\n",
    "                \"model_id\": MODEL_ID,\n",
    "                \"training_type\": TRAINING_TYPE,\n",
    "                \"use_lora\": USE_LORA,\n",
    "                \"use_qlora\": USE_QLORA,\n",
    "                \"dtype\": str(DTYPE),\n",
    "                \"seed\": SEED,\n",
    "                \"lora_r\": LORA_R if USE_LORA else None,\n",
    "                \"lora_alpha\": LORA_ALPHA if USE_LORA else None,\n",
    "                \"num_epochs\": NUM_TRAIN_EPOCHS,\n",
    "                \"learning_rate\": LEARNING_RATE,\n",
    "                \"batch_size\": PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "                \"grad_accum\": GRADIENT_ACCUMULATION_STEPS,\n",
    "                \"max_seq_length\": MAX_SEQ_LENGTH,\n",
    "                \"output_dir\": OUTPUT_DIR,\n",
    "                \"optimizer\": OPTIMIZER,\n",
    "                \"lr_scheduler\": LR_SCHEDULER_TYPE,\n",
    "                \"warmup_ratio\": WARMUP_RATIO,\n",
    "                \"weight_decay\": WEIGHT_DECAY,\n",
    "            },\n",
    "            job_type=\"fine-tuning\"\n",
    "        )\n",
    "        print(\"WandB initialized.\")\n",
    "    except Exception as e:\n",
    "        print(f\"WandB initialization failed: {e}. Disabling WandB.\")\n",
    "        os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "else:\n",
    "    print(\"WandB disabled by configuration (WANDB_PROJECT=None).\")\n",
    "    os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"--- WandB Setup Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odBskBDddpMe",
    "outputId": "86568ff6-e84f-44f6-ffbc-9f7bc7e64a80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Data Loading Function ---\n",
      "Data loading function defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Define chartllama data loading function ---\n",
    "\n",
    "print(\"\\n--- Defining Data Loading Function ---\")\n",
    "\n",
    "def load_chartllama_data(data_root: Path, image_root: Path, limit: Optional[int] = None):\n",
    "    \"\"\"Loads ChartLlama QA pairs from JSON files.\"\"\"\n",
    "    if not data_root.is_dir():\n",
    "        raise FileNotFoundError(f\"Data root directory not found: {data_root.resolve()}\")\n",
    "\n",
    "    examples, skipped = [], 0\n",
    "    json_files = list(data_root.glob(\"*_simplified_qa.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        raise FileNotFoundError(f\"No '*_simplified_qa.json' files found in {data_root}\")\n",
    "\n",
    "    for json_file in tqdm(json_files, desc=\"Processing JSON files\"):\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            qa_list = json.load(f)\n",
    "\n",
    "        for idx, qa in enumerate(qa_list):\n",
    "            if limit and len(examples) >= limit:\n",
    "                break\n",
    "\n",
    "            question = qa.get(\"conversations\", [{}])[0].get(\"value\", \"\").replace(\"<image>\", \"\").strip()\n",
    "            answer = qa.get(\"conversations\", [{}, {}])[1].get(\"value\", \"\").strip()\n",
    "            image_path = (image_root / qa.get(\"image\", \"\")).resolve()\n",
    "\n",
    "            if question and answer and image_path.is_file():\n",
    "                examples.append({\n",
    "                    \"id\": qa.get(\"id\", f\"{json_file.stem}_{idx}\"),\n",
    "                    \"question\": question,\n",
    "                    \"answer\": answer,\n",
    "                    \"image_path\": str(image_path),\n",
    "                })\n",
    "            else:\n",
    "                skipped += 1\n",
    "\n",
    "    if not examples:\n",
    "        raise ValueError(f\"No valid examples loaded from {data_root}. Skipped {skipped} samples.\")\n",
    "\n",
    "    print(f\"\\nLoaded {len(examples)} examples. Skipped {skipped} invalid samples.\")\n",
    "    return Dataset.from_list(examples)\n",
    "\n",
    "print(\"Data loading function defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277,
     "referenced_widgets": [
      "625bae4a365b435c91aa623b42e7754c",
      "6152581c7d4746ceb6d61bc71e015c01",
      "a9db73bd09d44ed3ae5934b6ce58de5b",
      "112a279018b342fea4829d34e0edbdd6",
      "e2869fd0d0944565aae8e8932ef5004c",
      "b34c44835f0b401eb94e32f66d44adfc",
      "278aa53e5ef9415fae21bdf41b770afd",
      "19871de1c8cf474d963b534dd9a1438f",
      "033846748696417bb4fb61f93505c93e",
      "d9fd9b306db94295a4a2c78cc9fa33a3",
      "f4a13bca67db4ab5acc128da99f02935"
     ]
    },
    "id": "FU4jyOiEd2Rn",
    "outputId": "d472ecea-524e-47c0-a3da-bd2a1350e300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading and Splitting Data ---\n",
      "Loading data from: /home/ricky732/CS7643_final_project/working_dir/chartllama_data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313f7af5d68c4f82ad7e9bf3614367ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing JSON files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 980 examples. Skipped 0 invalid samples.\n",
      "\n",
      "Raw data loaded and split.\n",
      "Train samples: 784\n",
      "Eval samples (Validation): 196\n",
      "\n",
      "Sample train data point (raw):\n",
      "{'id': 'ours_simplified_qa_35_2', 'question': 'What is the mortality rate for Neonatal mortality (under-28 days)?', 'answer': '4.6', 'image_path': '/home/ricky732/CS7643_final_project/working_dir/chartllama_data/ours/funnel_chart/png/funnel_chart_100examples_35.png'}\n"
     ]
    }
   ],
   "source": [
    "# --- Load Chartllama data ---\n",
    "\n",
    "print(\"\\n--- Loading and Splitting Data ---\")\n",
    "train_dataset, eval_dataset, raw_dataset = None, None, None\n",
    "\n",
    "# ensure DATA_DIR is a valid Path object\n",
    "DATA_DIR = Path(DATA_DIR)\n",
    "if not DATA_DIR.is_absolute():\n",
    "    DATA_DIR = Path(WORKING_DIR) / DATA_DIR\n",
    "\n",
    "if not DATA_DIR.is_dir():\n",
    "    raise FileNotFoundError(f\"Input data directory not found: {DATA_DIR.resolve()}\")\n",
    "\n",
    "print(f\"Loading data from: {DATA_DIR.resolve()}\")\n",
    "raw_dataset = load_chartllama_data(DATA_DIR, DATA_DIR, limit=SAMPLE_LIMIT)\n",
    "\n",
    "if not raw_dataset:\n",
    "    raise RuntimeError(\"Data loading returned an empty dataset.\")\n",
    "\n",
    "# split dataset: 80% train, 20% validation\n",
    "dataset_split = raw_dataset.train_test_split(test_size=0.2, seed=SEED, shuffle=True)\n",
    "train_dataset, eval_dataset = dataset_split[\"train\"], dataset_split[\"test\"]\n",
    "\n",
    "print(f\"\\nRaw data loaded and split.\")\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Eval samples (Validation): {len(eval_dataset)}\")\n",
    "\n",
    "# display one sample from train dataset\n",
    "if train_dataset:\n",
    "    print(\"\\nSample train data point (raw):\")\n",
    "    print(train_dataset[0])\n",
    "else:\n",
    "    print(\"Train dataset is empty after split.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xKDyoRSSd8V7",
    "outputId": "9a5b77a4-51ce-4758-b182-cd4bbbd8dd0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading Model and Processor for Training ---\n",
      "Loading processor for model: HuggingFaceTB/SmolVLM-500M-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb2a9623ff145e984a4c5469949f4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ddae7c12c845d0845da628c8599dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/429 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8398871711450cbe0761786a6930bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/486 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f99417a3cd45b19b17cf560d1ff63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d394aeb78c741ba9e1d058730d04e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cebbc2945424b7f96f9454c02736190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208d407d3e7f454897ac24a2f9e5d92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.55M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce395c65ca242a79380179ca5cd1d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/4.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2581fe31831248408f5d77ac1ac1fef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor loaded.\n",
      "\n",
      "Configuring model loading...\n",
      "Configuring model for QLoRA (4-bit).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd6931df8da4ce5b8e938862eeafcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 'HuggingFaceTB/SmolVLM-500M-Instruct'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a88fb7c19944d1bd007fd9ffe5fc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99de688dbe624f36b73735ce80737d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "  - Device Map: {'': 0}\n",
      "  - Attention Implementation: N/A\n",
      "\n",
      "Applying PEFT/LoRA configuration...\n",
      "trainable params: 5,186,048 || all params: 512,668,352 || trainable%: 1.0116\n",
      "\n",
      "--- Model and Processor Setup Complete ---\n"
     ]
    }
   ],
   "source": [
    "# ### 3.1 Load Model and Processor\n",
    "\n",
    "print(\"\\n--- Loading Model and Processor for Training ---\")\n",
    "\n",
    "# load Processor\n",
    "print(f\"Loading processor for model: {MODEL_ID}\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "if processor.tokenizer.pad_token_id is None:\n",
    "    processor.tokenizer.pad_token = processor.tokenizer.eos_token\n",
    "    if hasattr(processor, 'pad_token') and processor.pad_token is None:\n",
    "        processor.pad_token = processor.tokenizer.eos_token\n",
    "print(\"Processor loaded.\")\n",
    "\n",
    "# configure Model Loading\n",
    "print(\"\\nConfiguring model loading...\")\n",
    "model_load_kwargs = {\"device_map\": \"auto\", \"torch_dtype\": DTYPE}\n",
    "\n",
    "if USE_LORA and USE_QLORA:\n",
    "    print(\"Configuring model for QLoRA (4-bit).\")\n",
    "    model_load_kwargs[\"quantization_config\"] = BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=DTYPE\n",
    "    )\n",
    "elif USE_LORA:\n",
    "    print(f\"Configuring model for LoRA (dtype: {DTYPE}).\")\n",
    "else:\n",
    "    print(f\"Configuring model for Full Fine-Tuning (dtype: {DTYPE}).\")\n",
    "\n",
    "# load Config\n",
    "config = AutoConfig.from_pretrained(MODEL_ID, trust_remote_code=True, use_cache=False)\n",
    "if hasattr(config, \"attn_implementation\"):\n",
    "    config.attn_implementation = ATTN_IMPLEMENTATION\n",
    "\n",
    "# load Model\n",
    "print(f\"Loading model '{MODEL_ID}'...\")\n",
    "model = Idefics3ForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID, config=config, trust_remote_code=True, **model_load_kwargs\n",
    ")\n",
    "\n",
    "print(\"Model loaded.\")\n",
    "print(f\"  - Device Map: {getattr(model, 'hf_device_map', model.device)}\")\n",
    "print(f\"  - Attention Implementation: {getattr(model.config, 'attn_implementation', 'N/A')}\")\n",
    "\n",
    "# PEFT Setup\n",
    "if USE_LORA:\n",
    "    print(\"\\nApplying PEFT/LoRA configuration...\")\n",
    "    if USE_QLORA:\n",
    "        model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True, gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "        model.config.use_cache = False\n",
    "    elif hasattr(model, \"gradient_checkpointing_enable\"):\n",
    "        model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "        model.config.use_cache = False\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        r=LORA_R, lora_alpha=LORA_ALPHA, lora_dropout=LORA_DROPOUT,\n",
    "        target_modules=LORA_TARGET_MODULES, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "\n",
    "    if not isinstance(model, PeftModel):\n",
    "        model = get_peft_model(model, peft_config)\n",
    "        model.print_trainable_parameters()\n",
    "else:\n",
    "    if hasattr(model, \"gradient_checkpointing_enable\"):\n",
    "        model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "        model.config.use_cache = False\n",
    "\n",
    "print(\"\\n--- Model and Processor Setup Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odIqqWQXeT3r",
    "outputId": "20385819-462d-4247-d9b0-ce030fbf706c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Formatting Function & Data Collator ---\n",
      "\n",
      "Custom Collator instantiated.\n"
     ]
    }
   ],
   "source": [
    "# ### 3.1 define smolvlm formatting functions and collate_fn\n",
    "\n",
    "print(\"\\n--- Defining Formatting Function & Data Collator ---\")\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"You are a Vision Language Model specialized in interpreting visual data from chart images. Your task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase. The charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text. Focus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.\"\"\"\n",
    "#SYSTEM_MESSAGE = \"\"\"You are a Vision-Language Model specialized in interpreting chart images. Please answer the question using only one word or a number based on the provided chart.\"\"\"\n",
    "\n",
    "def create_chat_messages(sample):\n",
    "    \"\"\"Creates the chat message structure for SFT training.\"\"\"\n",
    "    question = sample.get(\"question\")\n",
    "    answer = sample.get(\"answer\")\n",
    "    if question is None or answer is None:\n",
    "         return None\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": SYSTEM_MESSAGE}]},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": question}\n",
    "        ]},\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": answer}]},\n",
    "    ]\n",
    "\n",
    "\n",
    "@dataclass # ChartLlama collator class for collate function\n",
    "class ChartLlamaCollator:\n",
    "    processor: AutoProcessor\n",
    "    max_seq_length: int = MAX_SEQ_LENGTH\n",
    "\n",
    "    def __post_init__(self):\n",
    "        image_token_str = \"<image>\"\n",
    "        self.image_token_id = self.processor.tokenizer.convert_tokens_to_ids(image_token_str)\n",
    "        if self.image_token_id is None:\n",
    "            self.image_token_id = -100\n",
    "\n",
    "    def __call__(self, examples: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        pil_images, texts = [], []\n",
    "\n",
    "        for ex in examples:\n",
    "            img_path = ex.get('image_path')\n",
    "            if not img_path or not os.path.exists(img_path):\n",
    "                continue\n",
    "\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            messages = create_chat_messages(ex)\n",
    "            if messages is None:\n",
    "                continue\n",
    "\n",
    "            formatted_text = self.processor.apply_chat_template(\n",
    "                messages, add_generation_prompt=False, tokenize=False\n",
    "            )\n",
    "\n",
    "            pil_images.append(img)\n",
    "            texts.append(formatted_text)\n",
    "\n",
    "        if not texts or not pil_images:\n",
    "            return {\"input_ids\": torch.tensor([], dtype=torch.long)}\n",
    "\n",
    "        batch = self.processor(\n",
    "            text=texts,\n",
    "            images=pil_images,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            # truncation=True,\n",
    "            # max_length=self.max_seq_length,\n",
    "        )\n",
    "\n",
    "        labels = batch[\"input_ids\"].clone()\n",
    "        labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        if self.image_token_id != -100:\n",
    "            labels[labels == self.image_token_id] = -100\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "chart_collator = ChartLlamaCollator(processor=processor)\n",
    "print(\"\\nCustom Collator instantiated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQ0-a3LaeZO9",
    "outputId": "b991cd73-66c5-41fe-fbd1-b3db759a4677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Configuring Training Arguments ---\n",
      "SFTConfig set.\n"
     ]
    }
   ],
   "source": [
    "# configure training arguments\n",
    "print(\"\\n--- Configuring Training Arguments ---\")\n",
    "\n",
    "if 'OUTPUT_DIR' not in locals():\n",
    "    raise NameError(\"OUTPUT_DIR not defined. Rerun configuration cell.\")\n",
    "\n",
    "trainer_config = SFTConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    dataset_text_field=\"\",\n",
    "    packing=False,\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "\n",
    "    optim=OPTIMIZER,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
    "\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    save_strategy=SAVE_STRATEGY,\n",
    "    save_total_limit=2,\n",
    "    save_only_model=(\"peft_config\" in locals() and peft_config is not None),\n",
    "\n",
    "    bf16=(DTYPE == torch.bfloat16),\n",
    "    fp16=(DTYPE == torch.float16),\n",
    "\n",
    "    eval_strategy=EVAL_STRATEGY,\n",
    "    eval_steps=EVAL_STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "\n",
    "    seed=SEED,\n",
    "    report_to=\"wandb\" if WANDB_PROJECT and os.environ.get(\"WANDB_DISABLED\") != \"true\" else \"none\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "print(\"SFTConfig set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TzmIm_QcsfB",
    "outputId": "a6f6bdbc-547f-4be1-d240-50c7adbd9a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initializing SFTTrainer ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFTTrainer initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# initialize trainer\n",
    "\n",
    "print(\"\\n--- Initializing SFTTrainer ---\")\n",
    "\n",
    "required_components = [train_dataset, model, trainer_config, chart_collator, processor]\n",
    "\n",
    "if all(required_components):\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=trainer_config,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset if EVAL_STRATEGY != \"no\" else None,\n",
    "        data_collator=chart_collator,\n",
    "        peft_config=peft_config if USE_LORA else None,\n",
    "    )\n",
    "    print(\"SFTTrainer initialized successfully.\")\n",
    "else:\n",
    "    missing = [name for name, comp in zip(\n",
    "        ['train_dataset', 'model', 'trainer_config', 'chart_collator', 'processor'],\n",
    "        required_components) if comp is None]\n",
    "    raise RuntimeError(f\"Cannot initialize trainer. Missing components: {', '.join(missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "YExT-I4GevPn",
    "outputId": "cb52151b-7813-4991-97a9-8c494ea17693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking if Training Should Be Skipped ---\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 47:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.195400</td>\n",
       "      <td>1.770576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.349600</td>\n",
       "      <td>0.542882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.431299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricky732/anaconda3/envs/py10_vlm/lib/python3.10/site-packages/peft/utils/save_and_load.py:220: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 48.05 minutes.\n",
      "***** train metrics *****\n",
      "  total_flos               =  6457924GF\n",
      "  train_loss               =     1.4076\n",
      "  train_runtime            = 0:48:03.02\n",
      "  train_samples_per_second =      0.816\n",
      "  train_steps_per_second   =      0.051\n",
      "\n",
      "--- Training Step Execution Finished ---\n"
     ]
    }
   ],
   "source": [
    "# --- Run Training (with Loss curve Plotting Added & Enhanced Naming) ---\n",
    "\n",
    "print(\"\\n--- Checking if Training Should Be Skipped ---\")\n",
    "\n",
    "model_exists = os.path.isdir(FINAL_MODEL_DIR) and any(\n",
    "    f.endswith(('.bin', '.safetensors', 'adapter_config.json')) for f in os.listdir(FINAL_MODEL_DIR)\n",
    ")\n",
    "\n",
    "processor_exists = os.path.isfile(os.path.join(FINAL_PROCESSOR_DIR, \"preprocessor_config.json\"))\n",
    "\n",
    "if model_exists and processor_exists:\n",
    "    print(\"Model and processor already exist. Skipping training.\")\n",
    "else:\n",
    "    if trainer is None or processor is None:\n",
    "        raise RuntimeError(\"Trainer or processor not available. Cannot proceed with training.\")\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    os.makedirs(FINAL_MODEL_DIR, exist_ok=True)\n",
    "    os.makedirs(FINAL_PROCESSOR_DIR, exist_ok=True)\n",
    "\n",
    "    train_result = trainer.train()\n",
    "\n",
    "    print(f\"Training completed in {(time.time() - start_time)/60:.2f} minutes.\")\n",
    "\n",
    "    trainer.save_model(FINAL_MODEL_DIR)\n",
    "    processor.save_pretrained(FINAL_PROCESSOR_DIR)\n",
    "\n",
    "    trainer.log_metrics(\"train\", train_result.metrics)\n",
    "    trainer.save_metrics(\"train\", train_result.metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "    log_history = trainer.state.log_history\n",
    "    if log_history:\n",
    "        log_df = pd.DataFrame(log_history)\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "        if 'loss' in log_df:\n",
    "            ax.plot(log_df['step'], log_df['loss'], label='Training Loss', marker='o')\n",
    "        if 'eval_loss' in log_df:\n",
    "            ax.plot(log_df['step'], log_df['eval_loss'], label='Validation Loss', marker='s')\n",
    "\n",
    "        ax.set_title(f\"Training & Validation Loss ({model_name_short}, {TRAINING_TYPE})\")\n",
    "        ax.set_xlabel(\"Steps\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "        plot_path = os.path.join(OUTPUT_DIR, f\"loss_curves_{model_name_short}_{TRAINING_TYPE}.png\")\n",
    "        fig.savefig(plot_path, dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "# Cleanup\n",
    "del trainer\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n--- Training Step Execution Finished ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLW_j24AfXO6",
    "outputId": "a69c42c7-9dee-4e42-ae27-91c9777a514a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Setting up Evaluation Environment ---\n",
      "Loading processor from: /home/ricky732/CS7643_final_project/working_dir/smolvlm-500M-chartllama-sft-long-prompt-SmolVLM-500M-Instruct-qlora-tuned-paddingTrue/final_processor\n",
      "Processor loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Fine-tuned Model ---\n",
    "print(\"\\n--- Setting up Evaluation Environment ---\")\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "FT_MODEL_LOAD_PATH = FINAL_MODEL_DIR\n",
    "PROCESSOR_LOAD_PATH = FINAL_PROCESSOR_DIR\n",
    "\n",
    "print(f\"Loading processor from: {PROCESSOR_LOAD_PATH}\")\n",
    "\n",
    "if not os.path.isdir(PROCESSOR_LOAD_PATH):\n",
    "    raise FileNotFoundError(f\"Processor directory not found: {PROCESSOR_LOAD_PATH}\")\n",
    "\n",
    "eval_processor = AutoProcessor.from_pretrained(PROCESSOR_LOAD_PATH, trust_remote_code=True)\n",
    "\n",
    "if eval_processor.tokenizer.pad_token_id is None:\n",
    "    eval_processor.tokenizer.pad_token = eval_processor.tokenizer.eos_token\n",
    "    if hasattr(eval_processor, 'pad_token') and eval_processor.pad_token is None:\n",
    "        eval_processor.pad_token = eval_processor.tokenizer.eos_token\n",
    "\n",
    "print(\"Processor loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvrSHP3NbX3K",
    "outputId": "10bf146b-6ff3-4890-8f3c-d8d59b68f2f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Fine-tuned Model ---\n",
    "\n",
    "eval_model = None\n",
    "if not eval_processor:\n",
    "    raise RuntimeError(\"Processor is not loaded. Cannot load model.\")\n",
    "\n",
    "if not os.path.isdir(FT_MODEL_LOAD_PATH):\n",
    "    raise FileNotFoundError(f\"Fine-tuned model directory not found: {FT_MODEL_LOAD_PATH}\")\n",
    "\n",
    "# Load evaluation configuration\n",
    "try:\n",
    "    eval_config = AutoConfig.from_pretrained(FT_MODEL_LOAD_PATH, trust_remote_code=True)\n",
    "except OSError:\n",
    "    eval_config = AutoConfig.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "eval_config.use_cache = True\n",
    "if hasattr(eval_config, \"attn_implementation\"):\n",
    "    eval_config.attn_implementation = ATTN_IMPLEMENTATION\n",
    "\n",
    "load_kwargs = {\"device_map\": \"auto\", \"torch_dtype\": DTYPE}\n",
    "\n",
    "if USE_LORA:\n",
    "    # Ensure pad_token consistency\n",
    "    pad_token_id = eval_processor.tokenizer.pad_token_id\n",
    "    base_config = AutoConfig.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "    config_to_modify = base_config.text_config if hasattr(base_config, 'text_config') else base_config\n",
    "    config_to_modify.pad_token_id = pad_token_id\n",
    "    config_to_modify.vocab_size = max(config_to_modify.vocab_size, pad_token_id + 1)\n",
    "\n",
    "    base_config.use_cache = True\n",
    "    if hasattr(base_config, \"attn_implementation\"):\n",
    "        base_config.attn_implementation = ATTN_IMPLEMENTATION\n",
    "\n",
    "    #if USE_QLORA:\n",
    "    #    load_kwargs[\"quantization_config\"] = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=DTYPE)\n",
    "\n",
    "    base_model = Idefics3ForConditionalGeneration.from_pretrained(MODEL_ID, config=base_config, trust_remote_code=True, **load_kwargs)\n",
    "    eval_model = PeftModel.from_pretrained(base_model, FT_MODEL_LOAD_PATH)\n",
    "else:\n",
    "    eval_model = Idefics3ForConditionalGeneration.from_pretrained(FT_MODEL_LOAD_PATH, config=eval_config, trust_remote_code=True, **load_kwargs)\n",
    "\n",
    "# Prepare model for evaluation\n",
    "eval_model.eval()\n",
    "print(\"Fine-tuned model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7JCuLGbrGyJ",
    "outputId": "ac689d4a-88c3-44d3-dff6-ae395bb61410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Base Model for Evaluation ---\n",
    "\n",
    "if eval_processor is None:\n",
    "    raise RuntimeError(\"Processor is not loaded; cannot load base model.\")\n",
    "\n",
    "base_model_config = AutoConfig.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "base_model_config.use_cache = True\n",
    "\n",
    "if hasattr(base_model_config, \"attn_implementation\"):\n",
    "    base_model_config.attn_implementation = ATTN_IMPLEMENTATION\n",
    "\n",
    "base_load_kwargs = {\"device_map\": \"auto\", \"torch_dtype\": DTYPE}\n",
    "\n",
    "base_model_eval = Idefics3ForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    config=base_model_config,\n",
    "    trust_remote_code=True,\n",
    "    **base_load_kwargs\n",
    ")\n",
    "\n",
    "base_model_eval.eval()\n",
    "print(\"Base model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stWYNZe_fyQD",
    "outputId": "77143942-b534-4258-d85c-923ccb204106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading evaluation dataset 'HuggingFaceM4/ChartQA' split 'test'...\n",
      "Loaded 2500 samples for evaluation (full test set).\n"
     ]
    }
   ],
   "source": [
    "# --- Load Evaluation Dataset (ChartQA) ---\n",
    "chartqa_test_dataset = None\n",
    "if eval_processor:\n",
    "    try:\n",
    "        print(f\"\\nLoading evaluation dataset '{CHARTQA_DATASET_ID}' split '{EVAL_SPLIT}'...\")\n",
    "        chartqa_test_iterable = load_dataset(CHARTQA_DATASET_ID, split=EVAL_SPLIT, streaming=False)\n",
    "\n",
    "        if EVAL_LIMIT is not None and EVAL_LIMIT > 0:\n",
    "            chartqa_test_list = list(chartqa_test_iterable)\n",
    "            chartqa_test_dataset = chartqa_test_list[:EVAL_LIMIT]\n",
    "            print(f\"Loaded and limited to {len(chartqa_test_dataset)} samples for evaluation.\")\n",
    "        else:\n",
    "            chartqa_test_dataset = list(chartqa_test_iterable)\n",
    "            print(f\"Loaded {len(chartqa_test_dataset)} samples for evaluation (full {EVAL_SPLIT} set).\")\n",
    "\n",
    "        if chartqa_test_dataset:\n",
    "             if isinstance(chartqa_test_dataset[0], dict) and 'img_idx' not in chartqa_test_dataset[0]:\n",
    "                  chartqa_test_dataset = [dict(sample, img_idx=i) for i, sample in enumerate(chartqa_test_dataset)]\n",
    "        else:\n",
    "             print(\"Warning: ChartQA dataset is empty after loading/limiting.\")\n",
    "\n",
    "    except Exception as e_dataset:\n",
    "        print(f\"ERROR loading evaluation dataset: {e_dataset}\")\n",
    "        traceback.print_exc()\n",
    "        chartqa_test_dataset = None\n",
    "else:\n",
    "     print(\"Skipping dataset loading due to processor error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "za0dmEKnf0TZ",
    "outputId": "f073e028-dcae-445e-d457-4af8c8382911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Readiness:\n",
      "  - Processor Ready: True\n",
      "  - Fine-tuned Model Ready: True\n",
      "  - Base Model Ready: True\n",
      "  - Dataset Ready: True\n",
      "  - Can Evaluate Fine-tuned: True\n",
      "  - Can Evaluate Base: True\n",
      "Evaluation Device: cuda\n",
      "\n",
      "--- Evaluation Setup Complete ---\n"
     ]
    }
   ],
   "source": [
    "# Check Evaluation Readiness\n",
    "components = {\n",
    "    \"Processor\": eval_processor,\n",
    "    \"Fine-tuned Model\": eval_model,\n",
    "    \"Base Model\": base_model_eval,\n",
    "    \"Dataset\": chartqa_test_dataset if chartqa_test_dataset else None,\n",
    "}\n",
    "\n",
    "readiness = {name: comp is not None for name, comp in components.items()}\n",
    "readiness[\"Dataset\"] = readiness[\"Dataset\"] and len(chartqa_test_dataset) > 0\n",
    "\n",
    "can_evaluate_finetuned = all([readiness[\"Processor\"], readiness[\"Fine-tuned Model\"], readiness[\"Dataset\"]])\n",
    "can_evaluate_base = all([readiness[\"Processor\"], readiness[\"Base Model\"], readiness[\"Dataset\"]])\n",
    "\n",
    "print(\"\\nEvaluation Readiness:\")\n",
    "for name, ready in readiness.items():\n",
    "    print(f\"  - {name} Ready: {ready}\")\n",
    "\n",
    "print(f\"  - Can Evaluate Fine-tuned: {can_evaluate_finetuned}\")\n",
    "print(f\"  - Can Evaluate Base: {can_evaluate_base}\")\n",
    "print(f\"Evaluation Device: {DEVICE}\")\n",
    "\n",
    "# cleanup\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n--- Evaluation Setup Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ursoAe7Yf314",
    "outputId": "cac021f1-97a0-4d32-add8-9917ca257569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Evaluation Helper Functions ---\n",
      "Evaluation helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Define Evaluation helper functions\n",
    "print(\"\\n--- Defining Evaluation Helper Functions ---\")\n",
    "\n",
    "# System message for evaluation prompting (provided by SmolVLM)\n",
    "EVAL_SYSTEM_MESSAGE = \"\"\"You are a Vision Language Model specialized in interpreting visual data from chart images.\n",
    "Your task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase.\n",
    "The charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\n",
    "Focus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.\"\"\"\n",
    "\n",
    "EVAL_SYSTEM_MESSAGE = \"\"\"Have fun!\"\"\"\n",
    "\n",
    "def create_inference_chat_messages(sample):\n",
    "    \"\"\"Creates the chat message structure for inference using ChartQA's 'query' field.\"\"\"\n",
    "    question = sample.get(\"query\")\n",
    "    if not question:\n",
    "        return None\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": EVAL_SYSTEM_MESSAGE}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": question}]},\n",
    "    ]\n",
    "\n",
    "\n",
    "print(\"Evaluation helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170,
     "referenced_widgets": [
      "4c5a6e95dd7148dc9f7bc527679507fa",
      "813631951f2f40acb899c8927cec9bb3",
      "72c90dd27f3c4ef9a8492fd3b430af7c",
      "79ffb8362da9449aad286e3eb833b05a",
      "e7d75c969a4f4901944f68bd508b904f",
      "e738c67125104bcb8818d2862f120190",
      "2f4b5d5d1127458881d2ef21715cec1f",
      "eed838704c95403d943d1f8959d79b55",
      "a76c3e7d3295473f90d7504e41986d68",
      "e3a914640f2c429fb46ce17f9b1b503b",
      "0d2396bf005146758bd55e63bfbae9e6"
     ]
    },
    "id": "uhz0ZKGdf6hX",
    "outputId": "52ecee04-490a-45a7-d997-3021e4979de0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Evaluation Generation & Saving ---\n",
      "Generating predictions for 2 model(s) on 2500 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f7a6a234cd44f9aeb0f2f9c898f156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation results (raw predictions) saved to: /home/ricky732/CS7643_final_project/working_dir/smolvlm-500M-chartllama-sft-long-prompt-SmolVLM-500M-Instruct-qlora-tuned-paddingTrue/chartqa_evaluation_results_comparison.json\n",
      "\n",
      "--- Evaluation Generation & Saving Finished ---\n"
     ]
    }
   ],
   "source": [
    "# --- Generate Predictions and Save Results ---\n",
    "\n",
    "print(\"\\n--- Running Evaluation Generation & Saving ---\")\n",
    "\n",
    "# --- Define Concise Generation Function ---\n",
    "def generate_prediction_concise(model, processor, sample, max_tokens, max_len):\n",
    "    question, image = sample.get(\"query\"), sample.get(\"image\")\n",
    "    if not (question and isinstance(image, Image.Image)): return \"ERROR:Input\"\n",
    "    if image.mode != 'RGB':\n",
    "        try: image = image.convert('RGB')\n",
    "        except: return \"ERROR:Convert\"\n",
    "\n",
    "    messages = create_inference_chat_messages(sample)\n",
    "    if not messages: return \"ERROR:Messages\"\n",
    "\n",
    "    prediction = \"ERROR:Generate\"\n",
    "    inputs = None; generated_ids = None\n",
    "    try:\n",
    "        prompt = processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "        device = next(iter(model.parameters()), torch.tensor([])).device\n",
    "        if device is None: device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        inputs = processor(text=[prompt], images=[image], return_tensors=\"pt\", padding=False, truncation=True, max_length=max_len).to(device)\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=max_tokens, do_sample=False,\n",
    "                                       pad_token_id=processor.tokenizer.pad_token_id,\n",
    "                                       eos_token_id=processor.tokenizer.eos_token_id)\n",
    "        gen_tokens = generated_ids[0, inputs[\"input_ids\"].shape[1]:]\n",
    "        prediction = processor.decode(gen_tokens, skip_special_tokens=True).strip() if gen_tokens.numel() > 0 else \"[NO_TOKENS]\"\n",
    "    except Exception as e:\n",
    "        prediction = f\"ERROR:{e.__class__.__name__}\"\n",
    "    finally:\n",
    "        del inputs, generated_ids\n",
    "    return prediction\n",
    "# --- End Generation Function ---\n",
    "\n",
    "# Determine models to evaluate\n",
    "models_to_eval = {}\n",
    "if 'can_evaluate_finetuned' in locals() and can_evaluate_finetuned and 'eval_model' in locals():\n",
    "    models_to_eval[\"finetuned\"] = eval_model\n",
    "if 'can_evaluate_base' in locals() and can_evaluate_base and 'base_model_eval' in locals():\n",
    "    models_to_eval[\"base\"] = base_model_eval\n",
    "\n",
    "results_list = []\n",
    "# Check dataset and models before looping\n",
    "if 'chartqa_test_dataset' in locals() and chartqa_test_dataset and models_to_eval:\n",
    "    print(f\"Generating predictions for {len(models_to_eval)} model(s) on {len(chartqa_test_dataset)} samples...\")\n",
    "    # --- Generate Predictions ---\n",
    "    for sample in tqdm(chartqa_test_dataset, desc=\"Generating Predictions\"):\n",
    "        entry = {\"id\": sample.get(\"img_idx\", \"N/A\"),\n",
    "                 \"question\": sample.get(\"query\"),\n",
    "                 \"ground_truth\": str(sample.get(\"label\"))} # Convert GT to string here\n",
    "\n",
    "        # Basic validation of core sample data needed for processing\n",
    "        if not all([entry[\"id\"] != \"N/A\", entry[\"question\"], entry[\"ground_truth\"] is not None, isinstance(sample.get(\"image\"), Image.Image)]):\n",
    "            print(f\"Warning: Skipping sample {entry['id']} due to missing/invalid core data.\")\n",
    "            continue # Skip this sample\n",
    "\n",
    "        # Generate for applicable models\n",
    "        for name, model_obj in models_to_eval.items():\n",
    "            entry[f\"predicted_answer_{name}\"] = generate_prediction_concise(model_obj, eval_processor, sample, MAX_NEW_TOKENS_EVAL, MAX_SEQ_LENGTH)\n",
    "        results_list.append(entry)\n",
    "    # --- End Prediction Loop ---\n",
    "\n",
    "    # --- Save results_df to JSON ---\n",
    "    if results_list:\n",
    "        results_df = pd.DataFrame(results_list)\n",
    "        if 'EVAL_OUTPUT_FILE' in locals() and EVAL_OUTPUT_FILE:\n",
    "            try:\n",
    "                os.makedirs(os.path.dirname(EVAL_OUTPUT_FILE), exist_ok=True)\n",
    "                results_df.to_json(EVAL_OUTPUT_FILE, orient=\"records\", indent=2)\n",
    "                print(f\"\\nEvaluation results (raw predictions) saved to: {EVAL_OUTPUT_FILE}\")\n",
    "            except Exception as e_save:\n",
    "                 print(f\"\\nERROR saving evaluation results to {EVAL_OUTPUT_FILE}: {e_save}\")\n",
    "        else:\n",
    "             print(\"\\nWarning: EVAL_OUTPUT_FILE not defined, results not saved.\")\n",
    "    else:\n",
    "        print(\"No valid evaluation results were generated to save.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping evaluation generation: Dataset or models not ready.\")\n",
    "\n",
    "print(f\"\\n--- Evaluation Generation & Saving Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "id": "46FDeddBnzI-",
    "outputId": "46b07ada-3cf7-4503-fda0-615b6d57bece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Aggregating Evaluation Results ---\n",
      "Aggregated Results Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>Pred_SmolVLM-500M-Instruct-qlora-tuned-paddingTrue</th>\n",
       "      <th>Pred_SmolVLM-500M-Instruct-qlora-tuned-Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How many food item is shown in the bar graph?</td>\n",
       "      <td>['14']</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the difference in value between Lamb a...</td>\n",
       "      <td>['0.57']</td>\n",
       "      <td>103.7-103.13\\nAnswer: 0.50</td>\n",
       "      <td>103.7 - 103.13 \\nAnswer: 0.5.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How many bars are shown in the chart?</td>\n",
       "      <td>['3']</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Is the sum value of Madagascar more then Fiji?</td>\n",
       "      <td>['No']</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>Yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What's the value of the lowest bar?</td>\n",
       "      <td>['23']</td>\n",
       "      <td>The Japanese public is divided over whether Ja...</td>\n",
       "      <td>In a new survey, 68% of Japanese say Japan sho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question ground_truth  \\\n",
       "0   0      How many food item is shown in the bar graph?       ['14']   \n",
       "1   1  What is the difference in value between Lamb a...     ['0.57']   \n",
       "2   2              How many bars are shown in the chart?        ['3']   \n",
       "3   3     Is the sum value of Madagascar more then Fiji?       ['No']   \n",
       "4   4                What's the value of the lowest bar?       ['23']   \n",
       "\n",
       "  Pred_SmolVLM-500M-Instruct-qlora-tuned-paddingTrue  \\\n",
       "0                                                 16   \n",
       "1                         103.7-103.13\\nAnswer: 0.50   \n",
       "2                                                  4   \n",
       "3                                               Yes.   \n",
       "4  The Japanese public is divided over whether Ja...   \n",
       "\n",
       "     Pred_SmolVLM-500M-Instruct-qlora-tuned-Original  \n",
       "0                                                 16  \n",
       "1                      103.7 - 103.13 \\nAnswer: 0.5.  \n",
       "2                                                  3  \n",
       "3                                               Yes.  \n",
       "4  In a new survey, 68% of Japanese say Japan sho...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated results saved to /home/ricky732/CS7643_final_project/working_dir/smolvlm-500M-chartllama-sft-long-prompt-ALL_RUNS_COMPARISON_WITH_BASE.csv\n"
     ]
    }
   ],
   "source": [
    "### Final results compilation\n",
    "print(\"--- Aggregating Evaluation Results ---\")\n",
    "\n",
    "BASE_OUTPUT_DIR = Path(WORKING_DIR)\n",
    "OUTPUT_FOLDER_PREFIX = OUTPUT_DIR_BASE_NAME\n",
    "EVAL_FILENAME = \"chartqa_evaluation_results_comparison.json\"\n",
    "\n",
    "search_pattern = f\"{OUTPUT_FOLDER_PREFIX}*/{EVAL_FILENAME}\"\n",
    "result_files = list(BASE_OUTPUT_DIR.glob(search_pattern))\n",
    "\n",
    "# if not result_files:\n",
    "#     raise FileNotFoundError(\"No evaluation result files found.\")\n",
    "\n",
    "aggregated_dfs = []\n",
    "base_models_added = set()\n",
    "\n",
    "for file_path in result_files:\n",
    "    run_label = file_path.parent.name.replace(f\"{OUTPUT_FOLDER_PREFIX}-\", \"\")\n",
    "    parts = run_label.split('-')\n",
    "    base_model_name = '-'.join(parts[:-1]) if len(parts) >= 2 else \"UnknownBase\"\n",
    "    base_label = f\"{base_model_name}-Original\"\n",
    "\n",
    "    df = pd.read_json(file_path)\n",
    "\n",
    "    columns = ['id', 'question', 'ground_truth'] if not aggregated_dfs else ['id']\n",
    "    rename_dict = {}\n",
    "\n",
    "    if 'predicted_answer_finetuned' in df:\n",
    "        columns.append('predicted_answer_finetuned')\n",
    "        rename_dict['predicted_answer_finetuned'] = f\"Pred_{run_label}\"\n",
    "\n",
    "    if base_model_name not in base_models_added and 'predicted_answer_base' in df:\n",
    "        columns.append('predicted_answer_base')\n",
    "        rename_dict['predicted_answer_base'] = f\"Pred_{base_label}\"\n",
    "        base_models_added.add(base_model_name)\n",
    "\n",
    "    df_subset = df[columns].rename(columns=rename_dict)\n",
    "    aggregated_dfs.append(df_subset)\n",
    "\n",
    "if aggregated_dfs:\n",
    "    final_comparison_df = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), aggregated_dfs)\n",
    "    final_comparison_df.ffill(inplace=True)\n",
    "    final_comparison_df.bfill(inplace=True)\n",
    "else:\n",
    "    print(\" No evaluation results found to aggregate.\")\n",
    "    final_comparison_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "print(\"Aggregated Results Preview:\")\n",
    "display(final_comparison_df.head())\n",
    "\n",
    "output_file = BASE_OUTPUT_DIR / f\"{OUTPUT_FOLDER_PREFIX}-ALL_RUNS_COMPARISON_WITH_BASE.csv\"\n",
    "final_comparison_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Aggregated results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5OolIvYVfkEY",
    "outputId": "3c5525ff-5aaa-444a-b073-460e24f4b0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmolVLM-500M-Instruct-qlora-tuned-paddingTrue EM= 41.11%  Relaxed= 50.36%  (1392 num / 1406 valid)\n",
      "SmolVLM-500M-Instruct-qlora-tuned-Original EM= 35.74%  Relaxed= 44.15%  (1008 num / 1013 valid)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>RelaxedNum(%)</th>\n",
       "      <th>#Numeric</th>\n",
       "      <th>#Valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SmolVLM-500M-Instruct-qlora-tuned-paddingTrue</th>\n",
       "      <td>41.11</td>\n",
       "      <td>50.36</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>1406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SmolVLM-500M-Instruct-qlora-tuned-Original</th>\n",
       "      <td>35.74</td>\n",
       "      <td>44.15</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1013.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               EM (%)  RelaxedNum(%)  \\\n",
       "SmolVLM-500M-Instruct-qlora-tuned-paddingTrue   41.11            50.36   \n",
       "SmolVLM-500M-Instruct-qlora-tuned-Original      35.74            44.15   \n",
       "\n",
       "                                               #Numeric  #Valid  \n",
       "SmolVLM-500M-Instruct-qlora-tuned-paddingTrue     1392.0   1406.0  \n",
       "SmolVLM-500M-Instruct-qlora-tuned-Original        1008.0   1013.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>Pred_SmolVLM-500M-Instruct-qlora-tuned-paddingTrue</th>\n",
       "      <th>Pred_SmolVLM-500M-Instruct-qlora-tuned-Original</th>\n",
       "      <th>GT_proc</th>\n",
       "      <th>Pred_SmolVLM-500M-Instruct-qlora-tuned-paddingTrue_proc</th>\n",
       "      <th>Pred_SmolVLM-500M-Instruct-qlora-tuned-Original_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How many food item is shown in the bar graph?</td>\n",
       "      <td>['14']</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the difference in value between Lamb a...</td>\n",
       "      <td>['0.57']</td>\n",
       "      <td>103.7-103.13\\nAnswer: 0.50</td>\n",
       "      <td>103.7 - 103.13 \\nAnswer: 0.5.</td>\n",
       "      <td>0.57</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How many bars are shown in the chart?</td>\n",
       "      <td>['3']</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Is the sum value of Madagascar more then Fiji?</td>\n",
       "      <td>['No']</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What's the value of the lowest bar?</td>\n",
       "      <td>['23']</td>\n",
       "      <td>The Japanese public is divided over whether Ja...</td>\n",
       "      <td>In a new survey, 68% of Japanese say Japan sho...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question ground_truth  \\\n",
       "0   0      How many food item is shown in the bar graph?       ['14']   \n",
       "1   1  What is the difference in value between Lamb a...     ['0.57']   \n",
       "2   2              How many bars are shown in the chart?        ['3']   \n",
       "3   3     Is the sum value of Madagascar more then Fiji?       ['No']   \n",
       "4   4                What's the value of the lowest bar?       ['23']   \n",
       "\n",
       "  Pred_SmolVLM-500M-Instruct-qlora-tuned-paddingTrue  \\\n",
       "0                                                 16   \n",
       "1                         103.7-103.13\\nAnswer: 0.50   \n",
       "2                                                  4   \n",
       "3                                               Yes.   \n",
       "4  The Japanese public is divided over whether Ja...   \n",
       "\n",
       "     Pred_SmolVLM-500M-Instruct-qlora-tuned-Original GT_proc  \\\n",
       "0                                                 16    14.0   \n",
       "1                      103.7 - 103.13 \\nAnswer: 0.5.    0.57   \n",
       "2                                                  3     3.0   \n",
       "3                                               Yes.      no   \n",
       "4  In a new survey, 68% of Japanese say Japan sho...    23.0   \n",
       "\n",
       "  Pred_SmolVLM-500M-Instruct-qlora-tuned-paddingTrue_proc  \\\n",
       "0                                               16.0        \n",
       "1                                               None        \n",
       "2                                                4.0        \n",
       "3                                               None        \n",
       "4                                               None        \n",
       "\n",
       "   Pred_SmolVLM-500M-Instruct-qlora-tuned-Original_proc  \n",
       "0                                               16.0     \n",
       "1                                                NaN     \n",
       "2                                                3.0     \n",
       "3                                                NaN     \n",
       "4                                                NaN     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: /home/ricky732/CS7643_final_project/working_dir/smolvlm-500M-chartllama-sft-long-prompt-ALL_RUNS_COMPARISON_WITH_PROCESSED.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Advanced accuracy metrics -------------------------------\n",
    "\n",
    "YES, NO      = {\"yes\",\"y\",\"true\",\"correct\"}, {\"no\",\"n\",\"false\",\"incorrect\"}\n",
    "TOL, EPS     = 0.05, 1e-9                  # 5%, tiny tolerance for 0\n",
    "PRED_PREFIX  = \"Pred_\"                     # rename if your columns differ\n",
    "\n",
    "# 2.  Helpers -------------------------------------------------------------------\n",
    "def to_scalar(v):\n",
    "    \"\"\"Clean & convert value  float | 'yes' | 'no' | None.\"\"\"\n",
    "    if pd.isna(v): return None\n",
    "    s = str(v).strip()\n",
    "    m = re.fullmatch(r\"\\[['\\\"]?(.*?)['\\\"]?\\]\", s)\n",
    "    if m: s = m.group(1)\n",
    "    s = s.lower().replace(\",\",\"\").replace(\"$\",\"\").replace(\"%\",\"\").strip()\n",
    "    if s in YES: return \"yes\"\n",
    "    if s in NO:  return \"no\"\n",
    "    for fn in (float, w2n.word_to_num):\n",
    "        try: return float(fn(s))\n",
    "        except Exception: pass\n",
    "    return None\n",
    "\n",
    "def relaxed(gt, pred):\n",
    "    return abs(gt - pred) <= (abs(gt) * TOL or EPS)\n",
    "\n",
    "# 3.  Basic checks --------------------------------------------------------------\n",
    "if not isinstance(globals().get(\"final_comparison_df\"), pd.DataFrame):\n",
    "    sys.exit(\"  `final_comparison_df` is missing.\")\n",
    "\n",
    "df = final_comparison_df.copy()\n",
    "df[\"GT_proc\"] = df[\"ground_truth\"].map(to_scalar)\n",
    "\n",
    "keep = df[\"GT_proc\"].isin([\"yes\",\"no\"]) | df[\"GT_proc\"].apply(lambda x: isinstance(x,(int,float)))\n",
    "df_filt = df[keep]\n",
    "if df_filt.empty:\n",
    "    sys.exit(\"  No yes/no/numeric groundtruth rows after processing.\")\n",
    "\n",
    "# Metrics per run -----------------------------------------------------------\n",
    "results = {}\n",
    "for col in [c for c in df.columns if c.startswith(PRED_PREFIX)]:\n",
    "    proc = f\"{col}_proc\"\n",
    "    df[proc] = df[col].map(to_scalar)\n",
    "\n",
    "    valid   = df[[\"GT_proc\", proc]].dropna()\n",
    "    numeric = valid[valid[\"GT_proc\"].apply(lambda x:isinstance(x,(int,float))) &\n",
    "                    valid[proc].apply(lambda x:isinstance(x,(int,float)))]\n",
    "\n",
    "    em  = 100 * (valid[\"GT_proc\"] == valid[proc]).mean() if not valid.empty else 0\n",
    "    rel = 100 * numeric.apply(lambda r: relaxed(r[\"GT_proc\"], r[proc]), axis=1).mean() if not numeric.empty else 0\n",
    "\n",
    "    run = col.replace(PRED_PREFIX, \"\")\n",
    "    results[run] = {\"EM (%)\": round(em,2),\n",
    "                    \"RelaxedNum(%)\": round(rel,2),\n",
    "                    \"#Numeric\": len(numeric),\n",
    "                    \"#Valid\": len(valid)}\n",
    "\n",
    "    print(f\"{run:<15} EM={em:6.2f}%  Relaxed={rel:6.2f}%  ({len(numeric)} num / {len(valid)} valid)\")\n",
    "\n",
    "# Summary & preview ---------------------------------------------------------\n",
    "summary = pd.DataFrame(results).T.sort_values(\"EM (%)\", ascending=False)\n",
    "display(summary)\n",
    "display(df.head())\n",
    "\n",
    "# Save to CSV ---------------------------------------------------------------\n",
    "BASE_OUTPUT_DIR = Path(globals().get(\"BASE_OUTPUT_DIR\", \"./outputs\"))\n",
    "BASE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "prefix = globals().get(\"OUTPUT_FOLDER_PREFIX\", \"RUNS\")\n",
    "out_file = BASE_OUTPUT_DIR / f\"{prefix}-ALL_RUNS_COMPARISON_WITH_PROCESSED.csv\"\n",
    "df.to_csv(out_file, index=False)\n",
    "print(\"  Saved:\", out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "Xh3ES_Khp-UA",
    "outputId": "97ad80b4-3418-4f75-fa0d-7ad45578e1ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Aggregating and Plotting Loss Curves ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x300 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated plot saved to /home/ricky732/CS7643_final_project/working_dir/smolvlm-500M-chartllama-sft-long-prompt_aggregated_loss_curves.png\n"
     ]
    }
   ],
   "source": [
    "# aggregate and plot loss curves\n",
    "\n",
    "print(\"--- Aggregating and Plotting Loss Curves ---\")\n",
    "\n",
    "BASE_OUTPUT_DIR = Path(WORKING_DIR)\n",
    "OUTPUT_FOLDER_PREFIX = OUTPUT_DIR_BASE_NAME\n",
    "STATE_FILENAME = \"trainer_state.json\"\n",
    "\n",
    "search_pattern = f\"{OUTPUT_FOLDER_PREFIX}*/{STATE_FILENAME}\"\n",
    "state_files = list(BASE_OUTPUT_DIR.glob(search_pattern))\n",
    "\n",
    "if not state_files:\n",
    "    raise FileNotFoundError(\"No trainer state files found.\")\n",
    "\n",
    "run_data = []\n",
    "max_loss = 0\n",
    "\n",
    "for file_path in state_files:\n",
    "    run_label = file_path.parent.name.replace(f\"{OUTPUT_FOLDER_PREFIX}-\", \"\")\n",
    "\n",
    "    if run_label.endswith(\"-full-tuned\"):\n",
    "        method = \"Full\"\n",
    "    elif run_label.endswith(\"-lora-tuned\"):\n",
    "        method = \"LoRA\"\n",
    "    elif run_label.endswith(\"-qlora-tuned\"):\n",
    "        method = \"QLoRA\"\n",
    "    else:\n",
    "        method = \"LoRA\"\n",
    "\n",
    "    run_label = run_label.replace(\"-full-tuned\", \"\").replace(\"-lora-tuned\", \"\").replace(\"-qlora-tuned\", \"\")\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        log_history = json.load(f).get(\"log_history\", [])\n",
    "\n",
    "    df = pd.DataFrame(log_history)\n",
    "    train_df = df[df['loss'].notna() & df['step'].notna()]\n",
    "    val_df = df[df['eval_loss'].notna() & df['step'].notna()]\n",
    "\n",
    "    if not train_df.empty:\n",
    "        max_loss = max(max_loss, train_df['loss'].max())\n",
    "    if not val_df.empty:\n",
    "        max_loss = max(max_loss, val_df['eval_loss'].max())\n",
    "\n",
    "    run_data.append((run_label, train_df, val_df, method))\n",
    "\n",
    "run_data.sort(key=lambda x: x[0])\n",
    "\n",
    "ncols = 6\n",
    "nrows = math.ceil(len(run_data) / ncols)\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 3), sharey=True, squeeze=False)\n",
    "\n",
    "for ax, (label, train_df, val_df, method) in zip(axes.flatten(), run_data):\n",
    "    if not train_df.empty:\n",
    "        ax.plot(train_df['step'], train_df['loss'], label='Train', linestyle='-', marker='o')\n",
    "    if not val_df.empty:\n",
    "        ax.plot(val_df['step'], val_df['eval_loss'], label='Val', linestyle='--', marker='s')\n",
    "\n",
    "    ax.set_title(f\"{label}\\n({method})\", fontsize=9)\n",
    "    ax.legend(fontsize=7)\n",
    "    ax.grid(True, linestyle=':', alpha=0.7)\n",
    "\n",
    "for ax in axes.flatten()[len(run_data):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.suptitle(\"Training & Validation Losses Across Runs\", fontsize=14)\n",
    "fig.supxlabel(\"Training Steps\", fontsize=11)\n",
    "fig.supylabel(\"Loss\", fontsize=11)\n",
    "fig.tight_layout(rect=[0.02, 0.02, 1, 0.96])\n",
    "\n",
    "plot_path = BASE_OUTPUT_DIR / f\"{OUTPUT_FOLDER_PREFIX}_aggregated_loss_curves.png\"\n",
    "fig.savefig(plot_path, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Aggregated plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4tglAgHhDYK",
    "outputId": "4772fc2c-975e-4059-9dbe-d582fa334ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tokenizer: <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>\n",
      "  pad_token: '<|im_end|>'\n",
      "  pad_token_id: 2\n",
      "  eos_token: '<end_of_utterance>'\n",
      "  eos_token_id: 49279\n"
     ]
    }
   ],
   "source": [
    "# After loading processor = AutoProcessor.from_pretrained(...)\n",
    "# And after the if block checking for None pad_token_id\n",
    "\n",
    "print(f\"Using Tokenizer: {type(processor.tokenizer)}\")\n",
    "print(f\"  pad_token: '{processor.tokenizer.pad_token}'\")\n",
    "print(f\"  pad_token_id: {processor.tokenizer.pad_token_id}\")\n",
    "print(f\"  eos_token: '{processor.tokenizer.eos_token}'\")\n",
    "print(f\"  eos_token_id: {processor.tokenizer.eos_token_id}\")\n",
    "# Optional: Check if processor itself has pad_token attribute\n",
    "if hasattr(processor, 'pad_token'):\n",
    "    print(f\"  Processor object pad_token attribute: '{processor.pad_token}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "033846748696417bb4fb61f93505c93e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0d2396bf005146758bd55e63bfbae9e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "112a279018b342fea4829d34e0edbdd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9fd9b306db94295a4a2c78cc9fa33a3",
      "placeholder": "",
      "style": "IPY_MODEL_f4a13bca67db4ab5acc128da99f02935",
      "value": "7/7[00:00&lt;00:00,7.21it/s]"
     }
    },
    "19871de1c8cf474d963b534dd9a1438f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "278aa53e5ef9415fae21bdf41b770afd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f4b5d5d1127458881d2ef21715cec1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c5a6e95dd7148dc9f7bc527679507fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_813631951f2f40acb899c8927cec9bb3",
       "IPY_MODEL_72c90dd27f3c4ef9a8492fd3b430af7c",
       "IPY_MODEL_79ffb8362da9449aad286e3eb833b05a"
      ],
      "layout": "IPY_MODEL_e7d75c969a4f4901944f68bd508b904f"
     }
    },
    "6152581c7d4746ceb6d61bc71e015c01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b34c44835f0b401eb94e32f66d44adfc",
      "placeholder": "",
      "style": "IPY_MODEL_278aa53e5ef9415fae21bdf41b770afd",
      "value": "ProcessingJSONfiles:100%"
     }
    },
    "625bae4a365b435c91aa623b42e7754c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6152581c7d4746ceb6d61bc71e015c01",
       "IPY_MODEL_a9db73bd09d44ed3ae5934b6ce58de5b",
       "IPY_MODEL_112a279018b342fea4829d34e0edbdd6"
      ],
      "layout": "IPY_MODEL_e2869fd0d0944565aae8e8932ef5004c"
     }
    },
    "72c90dd27f3c4ef9a8492fd3b430af7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eed838704c95403d943d1f8959d79b55",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a76c3e7d3295473f90d7504e41986d68",
      "value": 100
     }
    },
    "79ffb8362da9449aad286e3eb833b05a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3a914640f2c429fb46ce17f9b1b503b",
      "placeholder": "",
      "style": "IPY_MODEL_0d2396bf005146758bd55e63bfbae9e6",
      "value": "100/100[02:08&lt;00:00,1.40s/it]"
     }
    },
    "813631951f2f40acb899c8927cec9bb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e738c67125104bcb8818d2862f120190",
      "placeholder": "",
      "style": "IPY_MODEL_2f4b5d5d1127458881d2ef21715cec1f",
      "value": "GeneratingPredictions:100%"
     }
    },
    "a76c3e7d3295473f90d7504e41986d68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a9db73bd09d44ed3ae5934b6ce58de5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19871de1c8cf474d963b534dd9a1438f",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_033846748696417bb4fb61f93505c93e",
      "value": 7
     }
    },
    "b34c44835f0b401eb94e32f66d44adfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9fd9b306db94295a4a2c78cc9fa33a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2869fd0d0944565aae8e8932ef5004c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3a914640f2c429fb46ce17f9b1b503b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e738c67125104bcb8818d2862f120190": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7d75c969a4f4901944f68bd508b904f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eed838704c95403d943d1f8959d79b55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4a13bca67db4ab5acc128da99f02935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
